---
title: "Software Tutorials: Gene Set Identification (Video Transcript)"
---

# MAGMA {#sec-video1}

**Title**: Gene- and gene-set analysis in MAGMA

**Presenter(s)**: Christiaan de Leeuw

------------------------------------------------------------------------

# H-MAGMA {#sec-video2}

**Title**: Annotating Genetic Variants to Target Genes Using H-MAGMA

**Presenter(s)**: Nancy Y.A. Sey, University of North Carolina at Chapel Hill

Introduction

hi everyone my name is Nancy and today

I'll be talking to you about annotating

genetic variants to Target genes using

high C corporate magma or hmagmap for

short

Background

so before I get started I would just

like to credit doctors um Christian and

Danielle for developing magma Gene set

analysis

so magma is widely used in our field and

this is for various reasons with a few

being that the tool is pretty

revolutionary in that it's aided in

making sense of guas Finance by

identifying the target genes of genetic

variants identified from guas

additionally magma is very easy to use

in that you do not have to be

computationally Savvy to use the tool

also it is very efficient compared to

other tools in the field so it's it

takes a very short time to run magma

however despite all of these benefits

there are a few limitations to the tool

namely magma relies on positional

mapping to link variants to Target genes

we know from prior studies that the gene

regulatory landscape is complex and it's

therefore possible for variants

especially non-coin invariants to

interact with and regulate the install

genes so additionally

um the regulatory landscape can be

tissue or cell type specific so we have

to take into account the tissue or cell

type that's most relevant to the trait

or disease that we're interested in

understanding

so these two limitations served as the

foundation for developing High c-coupled

magma or H magma for short

so H magma complements magma by using

high C data

Materials

so as mentioned previously um H magma

complements magma so the materials are

needed to run H magma are the same as

the ones needed to run magma where the

only difference being the gene2 variant

annotation file so in this tutorial I

will walk you through how to generate

The hmac muscativic annotation file

which links non-coding um variants to

their target genes using high C

interaction

so again I will um just walk you through

how to generate The annotation file for

hmagma

Required files

so the materials needed to run hmagma

are similar to the ones needed to run

magma with the only difference being The

annotation file so to generate the H

magma annotation file you need a few

other files namely you need bed files

for Gene Exxon and promoter coordinates

Additionally you need a high C data set

in the bedp file format you will also

need an ancestry reference genome and

for the sake of this protocol we'll be

using the European ancestry

and once you have The annotation file

generated you need a Gua summary

statistics to run hmagmap

so again um the focus of this tutorial

will be on Steps A and B which walks you

through how to generate the hmag margin

to variant annotation file

Step 1 Load libraries and required data

so I have broken The annotation files

into seven different steps with code for

each step provided as part of this

recording

so the first step is to load your

libraries and all required data into a

work directory

the next step is to read in your Exon

and promoter batch files and create

genomic range objects for the Exxon and

promoter using the Exxon and promoter

coordinates from gen code version 26.

once you have this loaded and the

g-range object generated you will save

then as an R file

so similarly um you would generate a

genomic range object for all Snips using

the reference genome from the European

ancestry and you will save you also save

this as an R file in the work directory

for later use

Step 2 Overlap Snips to Gene

so in the following step um we will

overlap Snips to Gene starting with the

Exotic snips

so as a reminder the Exotic Snips are

assigned to your target genes using

positional mapping and this is because

they are more likely to impact the genes

in which they reside

so to assign the Exotic Snips to your

target genes we will overlap the gene

range for objects for Exon with

engineering objects for Snips that was

created in steps two and three

respectively

so similarly we will also overlap the

g-range object for promoters with the

g-range object that was created for the

snips

so once you have both g-range objects

created for the exons and the promoters

um these will be saved as an R file for

later use

Intergenic Snips

foreign so after um after we've assigned

the Exotic and promoter snaps to their

target genes there will be a subset of

snips that do not overlap with either so

these are known as the intergenic or the

intronic Snips so in the following steps

I will walk you through how to match

those Snips to your target jeans using

high C interaction and this is shown

here in this diagram

so to achieve this we will first

identify those in intergenic and

intronic Snips and save them as an R

file

then we will load our high C data so for

the sake of this tutorial we'll be using

high C data from the adult brain as an

example

so once you load the high C data in the

bedpie format you will generate a

g-range object for it

so we will next find snip.physically

interact with excellence and with these

set of codes similarly we will also find

snip that physically interact with

promoter with the promoter regions

so next we will combine those g-range

outlets for the exons and the promoters

to retrieve a unique um with to retrieve

unique items

so lastly we will overlap the intergenic

and the intronic Snips with high C to

identify their target genes

so once we have all these Snips um

namely the exonic the promoter the

intergenic and the intronic Snips map to

your target genes

um the last few codes that I will show

you in Step seven will be used to

generate The annotation file that is

compatible with Magma

so to achieve this we will structure The

annotation file so that it has the genes

in The Ensemble format the chromosomal

location and followed by the Snips that

is assigned to each particular Gene

so this is how you you will have um so

following these seven steps you will

have your hmac vibrant to Gene

annotation file that can be used to run

each magma for any trait or disease

so with this um you can run hmadmav for

any trade um so for here I will I'll use

an example using p um Parkinson's

disorder as an example

so this is the portion of the magma um

file the magma code that you place your

hmag margin to variant annotation file

Output files

so here I am showing you one of the

output files that you get from running

hmagma so this is the dot genes.out file

so with this file um you can actually

extract the significant genes at various

FDR thresholds for Downstream analysis

Limitations

so as I mentioned previously in the

beginning of this tutorial magma has

transformed the field of psychiatric

genetics and with each magma we can

address some of its limitations

however it is important to note that

there are still some pendant limitations

that aren't addressed using H magma

namely the directionality of effect so

even though H magma can assign Snips to

their target genes I'm using higher C

data we do not know whether the Snips

the variants are upregulating the gene

or they are doing regular down

regulating the gene so to address this

you can use various eqtl data sets to

to analyze the directionality of effect

additionally we know that not all not

all Snips are actually implicated in a

trait or disease so you need to do

further functional validation to further

prune down the list of genes

and then we also know that the sample

size of a g was greatly impacts the

number of Target genes that is

identifiable so this H magma also

suffers from this

and lastly

um lack of diversity in genetic studies

most of the analysis that we've done

with h magma has mostly been from

European ancestry however it's important

to note that you can also run H magma

for other ancestries

Conclusion

so with that um in the last slide here I

would just like to acknowledge where we

currently are with h magma so previously

we have generated H magma for brain

tissues including adult and Fetal brain

we have also added various salty

specific annotation files including

cortical

ipsc derived neurons and ipsc derived

astrocytes as well as midbrain

endopliminergic neurons however H magma

is more versatile than just brain

related cells so to expand the two we

have created additional annotation files

for 28 different cells and tissue types

to allow other researchers to use the

tool

and these cell types um are listed here

and

most of all of these annotations files

can be drum can be derived from our

GitHub page

and with that I would just like to thank

my lab as well as my funding sources

additionally I'll be hosting um a q a

section

um on October 15 2021 at 3 45 PM Eastern

Standard Time so if you have any

questions or you would just like to say

hi please drop by to see um and ask any

questions thank you

------------------------------------------------------------------------

# E-MAGMA {#sec-video3}

**Title**: E-MAGMA: an eQTL-informed method to identify risk genes using genome-wide association study summary statistics

**Presenter(s)**: Zac Gerring, Eske Derks

thank you for attending my talk entitled e-magma an eqtl-informed method to identify risk genes using genome-wide association studies summary statistics magma was initially developed to extract biological insights from g-was by linking risk variants to their nearby genes

the method assigns single nucleotide polymorphism associations to gene level associations while correcting the confounding factors such as gene length minor allele frequency and gene density while magma is a reliable and commonly used tool there is room for alternative approaches for how snips are assigned to genes for example conventional magma assigns snips to the nearest gene which is not always the most accurate approach non-coding snips can affect the expression of distal genes known as expression quantitative trait loci eqtr magma or heat magma is a modified version of conventional magma that leverages tissue specific eqtl information to assign snips to genes the genotype tissue expression project or gtex is an ongoing effort to build a public resource to study tissue-specific gene expression and regulation the current version of gtex contains samples collected from 53 non-disease tissue sites across nearly 1 000 individuals including 13 brain tissues from around 200 individuals

this diagram gives an example of how gtex can be used for the functional interpretation of genome-wide association signals the expression quantitative quantitative trait losse annotation from various tissues can be used to propose one or more potential causal genes whose regulation is either tissue shared shown in green or tissue specific shown in yellow for a

trait associated variant these associations would not be identified assigning snips to genes based on proximity alone e magma largely adopts the magma pipeline which consists of three broad steps gene annotation to assign snips to genes gene analysis to compute gene-based p-values and gene-level analysis to test the enrichment of gene-based results in curated gene sets e-magma only modifies the annotation step this is achieved by mapping significant eqtls from gtex to nearby genes in a tissue-specific manner rather than a single annotation file containing the mappings of snipster genes e-magma uses 48 annotation files one for each tissue and gtex after running gene annotation e-magman generates all intermediary files required for the gene level analysis

this slide shows the basic code for each step of conventional magma with alterations for e-magma outlined by red boxes in the gene annotation step the snip location file is altered to include significant eqtls for one of 48 tissues in gtx the tissue-specific eqtail annotation files are used in the gene analysis to generate gene-based p-values in addition to generating gene-based p-values we also generate intermediary or raw files for the gene set and biological pathway analysis

we tested the performance of e magma against other gene-based approaches including conventional magma aspertic scan fusion and summary based mendelian randomization using a simulation experiment the simulations use snip genotype information from the qimr adult twin study we excluded non-founders snips with more than one percent missingness and snips with a minor alarm frequency of less than 0.05 and we only analyze snips on chromosome this resulted in 7138nbc with around 60 000 snips eqt information was derived from gtx whole blood which included some 650 000 eqtl gene combinations for around 8200 genes phenotypes were simulated using gcta using gender type and eqtl reference data from chromosome 1. only genes with at least one significant ukchel were included in the analysis giving 651 genes and we performed 10 simulations per gene gbos on the 6510 generated phenotypes were performed using plink and we corrected the results for the number of genes in the eqtl reference set

we first evaluated the type 1 error rate across methods by calculating the proportion of genes that were significant in the absence of a true association between eqtls and phenotypic values the figure on the left shows all methods had good control of the type 1 error rate we subsequently evaluated statistical power to detect associations at a gene level for varying levels of phenotypic variants explained by uqtls we assess the proportion of significant associations relative to both the total number of causal genes in figure a and when accounting for the total number of causal genes included in each method shown in figure b e magmat have performed all methods across different proportions of variants explained by gene expression after correcting for the number of genes included in each gene based method e magma is still outperformed the other approaches

we estimated statistical power as a function of the number of eqtls per gene with one percent phenotypic variants explained by eqtls power significantly increased with the number of eqtls per gene as shown in this figure \[Music\] it should be noted that there was a significant association between the number of ekgles per gene and statistical power for all methods however e magma was less sensitive to the number of eqtls compared to the other approaches

we compared three gene-based methods e magma conventional magma and the t-was approach aspertic scan using g-wasps for major depressive disorder shown in the red circle identified 137 genes e magma the results of which are shown on the green circle identified 99 genes and desperadic scan shown in blue identified 57 genes a total of 16 genes were identified across all three methods the figure on the right shows aspertic scan minus log term p values on the y axis and e magma p-values on the x-axis with the color of the points indicating the tissue for which the gene-based dissociation was found as you can see there is good overlap between e-magma and esperidic scan and the overlap included established risk genes such as any gr-1 and team m106b

in conclusion e-magnet is an equity home formed extension to conventional magma and can be applied to any trait with g1 summary statistics e-magma map maintains appropriate controls with type 1 error rate while outperforming other methods in detecting causal associations a tutorial and input files can be found using the following github repository thank you

------------------------------------------------------------------------

# PRSet {#sec-video4}

**Title**: How to run pathway specific Polygenic Risk Scores

**Presenter(s)**: Judit García-González

Hello, my name is Judit García-González and I'm a postdoctoral fellow at the Icahn School of Medicine at Mount Sinai. Today, I will walk you through how to run pathway-specific polygenic risk scores, a tool that has been recently developed in the Polygenic Lab, either by Paul O'Reilly.

So, first of all, it's important to know what are and why it's interesting to use pathway polygenic risk scores. For that, I'm going to use one example that most of you might be familiar with, which is the PGC2 GWAS \[Psychiatric Genomics Consortium genome-wide association study based on the second data freeze\] for schizophrenia.

So, we know that psychiatric disorders like schizophrenia have complex aetiologies, where different environmental and genetic factors contribute to the liability of these traits. When we talk about genetic factors, we can imagine that GWAS is a composite of signals, where each signal might represent functional roots to disease. For example, there might be some genomic regions that harbour genetic variants associated with abnormal synaptic pruning. There might be other regions that are associated with biological pathways and processes related to immune activation, and other regions in the genome that pick up signals associated with cannabis consumption.

The idea behind pathway-specific polygenic scores is that, instead of aggregating effects across the entire genome, we will aggregate them across relevant pathways. And because we are separating the genetic contribution of a trait, accounting for the genomic structure, we hope that pathway polygenic scores might be more useful for patient stratification or to investigate the disease heterogeneity. Because now, one single individual, instead of having one single polygenic score, will have as many scores as pathways we investigate.

So, to calculate these pathway scores, I will walk you through the tool PRSet, which is an extension of the PRSice software, which uses a clumping and p-value thresholding method. It's important to know that the pathways can be any type of gene set that reflects the encoding of different biological functions. So, this tool is quite flexible to define pathways. PRSice, as well as the newest version of PRSet, have been developed by Dr Sam Choi, and you can find the software and the manual on this website: precise.info.

\[This website link does not work, but the PRSice and PRSet guides are still available online: https://choishingwan.github.io/PRSice/\]

On the website, you will find a quick start guide on how to download it, as well as some more detail about the available commands and how the method works.

So, how to use PRSet? PRSet is very similar to PRSice in terms of use, where we need as an input the GWAS summary statistics and individual-level data for genotype and phenotype. But for PRSet, we also require information about the pathways or gene sets that we want to use. As I said, the tool is quite flexible; pathways can be defined in a variety of ways, including pathways defined by existing canonical databases like Gene Ontology or Reactome, but also by experimental perturbations or some functional outputs, like gene co-expression or protein-protein interactions.

So, I'll go into a bit more detail on the different input options that are available to define pathways. One is using GMT and GTF files using the commands \--msigdb and \--gtf. The commands that are for PRSet will be shown in green.

So, MSigDB \[Molecular Signatures Database\] will contain information related to pathways, so that is the genes that form each pathway. You will need a \[GMT\] file where each pathway is specified in a different row, with all the units that compose that pathway. Then, the GTF file will contain the position coordinates for each gene. So, in general, GTF files contain different features, and by default, PRSet uses the features exon, gene, protein_coding, or CDS. But this can be modified with the command \--feature.

The second option that can be used is a BED file. In this case, you will need to include one BED file per pathway. So, if you want to include multiple pathways, then BED files can be included, separated by a comma. In the BED file, three columns are required, and those are: chromosome name, start position, and end position.

One important thing to know when using BED files is that they are indexed differently from PLINK files. So, whereas PLINK files are 1-based, BED files are 0-based.

So, you can see in this example that we have a sequence of nucleotides, and, whereas for 1-based indexing, one nucleotide is one position, the 0-based indexing will use a range around each nucleotide. So you will need to subtract -1 in the 0-based indexing for the BED files.

The input option three is a SNP \[single-nucleotide polymorphism\] list, so similar as the BED files, each pathway will be a different file, and they can be separated by a comma, as in this example here.

When you download PRSice for PRSet, there is some toy data that you can use, and these are the commands that you can use: you define the GWAS, your target sample. In this case, I'm using the first option to define the pathways. Then, you can set the number of permutations that you want to run and also the name of the output.

So, after walking you through the input, we can see a step-by-step of how PRSet calculates the pathway polygenic scores. To do that, I will compare it with the genome-wide PRS.

So, whereas for the genome-wide PRS, you clump and p-value threshold for given r^2^ and linkage disequilibrium, for pathway PRS, this will be done for each pathway separately. Then, similarly, whereas with the genome-wide PRS, each individual will have only one polygenic score, for pathway PRS, each individual will have *k* scores, for *k* number of pathways.

For the results, whereas for genome-wide PRS, what is reported is the association measured, which is the phenotype variance explained by the genome-wide PRS. In the case of the pathway PRS, there will be the same, i.e., the association of phenotype variance explained by each pathway PRS. But you can also report enrichment of GWAS signal in the pathway, which is based on R^2^ of the pathways.

So, I'll go a bit into more detail about these two different methods that PRSet can output. So, when we are talking about association, what PRSet will output is the self-contained p-value. It's just the regression of the phenotype on pathway PRS and covariates. So, pathways that have many genes, containing SNPs that are associated with the phenotype, are highlighted here in pink, and those will be significant. But it's important to note that for these results, the self-contained p-value does not account for pathway size. And for example, a large pathway will be more likely to be significant because it's easier to have a larger number of SNPs associated with the phenotype.

But the second output that we can have is this enrichment, that will be output as competitive p-value. This is resulting from a permutation procedure, and this will test whether a pathway is more associated with the phenotype compared to null pathways that have the same size. So, in this case, with the competitive p-value, we'll be accounting for the size of each pathway.

In this plot, I'll illustrate how we calculate this competitive p-value that accounts for the pathway size. We can imagine a pathway A that has some SNPs in the genic region of the pathway, and for which we will calculate an observed p-value. Then, we will calculate as many null pathways as permutations we run, and these null pathways will have the same number of false clumped SNPs as pathway A, but these SNPs will be randomly allocated. So, we will obtain a distribution of null p-values. Because its power will give us a p-value of the association, the competitive p-value will be defined as the number of tests under the null that have a p-value smaller than our observed p-value + 1, divided by the number of tests performed + 1.

So, this is how the competitive p-values are calculated. This approach and this output is similar to the type of enrichment analysis that are performed by MAGMA and LD Score regression, but pathway PRS have the advantage that they provide individual-level data that can be used for other applications.

So, let's see how the output of PRSet looks like. Similar to PRSice, for every PRSet run, we will have a log file, with extension .log, and this will contain the commands used for the analysis and all the information regarding the filtering, the fields that were selected, etc.

Then, we will have another file, with extension .precise, and this will contain the polygenic model for each pathway across thresholds. So, in this case, I was running only the threshold 1, which contains all the SNPs. But you can see that there is information for each pathway: the R^2^, the self-contained p-value, coefficient for the regression, standard error, and the number of SNPs. You will always see this base pathway, which is the background pathway used for the competitive p-value calculation.

Then, we have the .best file, which will give us the scores for each individual and each pathway. So here, each row will be one individual, and then the score for each pathway will be indicated in a separate column. So, there will be as many columns as pathways you are using. In this case, we see four examples from the KEGG \[Kyoto Encyclopedia of Genes and Genomes\] database. If you wanted all the scores at all p-value thresholds, because this .best file will report only the one with the best p-value threshold, you can use the command \--all.

Finally, we will have another file with extension .summary that will have the information of the best model fit of each phenotype pathway. And in this case, each pathway will be a row. And then, it will contain, again, information on the R^2^, null p-value, coefficient, and also this competitive p-value that I was talking about, that will indicate the enrichment of this pathway compared to other pathways of similar size.

Finally, I would like to leave some heads up and useful commands. So, for example, some commands that might be useful for the user is the window size, which is like, for example, if you are defining SNPs that are within a gene, you can extend that window. And so, you can include some number of N bases to the 3' region of each gene or to the 5' region of each gene. You can also exclude SNPs that are within a certain range with a command \--x-range. So, for example, the MHC \[major histocompatibility\] complex or the *APOE* region if you want to do some Alzheimer's analysis and you want to exclude that one.

If you want to improve the computational efficiency of PRSet, you can parallelise the process using the \--thread command. You can also speed up a little bit of PRSet at the expense of an increase in memory using the \--ultra command. Additionally, you can use the \--keep and the \--extract commands to exclude individuals or SNPs from the analysis.

If you are doing permutations to calculate the competitive p-values, this can be computationally intensive. So, it might be useful to adjust for the covariates like sex or age beforehand on your phenotype and then use the residuals as the phenotype because this will speed up the process.

So, this was this quick introduction to PRSet. Thank you for listening. If there is anything that is not here or you have any questions, there is a Q&A session on the 15th of October at 11:30, and this is the Zoom meeting ID. So, I'll be happy to clarify or answer any questions. Thank you.

\[Please note that this is an archival recording and the information about the meeting pertains to a past event.\]
