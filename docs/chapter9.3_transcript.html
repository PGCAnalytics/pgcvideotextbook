<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>PGC Video Textbook - Chapter 9.3: 9.3 Genomic Structural Equation Modeling (Video Transcript)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PGC Video Textbook</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./contact.html" rel="" target="">
 <span class="menu-text">Contact us</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://pgc.unc.edu/" rel="" target="">
 <span class="menu-text">PGC Website</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Chapter 9.3: 9.3 Genomic Structural Equation Modeling (Video Transcript)</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./pgc_logo_website_v3.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="">
            Source code
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="">
            Report a bug
            </a>
          </li>
      </ul>
    </div>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to the PGC Video Textbook!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Table of Contents</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Chapters</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: The Genome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Technologies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Study designs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: GWAS analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Polygenic Scores</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 7: Ancestry-Specific Analyses and Considerations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 8: Post-GWAS bioinformatics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 9: Advanced Topics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 10: Other Considerations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Software Tutorials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_cnvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNVs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_conditional.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conditional Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_crossdisorder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cross-disorder Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_ewas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EWAS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_geneset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gene Set Identification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GWAS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_genomicSEM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Genomic SEM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_MR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mendelian Randomization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_prs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PRS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SNP Heritability and Genetic Correlation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Additional Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Glossary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Software Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./addreading.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Additional Reading</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://pgc.unc.edu/for-researchers/download-results/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PGC Summary Statistics</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#genomic-sem-introduction" id="toc-genomic-sem-introduction" class="nav-link active" data-scroll-target="#genomic-sem-introduction">Genomic SEM Introduction</a>
  <ul class="collapse">
  <li><a href="#sec-video1" id="toc-sec-video1" class="nav-link" data-scroll-target="#sec-video1">Genomic Structural Equation Modeling: A Brief Introduction</a></li>
  </ul></li>
  <li><a href="#running-genomic-sem" id="toc-running-genomic-sem" class="nav-link" data-scroll-target="#running-genomic-sem">Running Genomic SEM</a>
  <ul class="collapse">
  <li><a href="#sec-video2" id="toc-sec-video2" class="nav-link" data-scroll-target="#sec-video2">Short Primer on Structural Equation Modeling (SEM) in Lavaan</a>
  <ul class="collapse">
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul></li>
  <li><a href="#sec-video3" id="toc-sec-video3" class="nav-link" data-scroll-target="#sec-video3">GenomicSEM: Input</a></li>
  <li><a href="#sec-video4" id="toc-sec-video4" class="nav-link" data-scroll-target="#sec-video4">Examples on the Genomic SEM wiki</a></li>
  <li><a href="#sec-video5" id="toc-sec-video5" class="nav-link" data-scroll-target="#sec-video5">Multivariate GWAS in Genomic SEM</a>
  <ul class="collapse">
  <li><a href="#section-1" id="toc-section-1" class="nav-link" data-scroll-target="#section-1"></a></li>
  </ul></li>
  <li><a href="#sec-video6" id="toc-sec-video6" class="nav-link" data-scroll-target="#sec-video6">Using Genomic SEM to Understand Psychiatric Comorbidity</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 9.3: 9.3 Genomic Structural Equation Modeling (Video Transcript)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<hr>
<section id="genomic-sem-introduction" class="level1">
<h1>Genomic SEM Introduction</h1>
<section id="sec-video1" class="level2">
<h2 class="anchored" data-anchor-id="sec-video1">Genomic Structural Equation Modeling: A Brief Introduction</h2>
<p><strong>Title</strong>: Genomic Structural Equation Modeling: A Brief Introduction</p>
<p><strong>Presenter(s)</strong>: Andrew Grotzinger</p>
<p><em>Introduction</em></p>
<p>In this first video, I want to provide a brief overview of genomic structural equation modeling, including some of the background and motivations that led us to develop this package.</p>
<p><em>Graphs</em></p>
<p>I’m going to start here by showing these two different graphs that show on the X axis, the discovery sample size from different GWAS studies and on the Y axis, the number of hits identified in this studies. And what you’ll notice is that as the sample size have increased, we have begun to identify hundreds if not now, thousands of different genetic variants associated with both complex traits like height and BMI and disease traits, like Crohn’s disease and prostate cancer, which really reflects this gradual realization that we’ve had in human complex trade genomics, that many of the outcomes that we’re interested in are highly polygenic, meaning that they are associated with many genes and not just some small handful of core genes. For those of us that are interested in the shared genetic relationships across traits this comes with the caveat that it’s not simply a matter of identifying the five or six overlapping genes.</p>
<p><em>Limitations</em></p>
<p>So for my self, as somebody who’s interested in clinical psychology outcomes, I couldn’t simply look at these two Manhattan plots for schizophrenia and depression, which just to orient you to these, to the chromosome on the X axis and the negative log 10 P values with values that are higher up over here indicating genetic variants that are more significant. That I can’t just count up the ones that are above this red dash line here for genome-wide significance. Cause there’s simply too many. So we needed at some point to develop methods that find ways to estimate the aggregate shared information across these really polygenic outcomes.</p>
<p><em>LD Score Regression</em></p>
<p>And thankfully A team from the Broad, including some people who are talking at this workshop developed this method called LD score regression which can be used to estimate genetic correlations across participants samples with varying degrees of sample overlap, using what is often publicly available, GWAS summary data. As in, you can go online right now and directly download that data without going through any sort of strenuous request process or going through an IRB.</p>
<p><em>Genetic Heat Maps</em></p>
<p>When LD score regression is applied, it can be used to produce what is often referred to as genetic heat maps. Two of which are shown here. So on the left, we have the genetic correlations estimated across psychiatric phenotypes with the squares that are shown with darker shading, indicating stronger levels of genetic overlap. And of course the squares on the diagnoal and all are shown in dark blue because that indicates the genic overlap of the phenotype with itself. So you see that across a number of these disorders, that there are high levels of genetic correlation. And that this is also reflected in general brain and behavioral, cognitive phenotypes shown this heat map over here on the right. And so this reflects one of the second things thatwe’ve realized in human complex trait, genetics, which is that there is both pervasive, polygenicity, which is say that the traits are affected by many genetic variants and there’s pervasive pleiotropy, which is to say that many of those variants are actually shared across traits. And this shared genetic architecture that we can see depicted here in these heat maps is really what motivated myself and others to come together and develop methods that allow us to actually analyze that joint genetic architecture. So again, genome-wide methods are clearly suggestive of these two things, high polygenicity necessity, and pervasive pleiotropy. And we’ve viewed genetic correlations as data to be modeled. We want it to be able to ask what kind of data generating processes give rise to these correlations and how can we use publicly available data, to examine systems of relationships, to really start to interrogate that data more. And so that what led us to develop genomic structural equation modeling, which we introduced in this nature, human behavior paper that involved a lot of key members on the team. But I’ll specifically highlight Michel Nivard and Elliot Tucker-Drob, who supervise this project and continue to work with me to develop extensions on it and of course, Michel is also one of the people presenting here.</p>
<p><em>Genomic SEM</em></p>
<p>So our solution to this problem of how we model the genetic correlation matrix is genomic SEM which applies structural equation models to these estimated genetic covariance matrices, and then allows the user to examine traits that oftentimes could not be measured in the same sample and it provides a flexible framework for really estimating a limitless number of models using only these GWAS summary statistics. That again, can be applied to summary stats or what is often referred to as sumstats with varying and unknown degrees of sample overlap.</p>
<p><em>Example</em></p>
<p>I just want to focus on one specific example for time reasons related to my main interest in clinical psychology and this reflects our most recent application of genomic SEM to psychiatric outcomes, where we produce this genetic heat map across 11 major psychiatric disorders. And what you see is there’s a pretty high level of genetic overlap across these disorders. And what is really unique about this is that many of these disorders cannot be measured in the same sample. So bipolar disorder and schizophrenia, the way that we structured our clinical diagnoses, you can’t have that same set of disorders within the same person. You’re either assigned one or the other based on your presentation. And so that means we’ve been limited in clinical psychology research to making inferences about what is shared across these disorders based on patterns of findings from separate samples. Where now for the first time, genomic SEM offers this unique opportunity to actually model the set of relationships across these rare and even mutually exclusive clinical presentations. Because again, The summary statistics that were used to produce this heat map are not from the same sample, but instead reflect the aggregate summary level data from these different cohorts . When we then applied genomic SEM to model these relationships, we found that a four factor model fit the data best. And this actually mapped on pretty well too some level of what we might expect based on the clinical presentations of these disorders. So for factor one, we have anorexia obsessive compulsive disorder and Tourette’s syndrome that we might characterize as being really defined by this kind of compulsive, like presentation. With the psychotic disorders of schizophrenia and bipolar disorder. What we’re calling a neurodevelopmental disorders factor because it’s defined primarily by ADHD and autism, but also notably includes PTSD and alcohol use disorder. And then this internalizing disorders factor over here that includes MDD, anxiety and PTSD. And I would note that these factors are all correlated, but they also segregate into these more tightly defined clusters of sets of disorders, giving rise to some level of understanding about what is shared across these specific subsets of psychiatric presentations. We can also use genomic SEM to examine individual SNP effects on the factors. And so when we then apply what we referred to, as multi-variate GWAS to these factors, it can be used to produce these 4 Miami plots here. Where I’m depicting with the black triangles, the GWAS hits that overlap with the univariate hits and in red triangles, the GWAS hits that were actually not hits for the individual disorders. And this is reflecting that by leveraging the shared information across the disorders that define the factor, without collecting any new data, we can actually discover new genetic variants associated with these factors. On the bottom half of these Miami plods, I’m showing the effect of Q SNP which is a heterogeneity index that we’ve developed that is designed to pick out those genetic variants that do not fit the factor model. As a classic example, we generally pull out the ADH1b gene that is associated with alcohol use disorder, specifically as something that is a Q SNP variant, which is to say that this is something that does not operate via these more general factors, but it’s highly specific to alcohol use disorder. And we’ll talk more about Q SNP in some of these later videos it was. And so sales pitch to genomic SEM I think one of the really. Amazing opportunities that genetics and genomics SEM building on methods like LD score regression presents is the ability to examine systems of relationships across a wide array of rare traits that could not be measured in the same sample. To give an example of research question, you might have that you could not do outside of a genetic space.</p>
<p>Let’s say that you’re interested in the genetics of early and late onset schizophrenia and anorexia nervosa. You have some sense of research literature that indicates that a particular onset stage of anorexia nervosa can sometimes contain a psychotic like presentation and you also recognize that these things can have distinct developmental onset periods that means something about the course of these diseases. And so you want to look at this cross-lagged model that examines the systems or relationships across these presentations within the disorder and across these two disorders.</p>
<p>You could collect a sample where you look at the relationship between early onset schizophrenia and anorexia nervosa and in the same vein, late onset schizophrenia and later onset anorexia nervosa. But that would take you a long time to collect just because of how rare these two disorders are. What you could not do is look at the relationship outside of a genetic space between the early and late onset versions of the same disorder. But again, when GWAS summary data, you could split the GWAS data by age of onset and then you could estimate the genetic overlap of the signal between the early and late onset versions of this disorder and so now with genomic SEM You can actually estimate this model and answer these sorts of research questions that again, would not even be possible outside of a genetic space.</p>
<p><em>Summary</em></p>
<p>This final slide is just to highlight the different ways in which genomic SEM has been used. Including some work that I’ve been involved in, but also works from other outside research groups that are published in high-impact journals, like molecular psychiatry, nature genetics, cell, and nature human behavior. I really hope that some of you see some opportunity to use genomic SEM in your own research. In the next videos, we’ll talk more about how structural equation modeling works and provide some hands-on examples of how to apply genomic SEM to actual genetic summary data.</p>
<hr>
</section>
</section>
<section id="running-genomic-sem" class="level1">
<h1>Running Genomic SEM</h1>
<hr>
<section id="sec-video2" class="level2">
<h2 class="anchored" data-anchor-id="sec-video2">Short Primer on Structural Equation Modeling (SEM) in Lavaan</h2>
<p><strong>Title</strong>: Short Primer on Structural Equation Modeling (SEM) in Lavaan</p>
<p><strong>Presenter(s)</strong>: Andrew Grotzinger</p>
<p>In this video, we’re going to talk about some of the basics of structural equation modeling and more specifically how to do&nbsp; structural equation modeling and Lavaan which is the art package that genomic SEM uses to estimate the models.</p>
<p>To start, let’s go over some of the basic model syntax for Lavaan, beginning with how to specify a regression relationship, which you could write as Y till the X, which visually depicted as a path diagram would mean X predicting Y with this single headed area. And depending on how you think about variables in your model, you might think of that as reflecting a ~ DB. Dependent ~ the independent outcome ~ predictor. But of course he would name these according to the actual names of the variables in your data set. This is just to drive home the point that the outcome is on the left-hand side of this equation and the predictor is on the right-hand side of the, ~ the over here. To specify a variance of a variable. You would write the name of that variable twice with two ~ in between. So X ~~ the X would specify the variance of X or the covariance of X with itself to specify the covariance between two different variables you would also use two ~ and on the right-hand side, you would write the name of that second variable in this case, Y. Which is a path diagram would reflect this two headed arrow between X and Y. And then the standardized case would of course reflect the correlation between these two variables.</p>
<p>To specify factor loadings which refers to the regression relationships between this unobserved lightened factor and these observed variables, a through E, which we’ll talk a little bit more about later in this presentation, you would write F and then equal sign ~ and then a through E you can name the latent factor however you want. In this case, we’ve just called it F and of course, A-E should again, reflect whatever the names of the actual variables are in your data set but this is generally speaking the schematic for how you would specify the factor loadings in a model. Just a note to say that the default behavior in Lavaan&nbsp; is to fix the loading of the first variable to one and this is necessary because since F is not a variable in your dataset, Lavaan and structural equation modeling more generally needs some sort of anchoring point so that it knows what kind of scale to put this latent factor on. So again, unless you tell it to do otherwise, Lavaan we’ll fix that loading for the first variable to one. So it knows how to scale the latent factor. And as another note, just in general and structural equation, modeling squares are used to depict observed variables, such as the variables here for A through E and circles are used to depict an observed or what is often referred to as latent variables. And that can include latent factors like the latent factor F over here or, for example, the residual variances of observed variables where the observed variable is something that is observed in your data set and the residual variance is not. And so for that reason is generally depicted as a circle.</p>
<p>To fix a parameter in a Lavaan model, you would write the value that you’re fixing it to on the right-hand side of the equation, followed by an asterisks, and then whatever variable name comes on that side. You always put the value you’re fixing into on the right-hand side. So you would not write one star X, ~~ Y but what this specifically does here is it fixes the covariance in between X and Y to one. You can also name a parameter in lavaan and to do that, you also put an asterisks on the right hand side of the equation, but then, you would also include whatever you’re naming that parameter, which should just be some set of letters. So I could call this dog, cat, a, rain drop. You just have to name it something that doesn’t overlap with the actual names of the variables in your dataset. So this names, the covariance between X and Y to be a, and that’s useful because then you can, in the later part of your model use what is referred to as model constraints for a particular parameter. So let’s say that for some reason, you know, that X and Y is covariance should be above zero, but you don’t know exactly what that number should be. So you’re not fixing the value to anything in particular, but you are telling the lavaan that that value should be above this particular number of .001. Just a cautionary note on naming parameters, I’ve seen a number of people use the same parameter label for multiple parts of the model and oftentimes this was done unintentionally on their part and the reason that that can is a problem is because when you name it with the same label, a here, that’s not just naming the covariance between X and Y. And the covariance is between Y and Z. It’s also telling Lavaan that you want to fix these two covariances to be estimated at the same value. So if you do want to name multiple parameters in the model. You just want to make sure to name them different things, unless you are intentionally trying to use what is referred to generally as inequality constraint. So this is a, what not to do unless you are trying to make these parameters be the same. Having reviewed all of these Lavaan basics. And I just want to go through some of the concepts and basics of structural equation modeling, and then continue to use this lavaan syntax along the way as we review those basics.</p>
<p>To start, I want to Begin in this hypothetical space where we’re talking about a situation that we would not run into in which we actually know what the relationships are between the variables. So here let’s say that we know that the regression relationship between X and Y is 0.4 and that Y as a residual variance of 0.84, which would imply this particular set of relationships were Y equals 0.4 times X plus this residual U. If we extend that out to say that, right we know that Y causes Z of 0.6 that would add on this additional notation of Z equals 0.6 times Y plus U. And so this would imply a particular covariance matrix in the population. This set of relationships where this isn’t a standardized space on the diagonal we have the variances of the variables, which are one. And then on the off diagonals, we have the Relationship between X and Y at 0.4, between Y and Z of 0.6 and the relationship between X and Z in a structural equation model. And this case would be 0.4 times 0.6 or .24. In practice, we, of course don’t have access to the covariance matrix in the population, but instead we have a particular covariance matrix within a sample, which is intended to be a rough approximation of the population that we’re interested in studying.</p>
<p>And so again, in practice, we have this observed covariance matrix in our sample. Instead of knowing these relationships, we’re then flipping that process on its head. And we’re saying that we want the model to pick the values within this system of relationships that we’ve specified that most closely, approximate the covariance matrix in our sample. With an structural equation modeling. You’ll hear people talk about the degrees of freedom at the model, and that refers to how many parameters you estimated relative to how many parameters you could have estimated given the unique elements in the covariance matrix. So for three variable covariance matrix, you have six unique elements which refers to the three variances on the diagonal and the three covariances on the off diagonal. And in our model, we’ve only estimated five of those parameters where specifically we did not estimate the regression or covariance relationship between X and Z. So that means we have one degree of freedom and can be thought of as specifying a model that provides a more parsimonious or simplified set of relationships relative to what we observe in the data. To specify this model Lavaan using that notation that we just went over for the regression relationship between X and Y. We would write Y ~ X over here in blue and for Y and Z the same thing, but Z ~Y.</p>
<p>So in practice again, what lavaan and what SEM softwares are doing more generally is they’re taking this observed covariance matrix and the system of relationships that you’ve specified and they’re picking the numbers that get as close as possible to that observed covariance matrix, which in this case would be.35, and 0.61. And that would imply a certain covariance matrix. And the level of difference between these two matrices is often what is used to produce what is referred to as model fit, which&nbsp; is something we’ll talk about in later videos. As we talked about earlier, you can also specify latent factors in a data set, which reflects the shared variation across a certain set of variables, such as Y one through Y five here. And I would just note that we’re actually employing a different notation than we used earlier, where were specifying the factor loadings again with the name of the factor F =~ And then the name of the variables that define the factor, but we’re overriding that default Lavaan behavior to fix the indicator the first variable to one by writing NA*Y1, and then we’re instead anchoring that part of the model or scaling it by telling Lavaan that we want to fix the latent variance of the factor to one. So we’re using what is referred to as unit variance identification instead of what we used before, when we fixed the loading of Y1 to one, which is referred to as unit loading identification. Not something that you need to keep in your working memory at all times, but just something for you to know as an option. And this particular part can be important if you’re specifying, let’s say correlations between factors, where if you set the variance of the factor to one, then that means they’re on a standardized scale and you can interpret those relationships as correlations.</p>
<p>Now here, we’re just showing what if you want to expand this out to include the relationships between two latent factors. And so again, in Lavaan syntax, you would right for the latent factor F1 here this part of the model here in blue F1 =~Y1+Y2+Y3+Y4+Y5 the regression relationship between F2 and F1 this part here in purple and for the latent factor model for Factor 2, F2=~Z1+Z2+Z3+Z4+Z5. What genomic SEM does is it uses the principles of structural equation modeling to fit a model to the genetic covariance matrix. So it’s a two-stage process where in stage one, that genetic, covariance matrix and its associated matrix of standard errors and their co-dependencies are estimated where we specifically use LD score regression and stage two, we fit that structural equation model to the matrices from stage one using Lavaan and the basic principles of structural equation modeling. I know this was a fairly brief overview, but hopefully it provided the basic notation to use Lavaan syntax and understand a little bit about what the SEM process looks like. And so in the next talk, we’ll go over how it is that we actually estimate this genetic covariance matrix and that set of standard errors.</p>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<hr>
</section>
</section>
<section id="sec-video3" class="level2">
<h2 class="anchored" data-anchor-id="sec-video3">GenomicSEM: Input</h2>
<p><strong>Title</strong>: GenomicSEM: Input/Explaining how S and V are estimated and what they are</p>
<p><strong>Presenter(s)</strong>: Michel Nivard</p>
<p>What goes into genomic SEM before you can actually fit a structural equation model. So it’s basically a class on how the sausage&nbsp; is made, right? So some of these things are details that are good as background, Good for you to understand, once you use genomic SEM. But basically stuff that’s largely handled by internal functions of genomic SEM. so it means you don’t have to do &nbsp; anything like this by hand and to discuss what goes into genomic SEM. It’s good to discuss two other things. Namely, what kind of information goes into a structural equation model in general? Right. You can use raw data, but you could also use the covariance matrix of the raw data to fit the structural equation model or a regression model, as we’ll see in the example. And it’s good to discuss what LD score aggression is exactly. It’s a very commonly used technique to estimate genetic co-variance and or heritability. And it actually is one of the main ways genomic SEM can estimate from raw GWAS data. So raw, summary statistics the genetic covariance between traits and the heritabilities, which you can then use to fit a structural equation model too. Okay. So first we’ll discuss what kind of information goes into a structural equation model. And, show you that basically you can either use raw data to get a structural equation model to work, but you can also use, the covariance matrix of that raw data. And that’s an important conceptual step, right? Because if you understand that you can later understand why we can fit structural equation models while we don’t observe any raw data in genomic SEM. And with raw data. I mean, phenotypic observations, we don’t observe those at all in genomic SEM. The only thing that goes in is the GWAS summary data.</p>
<p>So now we’ll switch over to, R and i’ll through a little example in which I create a dataset and then fit a structural equation model. And then I’ll take only the covariance matrix of the dataset and fit the same structural equation model to illustrate. what goes on in such an example, I didn’t really clear my workspace before, so let’s do that so we have a fresh start. The first thing we’ll do in this, R script this we’ll will require some, packages I need to generate some data and to fit structural equation model. So the mass package allows me to generate data from distributions and lavaan will allow me to fit structural equation models. Okay, then we’ll run these, we’ll also run this line, which States that variable N is 10,000 we’ll use the variable N for sample size all throughout the example. Then we’ll generate three random variables, X one X, two, and X three. And we’ll also generate random variable, Y which is a function of X one X, two X three, and some residual variance that’s not attributable to all those variables. So what does variable Y look like something like this, what does X one look like? Well X one was normal, right? This, we just generated from a random, normal variable. This is what it looks like. Okay. We’ll combine all those variables into a dataset, right? The dataset just keeps together all the variables in one place. Now the variables also have a relationship because that’s the way we define them. Right. So we could make a plot of Y against X one, and we’d see there be some sort of&nbsp; relationship where if X one is higher, Then Y is also, which is exactly what we expect given that we just made Y a function of X one. Right? Okay. Now on these data, we can fit linear regression model, which I do right here in which we regress Y on X one on X two, and X three. And we know what will come out of the linear regression model. Why? Because we just defined the relationship between Y and X. Right. We defined the relationship as Y being equal to 0.4 times X one, .5 times X two and minus 0.2 times X three. So if you run the model, Oh, I forgot to run the ‘dataset’ line, this is instructive. You know, when you, when you, when you’re programming, you’ll always make mistakes. I’m not going to cut it out of the video. Cause I think it’s instructive to know just that we also had just, you know, messed this up all the time. Maybe it’s not that instructive, but I messed this up all the time. Okay. So now I’ve run the lines we need to, to run a linear model, as you can see, this is the way you would define a model in R Andrew has a video up on how you can define Models in lavaan, but in R, the regression model uses a tilde as an equation sign and “+” to add additive terms. And so this linear model using the function, LM it’s fit, linear regression, and we can get a summary using the summary function, applied to the object in which the linear model is stored. Now, as you&nbsp; may expect the coefficients we get from the model are very close to the values we use to generate the data their not exact because generating random data, also introduce a slight bits of noise. so X one gets an estimate of point 40, which is its true value. Thereabouts, X two gets point 49 , while the true value is 0.5 and then X three gets minus point 16 while the true value is minus 0.2 so they’re all close to there, true value, which is great. the linear model works, which is, I guess not entirely unexpected, you can fit the linear model. The same model; whoops, spelling error. You’ll get this code by the way. I’ll make sure it’s available. You can fit the same model in lavaan using dis as a, as a descriptor of the model. Okay. Andrew went through the syntax for lavaan. So you should be able to understand this, but I’m going to read it out. Anyway. It basically defines one regression. Y is regressed on X one X, two and X three, and then explicitly defines the covariance between X one X two X one X three. And actually I just noticed it should also include the covariance between X two and X three okay. And then using “sem()”, which is the lavaan function and adding the dataset, we created, the raw data the the observed data, to the data argument we can fit the SEM model and let’s have a look. Now, a structural equation model is capable of estimating the same parameters as&nbsp; a regression model. So here you go. Y regressed on X 1, 0.4 Y regressed on X 2 point 49 and Y regressed on X 3 minus 0.16.</p>
<p>So, this is just a very convoluted, indirect way to fit the same model. Now notice, because this is a, this is a structure equation model we could fit many, many more models with these, four variables, we’d be flexible. We could, we could say: “well, actually, Y is an outcome of X one, two and three, but we suspect X two to be an outcome of X three.” Right. And we could fit a mediation model in which Y is regressed on all three variables. And the X two was regressed on X three. we could define that model and we could see what the parameter fit is. That’s the flexibility you have in lavaan or a structural equation model, or later in genomic SEM, but which you don’t have in a linear regression model. That’s not the point of this tutorial. So let’s get back to the point.</p>
<p>I can create the covariance between the variables in the dataset using cov() function in R right? And I’ll get this object Sigma, which has the covariance in it. Now, if we look at Sigma, we’ll see a matrix with covariances between Y and X one and X two and X three. Okay. We can actually feed that covariance matrix. To lavaan so we use the same SEM function, the same model. Now, instead of giving it raw data, we’re giving it the covariance matrix and we’re giving it the number of observations because it needs to know how precisely all the elements in the covariance matrix are fit. And we can run these and we’ll get exactly the same or very similar outputs.&nbsp; Right. It is, I am running this on SEM model 2. Right. So is this the model that doesn’t know about the raw data just knows about the covariance and, you get the same regression parameters. Now, this works because in A SEM model you defined a covariance, the cells of the covariance matrix in terms of the regression parameters. And then you ask the model to seek out the regression parameters that minimize the distance between the observed covariance matrix in the data and the covariance matrix implied by the model. And so we don’t need the raw data we could do with the covariance. Now it’s nice to have the raw data, because sometimes you have missing data points or other sort of things going on where there’s extra information hidden in the raw data. That’s not hidden in the covariance matrix. So it many cases it’s, it’s far more valuable to have to raw data, but if you don’t, you can fit these kinds of models on the covariance matrix.</p>
<p>Okay. Let’s go back to the presentation. So when you go over to that, you can, fit structural equation model based on the covariances only. And that’s a valid input for, a structural equation model. Now the input for genomic SEM are genetic covariances, which we get from GWAS summary data, right? So only from a vector of each SNP “rs” number the effect alllel, so which of the two alleles is actually increasing or decreasing the trades the Z statistic associated with that allele so that’s the statistic of the linear regression association in the GWAS, and that’s all, all we’re puttingin to getting the covariances. Now we’ll get those genetic covariances and heritabilities. Using LD score regression now, what is LD score regression? LD score regression actually tries to explain the signal that is created in a GWAS. So this is a Manhattanplot of a GWAS of schizophrenia and these hits highlighted in green. They only explained 4% of variability, but the heritability, according to twin studies, Is 80%. So how do we go about explaining the rest? So if we visualize the same GWAS as a QQ-plot, we’d see that the observed P values are much smaller.so therefore the minus log P values are bigger than what is expected under the expected distribution of a Z statistic, and so the question we ask is, is this, this inflation right? Is this true signal or is it type one error that we’d like mess something up that we’re getting all these false positives. And that’s the question we’re asking ourselves when we’re using LD score regression. And so just really important ingredient for LD score regression is the, the LD structure of the genome. So what I’ve tried to depict here is a part of the genome and each dark. Blue square is a SNP and the lighter blue squares depict the correlations between the adjacent SNPs and LD introduces correlations between adjacent SNPs, which I’m sure has been covered in the days before this person, patient. This also is what creates these towers in, in Manhattan plots right? Because. If one of these SNPs is associated truly with the trait, then then do to LD other ones become correlated with the trade. So you can summarize these LD patterns into a score, which is basically for every SNP, just the sum of its LD with all its neighbors. That’s basically to reflect how well the SNP is correlated to all the SNPS around it, and then consider there is a true genetic effect. Right, so on the left you can see I called this beta. So it’s a true effect. So none of these SNPs has an effect, except for this one, it has a tiny effect. If this were the true effect and we were to do a GWAS, we would get estimated betas, and so we get something like this where we estimate the beta&nbsp; for the SNP with the true effect to be non-zero, but also for all the SNPs that are in LD with the SNP, with the true effect, we’d expect a estimate of beta. Those are sort of raised. Now, what happens on the genome wide scale is that those test statistics you could derive from, from the linear regression of a trait on every SNP, they go up for SNPs that have more LD and they’d go up precisely because. So many SNPs in the genome are associated with the traits, right? ” that if you “tag” more SNPs as a SNP, you are more likely to tag more true causal SNPs, and therefore your that’s, your signal goes up and your test statistic goes up and it goes up in a very specific fashion. It goes up proportional to the heritability, to the number of with a true effect M, and with the sample size, right? Because Power goes up when the N goes up. And so if the sample size goes up, the relationship between test statistics and LD scores goes up as well.</p>
<p>So, and by the way down, there are Hilary Finucane, Brandon Bulik-Sullivan, Ben Neale, and Alkes Price, who basically wrote the first few papers on this relationship. So going back to the little squares i made the Chi square statistics you get from your GWAS they are regressed on LD scores, which reflect how well each SNP tags it’s neighbors SNPs that tag more neighbors are expected to have higher test statistics. And then the slope of that regression is reflective of the heritability because the other big unknowns in that equation sample size and M are known to us, right, because we know how big the GWAS was, and then there’s an intercept which actually reflects things that do not correlate with LD scores such as population stratification. Which is a very neat feature. So now we can separate the true signal from the signal introduced by population stratification.</p>
<p>So how did they go about validating this? They actually did a GWAS of Swedish controls versus UK controls. So neither of these sets of people have this disease, but they different mainly in their ancestry. And as you can see on the right hand side the QQ plot of the GWAS, it does look inflated. It does look like there is signal there that is inconsistent with the distribution of test statistics under the null, however, if they plot the LD score, Of all the SNPs, in bins against the death statistic in these bins, then there’s no relationship. In other words, the test statistic doesn’t go up with the LD, which means the signal is probably not a function of heritability, but a function of something else in this case, population stratification.</p>
<p>Now, if you do it with the real&nbsp; GWAS, like the schizophrenia GWAS we’ve discussed you see that there is a steep and consistent correlation between the LD score bin a SNP is in the mean chi square the SNPs in each of these bins have. So the relationship is strong and it’s actually consistent with a SNP heritability for schizophrenia of like 40% and 90% of the signal is true. Okay. So that’s how we get an estimate of heritability, GWAS summary statistics, the slope estimates, the heritability. And if we have two traits, we get two slopes, but can also, instead of using chi square test statistic, used a product of the Z statistics of the two traits, regress that on the LD score to get an estimate of genetic covariance between traits. So, this is an example where the rg is 0.5. We got a slope consistent with that RG genetic correlation. And this is an example of why the RG is zero. We get a slope consistent with there being zero correlation. Okay. And it’s robust, this, this entire technique to sample overlap between the GWAS. Now, why is that? Because this intercept in the case of genetic covariance will actually absorb the sample overlap. So it’s&nbsp; great. We can use GWASes from the same sample to estimate genetic correlation between traits or we can use entirely different samples, so we can correlate some MRI study to some metabolite study. Right. And that’s insightful because it’s really expensive to measure MRI and metabolites in the same. People and not always feasible.</p>
<p>Okay. Phase three of this lecture, what kind of information goes into a genomic structure equation model? Well, so these heritabilities and genetic covariances, we have estimated are actually assembled into a matrix S which holds the genetic variance covariance matrix. So the top left entry is the heritability, the first trait and all across the diagonal, we get heritabilities of the other traits and the off diagonal entries are the covariances between the traits. Now as we’ve seen at the very beginning of this lecture, a covariance matrix is sufficient to estimate a structural equation model. However, if we use a covariance matrix to estimate a structural equation model in lavaan, we need the sample size. Now these estimates don’t necessarily really have a sample size. Yes, the underlying GWAS has a sample size, but that doesn’t translate directly into a precision or standard error for these heritabilities. And so we need that information to be presented in a different way. So for every entry in this matrix, S we actually need to know it’s standard error or its variance, and we also need to know the covariance between the different estimates. Right. So imagine I estimate the heritability off height and BMI in one sample then those two heritability estimates are interdependent, right? Because it’s the same people in that sample that feed into those two estimates, and that dependency needs to be taken account off. That’s what we do in constructing this matrix V which basically has the squared standard errors or the variances off the heritabilities and genetic covariances on, on the diagonal. So all the elements of S have a diagonal element in V that corresponds to their standard error or their squared standard error, or variance. And then the off diagonal elements in V are actually the dependencies between the elements of S at this matrix takes a while to compute, but it’s basically computed in a very smart fashion that’s called Jack knifing in which we basically estimate the LD score regression in chunks of the genome, 200 chunks of the genome. And then we sample from those 200 chunks of the genome. We sample combinations of 199 chunks, and we estimate the matrix S 200 times. Each time omiting a different part of the genome, which gets us an estimate of the variance of all these elements in S and their covariance. Those, we store in V and then S and V are the matrices that actually go into genomic SEM now that sounds really hard and complex and computationally it is luckily others have solved the wonders of how to compute this for us. And so we can very easily implement it let me just show you.</p>
<p>In a browser. How is this done in genomic SEM it’s in the Wiki page of the genomic SEM GitHub chapter three: models without individual SNP effects. And it basically starts by preparing the GWAS summary data we get, which is couple of lines of code. Right, which gets us like the summary statistics in a standardized format. So LD score will know how to read them. And then after that’s done all, we need to tell LD score regression within genomic SEM is where to find, in this case, the summary statistics for psychiatric diseases. What the sample prevalence is of these diseases are in the respective GWASes what the population prevalence of the traits are in the population where it can find these, these LD scores I’ve been discussing what I want my traits to be named. And then I just run the function “ldsc()” and everything we just discussed. The estimating of S the estimating of V is done automatically, and it’s stored in an object, which you can then use to start running genomic SEM models. It also means you don’t need to rerun all those steps. You can store the object, you create it, so you don’t need to rerun LD score all the time.</p>
<p>Okay. Thank you for joining us for this lecture And catch you in the next one.</p>
<hr>
</section>
<section id="sec-video4" class="level2">
<h2 class="anchored" data-anchor-id="sec-video4">Examples on the Genomic SEM wiki</h2>
<p><strong>Title</strong>: Working through examples on the Genomic SEM wiki one by one: munge, ldsc, usermodel functions</p>
<p><strong>Presenter(s)</strong>: Michel Nivard</p>
<p>Introduction</p>
<p><strong>Hi. And welcome to this tutorial on &nbsp; genomic SEM and specifically a tutorial</strong></p>
<p>on fitting genomics and models without&nbsp; an individual snip effect. And today’s&nbsp;&nbsp;</p>
<p>video is on. how to perform those models. We also&nbsp; have written a Wiki page on the GitHub. Right.&nbsp;&nbsp;</p>
<p>So navigate to Github.com/GenomicSEM/GenomicSEM&nbsp; then click on the header Wiki. And you’ll find.&nbsp;&nbsp;</p>
<p>A number of tutorial, pages or pages with&nbsp; instructions, how to perform analyses in&nbsp;&nbsp;</p>
<p>GenomicSEM. And actually the third chapter of the&nbsp; Wiki is models without individual snip effects.&nbsp;&nbsp;</p>
<p>And that’s what we’re discussing. In this video&nbsp; and actually we’re running the code from this&nbsp;&nbsp;</p>
<p>tutorial. Right. And what the code will do it&nbsp; will. First download GWAS a summary data for,&nbsp;&nbsp;</p>
<p>for a number of psychiatric disorders,&nbsp; specifically bipolar schizophrenia,&nbsp;&nbsp;</p>
<p>depression. PTSD and anxiety disorder.&nbsp; We’ll clean those summary statistics &nbsp;&nbsp;</p>
<p>in, in the sense that , we’ll take them from their&nbsp; format as they’r oploaded by the authors in those&nbsp;&nbsp;</p>
<p>formats can vary quite a bit between authors.&nbsp; And groups and put them into a single uniform.&nbsp;&nbsp;</p>
<p>format This step we call munching. Then we’ll&nbsp; take a step in which we’ll compute The genetic&nbsp;&nbsp;</p>
<p>covariance matrix using LD score regression&nbsp; and we’ll compute the matrix of. Standard&nbsp;&nbsp;</p>
<p>errors associated with. Genetical variances and&nbsp; covariances as discussed in a previous video,&nbsp;&nbsp;</p>
<p>right. We had a video about computing, the&nbsp; matrix , S, the covariance matrix and the&nbsp;&nbsp;</p>
<p>matrix V. Which is the covariance matrix of all &nbsp; the elements in the covariance matrix once those&nbsp;&nbsp;</p>
<p>two steps are done. We can actually start fitting&nbsp; models. Well first fit the Common factor model.&nbsp;&nbsp;</p>
<p>And then we’ll manually fit a model with a&nbsp; common factor that loads on to schizophrenia.&nbsp;&nbsp;</p>
<p>Bipolar MDD, PTSD and anxiety and add a second&nbsp; factor. As an illustration. And basically allow&nbsp;&nbsp;</p>
<p>you guys at home to follow along now to follow&nbsp; along. You’ll need to download Summary data.&nbsp;&nbsp;</p>
<p>And this is a neat trick. If you’re on&nbsp; a Mac or Linux machine. You can actually&nbsp;&nbsp;</p>
<p>run. Command line scripts. In a terminal&nbsp; in “R” right. So I’ve written this script.&nbsp;&nbsp;</p>
<p>To download the LD scores we’ll need for LD score&nbsp; regression, a list of HapMap SNPs. Which is the&nbsp;&nbsp;</p>
<p>list of high-quality SNPs. We’ll use for LD score&nbsp; regression. And also, the GWAS summary data from&nbsp;&nbsp;</p>
<p>either the PGC website or from James Walters&nbsp; group. Who did a Cloz UK? GWAS of schizophrenia.&nbsp;&nbsp;</p>
<p>And unzip all those GWAS summary data. Now, this&nbsp; will take quite a while to run across. It’s like&nbsp;&nbsp;</p>
<p>three gigabytes of data you have to pull&nbsp; in from the internet. I’ve already ran it.&nbsp;&nbsp;</p>
<p>So that’s the step we’re going to assume you do&nbsp;&nbsp;</p>
<p>yourself at home Okay. Without further ado,&nbsp; let’s move over to the script for this video.&nbsp;&nbsp;</p>
<p>And as a first step in this script, I’ll&nbsp; require genomic SEM and the package data.Table.&nbsp;&nbsp;</p>
<p>And I will require data table because one&nbsp; of the files. Has a column. That’s sort of.&nbsp;&nbsp;</p>
<p>Not easy to work with in it’s SNP column.&nbsp; It actually has RSID and basepair and &nbsp;&nbsp;</p>
<p>chromosome and allele A1 and allele A2&nbsp; concatenated together as one variable.&nbsp;&nbsp;</p>
<p>And that’s not what we want. We want. A&nbsp; specific variable. That’s only the RSID&nbsp;&nbsp;</p>
<p>for the SNP. And so step zero is to prepare.&nbsp; Specifically that schizophrenia GWAS and &nbsp;&nbsp;</p>
<p>pull out the rs id’s from that one column. And&nbsp; I’ve written a bit of code here to do that.&nbsp;&nbsp;</p>
<p>And it will take quite a while to run and it will&nbsp; heat up my computer a bit. So there. We go and&nbsp;&nbsp;</p>
<p>I’ll. Then have to patiently wait for this code&nbsp; to run before we can actually take the next step.&nbsp;&nbsp;</p>
<p>munge</p>
<p>Okay. That code has managed to run and we’ve&nbsp; prepared the summary data for further processing.&nbsp;&nbsp;</p>
<p>Now we are ready to munge. So the munge function&nbsp; takes a number of arguments. Let’s look at the&nbsp;&nbsp;</p>
<p>help page real quickly. And we try to be good&nbsp; about updating the help pages, but all of us.&nbsp;&nbsp;</p>
<p>Developer for Genomic SEM, have an actual career&nbsp; on the side in which you have to do science. So&nbsp;&nbsp;</p>
<p>they may lag behind Sometimes . Or they miss.&nbsp; Certain information. So basically munge is a &nbsp;&nbsp;</p>
<p>function that processes. GWAS data and prepares&nbsp; them for LD score regresison. So we’ll take&nbsp;&nbsp;</p>
<p>in those large GWAS summary data files and it’ll&nbsp; write out. Smaller processed. Files, which are.&nbsp;&nbsp;</p>
<p>Ready for use in LD score regression. Okay. So the&nbsp; first. Arguments is called files and it actually&nbsp;&nbsp;</p>
<p>just is a vector of file names. Which are the&nbsp; names of the Gus files you’re going to process.&nbsp;&nbsp;</p>
<p>Right. And the second argument is&nbsp; HM3, HapMap3. And it’s basically.&nbsp;&nbsp;</p>
<p>I don’t know why we call it. HM3. We could have&nbsp; called it filter or, you know SNPs or selection&nbsp;&nbsp;</p>
<p>or whatever, but it’s argument you use too provide&nbsp; a list of SNPs you think are high quality,&nbsp;&nbsp;</p>
<p>sNPs or highly efficiently imputed SNPs. And&nbsp; for LD score regression people have commonly&nbsp;&nbsp;</p>
<p>used those HapMap3 SNPs. Because they’re well&nbsp; imputed. They behave well So we trust. LD score&nbsp;&nbsp;</p>
<p>regression analyses based on these SNPs will&nbsp; be. Good reflection of heritability or genetic&nbsp;&nbsp;</p>
<p>correlation between traits. Okay. The next&nbsp; argument. Is a vector of names for your traits.&nbsp;&nbsp;</p>
<p>Gotta be said: pick memorable names because&nbsp; you’ll need those names later. They’ll The prefix&nbsp;&nbsp;</p>
<p>for the file names. Okay. So very long strings of&nbsp; unintelligible things are probably not useful.&nbsp;&nbsp;</p>
<p>Especially if you return to a project in&nbsp; seven months and you’ve called something&nbsp;&nbsp;</p>
<p>flip flop, flip. Then you won’t know what&nbsp; it is, whereas if you call it. SCZ for&nbsp;&nbsp;</p>
<p>schizophrenia or BIP for bipolar. You might&nbsp; still recall. What the file was you processed,&nbsp;&nbsp;</p>
<p>though? It’s better to rely on scripts. then too&nbsp; rely on file names then. A vector of sample sizes.&nbsp;&nbsp;</p>
<p>An info filter. For. Files that if these, GWAS &nbsp; files, have an info column. It will filter SNPs &nbsp;&nbsp;</p>
<p>with an info below 0.9. And a minor allele&nbsp; frequency filter. If these files have a minor&nbsp;&nbsp;</p>
<p>allele frequency column, it will filter SNPs&nbsp; with an minorly frequency. Below 0.01. Now I say&nbsp;&nbsp;</p>
<p>if, because not all GWASes come with info&nbsp; and MAF. Columns. And so you will have to.&nbsp;&nbsp;</p>
<p>Work with what you’ve got. Right. And this&nbsp; is another reason to consider those high&nbsp;&nbsp;</p>
<p>quality HapMap3 SNPs, because sometimes you are&nbsp; simply unable to filter. On things like info,&nbsp;&nbsp;</p>
<p>which reflects imputation quality. Or minor&nbsp; allele frequency. Okay. Let’s run this code.&nbsp;&nbsp;</p>
<p>I should have started running it. While I was&nbsp; talking, but I didn’t. So. Now we’ll have to wait&nbsp;&nbsp;</p>
<p>a bit to. And as you can see. While its running&nbsp; it will keep you up to date via the terminal.&nbsp;&nbsp;</p>
<p>And it will also write. A log file. And. Usually&nbsp; takes a few minutes. About a minutes per file.&nbsp;&nbsp;</p>
<p>Which isn’t that long, but if you’re&nbsp; fitting models with like 50 traits,&nbsp;&nbsp;</p>
<p>it will take 50 minutes. Right. So as a, as a&nbsp; rule of thumb, As many minutes , as you have&nbsp;&nbsp;</p>
<p>traits and depending on how many traits you &nbsp; have, he may go for a cup of coffee. You may just&nbsp;&nbsp;</p>
<p>check your Twitter, or you may just want&nbsp; to, you know, take the afternoon off.&nbsp;&nbsp;</p>
<p>And have a nice long hike. Okay. So the munge. in&nbsp; LD score regression is done it took. 12 minutes.&nbsp;&nbsp;</p>
<p>A bit longer than I expected, but that’s probably&nbsp; because I’m screen recording at the same time. And&nbsp;&nbsp;</p>
<p>if you scroll back up a bit and, or look at&nbsp; the log file, it has produced. You’ll see. It&nbsp;&nbsp;</p>
<p>tells you what it’s doing and munging five.&nbsp; summary statistics files. Time it started.&nbsp;&nbsp;</p>
<p>Names of the files, which may be important if&nbsp; you have a lot of file names that are similar,&nbsp;&nbsp;</p>
<p>make sure the right files are read in and it&nbsp; will then tell you for each column in each file.&nbsp;&nbsp;</p>
<p>What it’s interpreted in it as so it finds a&nbsp; column. “SNP”. And it says I’m interpreting &nbsp;&nbsp;</p>
<p>that as the SNP. And other files. I&nbsp; may find something like SNPID. And it&nbsp;&nbsp;</p>
<p>will actually know that that’s probably SNP.&nbsp; Makes sense for you to go through this file&nbsp;&nbsp;</p>
<p>and check whether the things. It’s doing. Are&nbsp; correct right So important to check whether these&nbsp;&nbsp;</p>
<p>column names are? What you want them to be?&nbsp; Or are interpreted as you want them to be.&nbsp;&nbsp;</p>
<p>Then it will start filtering. remove rows&nbsp; that are in. The summary statistics file,&nbsp;&nbsp;</p>
<p>but not in the HapMap3 SNP lists , the snips&nbsp; we think are high quality SNP of want to&nbsp;&nbsp;</p>
<p>keep. It will then determine effect Column. To&nbsp; either be an odds ratio or a beta, it will do&nbsp;&nbsp;</p>
<p>this by determining the mean or the median of the&nbsp; column. Overall snips of the median is around one&nbsp;&nbsp;</p>
<p>or two meanness around one and we’ll&nbsp; think, well, that’s an alternate show.&nbsp;&nbsp;</p>
<p>If the mean, or the median is around zero. it&nbsp; will asuume that that’s actually a. Beta. Right.&nbsp;&nbsp;</p>
<p>And. Makes sense for you to double check &nbsp; whether it’s doing this correctly. Okay.&nbsp;&nbsp;</p>
<p>And. So usually for a paper. You would take&nbsp; an hour, half an hour to go through these.&nbsp;&nbsp;</p>
<p>Log files and make sure everything’s done&nbsp; correctly. Once you’ve run. LD score regression.&nbsp;&nbsp;</p>
<p>Your working directory will contain sumstats.gz&nbsp; files which are like 12 or 13 megabytes. They’re&nbsp;&nbsp;</p>
<p>far smaller than GWAS summary statistics&nbsp; because they only contain five columns.&nbsp;&nbsp;</p>
<p>Removing all the excess information you don’t&nbsp; need. And they only contained 1.3 million SNPs.&nbsp;&nbsp;</p>
<p>Now mind you, if the overlap between yourGWAS&nbsp; and the HapMap SNPs is only like 150,000 SNPS.&nbsp;&nbsp;</p>
<p>You don’t want to run LD score regression. You&nbsp; want to figure out why the overlap is so small.&nbsp;&nbsp;</p>
<p>Right. So it’s also one of the things, &nbsp; the log will report to you. It’s how many.&nbsp;&nbsp;</p>
<p>SNPS are deleted for what reason? Now. This&nbsp; example I’m in here. Three and 260,000 SNPs&nbsp;&nbsp;</p>
<p>where removed from the bipolar GWAS because&nbsp; the info. Doesn’t cross the threshold of 0.6.&nbsp;&nbsp;</p>
<p>Right. So that’s. The reason for exclusion.&nbsp; You can go back to the bipolar file and&nbsp;&nbsp;</p>
<p>manually check whether that’s true. If, if&nbsp; you somehow suspect. There’s something amiss&nbsp;&nbsp;</p>
<p>with your bipolar file or your analysis. For LD&nbsp; score regression needed to find some arguments.&nbsp;&nbsp;</p>
<p>First for argument is which traits we’re going&nbsp; to use. The sample prevalences of the GWASes,&nbsp;&nbsp;</p>
<p>Now Andrew has been so kind. At some point&nbsp; to check these out and look this up and.&nbsp;&nbsp;</p>
<p>Well, he had to. We were using them in the &nbsp; original genomics SEM paper. And then,&nbsp;&nbsp;</p>
<p>then also the associated population&nbsp; prevalence of these disorders. So here,&nbsp;&nbsp;</p>
<p>we’re assuming schizophrenia as a 1% population&nbsp; prevalence bipolar has a 1% population prevalence.&nbsp;&nbsp;</p>
<p>And for example, MDD, has a 16%? Population&nbsp; preference. And then you will also need to point&nbsp;&nbsp;</p>
<p>LD score regression to where it can actually&nbsp; find the LD scores, which as we’ve shown before,&nbsp;&nbsp;</p>
<p>have been downloaded from the internets and&nbsp; then you define trait names. at this step,&nbsp;&nbsp;</p>
<p>the trait names you define will be your variable&nbsp; names in your model later. So definitely here you&nbsp;&nbsp;</p>
<p>want to choose. Memorable names. Okay, let’s run&nbsp; this. Which again will take a few minutes. But,&nbsp;&nbsp;</p>
<p>you know, But the magic of video editing, I can&nbsp; omit those minutes and make this video move along&nbsp;&nbsp;</p>
<p>rapidly. But you may want to go an have cup of&nbsp; coffee. Okay, that finished running. And if you&nbsp;&nbsp;</p>
<p>scroll back up a bit, you can see that. It will&nbsp; produce sort of information for you to consider,&nbsp;&nbsp;</p>
<p>right. It will tell you. Okay You mean chi- square&nbsp; across the SNPs for the MDD sumstats is one&nbsp;&nbsp;</p>
<p>point in 26, Lambda GC, a metric off genome-wide&nbsp; inflation. The LD score intercept, which is &nbsp;&nbsp;</p>
<p>supposed to be one, an excess of one is actually a&nbsp; metrical population stratification in your GWAS.&nbsp;&nbsp;</p>
<p>It will report the heritability. On the observed&nbsp; scale and the heritability’s Z statistic now.&nbsp;&nbsp;</p>
<p>It will do so for all the heritabilities &nbsp; and genetic covariances right. And at the&nbsp;&nbsp;</p>
<p>bottom. I will report Genetic correlations and&nbsp; heritabilities. All of this is those are written&nbsp;&nbsp;</p>
<p>to a log. Which you can consider at your leisure &nbsp; and make sure that everything’s correct. Before&nbsp;&nbsp;</p>
<p>you consider even publishing. Genomic SEM results.&nbsp; Now let’s have a look at what was created by this&nbsp;&nbsp;</p>
<p>LD score regression function. So we’re going to&nbsp; do some ad hoc. Inspection of this R object the&nbsp;&nbsp;</p>
<p>LDSCoutput is where you’ve stored. the output a&nbsp; few of your LD score regression and it contains&nbsp;&nbsp;</p>
<p>a matrix V. And the matrix S and the matrix Five&nbsp; by five and it’s a genetic governance matrix.&nbsp;&nbsp;</p>
<p>So let’s have a look. The row names of the matrix&nbsp; are the variable names and on the diagonal,&nbsp;&nbsp;</p>
<p>you’ll find the heritabilities of the&nbsp; traits on the liability scale, because it&nbsp;&nbsp;</p>
<p>converted the observed scale heritabilities to &nbsp; reliability scale using the population. And.&nbsp;&nbsp;</p>
<p>Sample prevalences. You can find the details of&nbsp; that in Grotzinger et al on how that does that.&nbsp;&nbsp;</p>
<p>And on the offdiagonal elements, you’ll &nbsp; find the covariances between these traits.&nbsp;&nbsp;</p>
<p>No.&nbsp;As Andrew was discussed in another video.&nbsp; And I have discussed in the other video as well.&nbsp;&nbsp;</p>
<p>Structural equation model actually takes the&nbsp; covariance matrix as observed in the data. And&nbsp;&nbsp;</p>
<p>the covariance matrix implied by your model and&nbsp; tries to pick the parameters for the model such.&nbsp;&nbsp;</p>
<p>That it minimizes the distance between those two&nbsp; covariance matrices. And that’s what we’re going&nbsp;&nbsp;</p>
<p>to do right now. The first model will fit. I’m&nbsp; going to safe. This output. Right. So we don’t&nbsp;&nbsp;</p>
<p>common factor</p>
<p>have to rerun all those slow steps again. The&nbsp; first model will fit. is a common factor , which&nbsp;&nbsp;</p>
<p>is basically the model you’ll see here. Which&nbsp; says that a single latent factor explains.&nbsp;&nbsp;</p>
<p>The covariance between the psychiatric&nbsp; disorders we’re considering now such a model.&nbsp;&nbsp;</p>
<p>In some people’s eyes. And I think that’s&nbsp; a really reasonable perspective. carries a&nbsp;&nbsp;</p>
<p>strong causal implication named me that there&nbsp; is a shared cause. of these traits. Right.&nbsp;&nbsp;</p>
<p>And we can get into how you can actually test&nbsp; whether that’s a reasonable hypothesis. Later.&nbsp;&nbsp;</p>
<p>Now we’re just going to run the model okay. Let’s&nbsp; run the common factor now running. Muddle doesn’t&nbsp;&nbsp;</p>
<p>model output</p>
<p>really take that long. 0.7 seconds to be&nbsp; exact. Now you can imagine if you run &nbsp;&nbsp;</p>
<p>a GWAS with 10 million SNPs. 0.7 seconds. times&nbsp; ten million. It’s actually quite a bit of time.&nbsp;&nbsp;</p>
<p>And then we’d want to parallelize it and &nbsp; run it on, on a cluster computer perhaps.&nbsp;&nbsp;</p>
<p>But right now for this. SNP less model. It doesn’t&nbsp; matter. And so the output you get from. Let me&nbsp;&nbsp;</p>
<p>just resize the window here so we can like check&nbsp; the output out. From. LD score regression is.&nbsp;&nbsp;</p>
<p>No object within it. some model fits. That you&nbsp; can consider. To compare two models. For example,&nbsp;&nbsp;</p>
<p>the difference in chi-squares and degrees of&nbsp; freedom. You can test significance, test. I’m&nbsp;&nbsp;</p>
<p>different than your models. If the mdeols are not&nbsp; nestedit. You can consider the AIC. To compare&nbsp;&nbsp;</p>
<p>models and then there is the CFI. and SRMR,&nbsp; which are. Not relative metrics of two models,&nbsp;&nbsp;</p>
<p>but absolute metrics. And I refer you to the&nbsp; literature or the Wiki page or our articles for&nbsp;&nbsp;</p>
<p>details on how to interpret. These metrics and&nbsp; wherher you consider something good. This will&nbsp;&nbsp;</p>
<p>also depend on your application. And many factors.&nbsp; I also encouraged you to be strict on yourself.&nbsp;&nbsp;</p>
<p>And not just consider something good &nbsp; cause you wants the model to be good, but&nbsp;&nbsp;</p>
<p>I can only encourage you to do so. And if you&nbsp; pick me as a reviewer, I will compel you to do&nbsp;&nbsp;</p>
<p>so. So, you know, Careful what you wish for in&nbsp; listing me as a reviewer on your genomic SEM.&nbsp;&nbsp;</p>
<p>Article. I’m pretty sure the other Genomic &nbsp; SEM authors are similarly inclined. So,&nbsp;&nbsp;</p>
<p>you know, you’ll have to deal with someone’s.&nbsp; Neuroses about fit statistics. Then the other.&nbsp;&nbsp;</p>
<p>Part of the model. Output is actually the&nbsp; parameters, right? So this is the loading&nbsp;&nbsp;</p>
<p>of Schizophrenia the first factor F1.&nbsp; And this is the value of the loading.&nbsp;&nbsp;</p>
<p>It’s a standard error and this is the&nbsp; standardized loading.. Standardized loading &nbsp;&nbsp;</p>
<p>also has standard error. And there’s a B value.&nbsp; Very significant parameter. If you are too.&nbsp;&nbsp;</p>
<p>You were interested in. Destiny department&nbsp; you’ll get factor loadings. But you also get&nbsp;&nbsp;</p>
<p>residual variances. And so.residual variances, are&nbsp; variances in the traits that are not explained.&nbsp;&nbsp;</p>
<p>by. The factor and they’re on the scale of the&nbsp; original heritability. So 9% of the variance. in&nbsp;&nbsp;</p>
<p>bipolar disorder is not explained by the latent&nbsp; factor. Okay. Good to know. Goods let’s move on.&nbsp;&nbsp;</p>
<p>This was a single common factor model. And we’ve&nbsp; been so kind to define a function specifically.&nbsp;&nbsp;</p>
<p>fitting models</p>
<p>For you to use to fit the common &nbsp; factor model, but in many cases you&nbsp;&nbsp;</p>
<p>may want to fit a different model.&nbsp; Right. So to get into, get into the &nbsp;&nbsp;</p>
<p>habits or fitting our own models. We’re going to&nbsp; start by defining a common factor model. Now. You&nbsp;&nbsp;</p>
<p>should really, if you haven’t watched Andrew’s&nbsp; video on lavaan syntax, you should pause now&nbsp;&nbsp;</p>
<p>and go watch that video. And then come back&nbsp; because we’re going to use lavaan syntax,&nbsp;&nbsp;</p>
<p>and I’m going to assume you understand&nbsp; it because he has already explained it.&nbsp;&nbsp;</p>
<p>Right. So please do that and comeback. Okay, well,&nbsp; If you’re still here. You had watched the video&nbsp;&nbsp;</p>
<p>ready? You’re just back. Welcome back. Here we&nbsp; define a common factor model we define it as.&nbsp;&nbsp;</p>
<p>latent factor F1. Which is measured by that’s&nbsp; what this, this. Equal sign plus tilde means &nbsp;&nbsp;</p>
<p>measured by schizophrenia, bipolar, MDD, PTSD, and&nbsp; anxiety. Right. factor causes variance in those.&nbsp;&nbsp;</p>
<p>Disorders. And then we also define factor&nbsp; variance. to be one. We fix it to be one. Now&nbsp;&nbsp;</p>
<p>it’s an identifying characteristic. We need&nbsp; to fix the variance of the factor to one,&nbsp;&nbsp;</p>
<p>or we need to fix one of the loadings on one of&nbsp; the indicator for disorders to one. And let’s&nbsp;&nbsp;</p>
<p>run. common factor model. Using. The code for user&nbsp; model. . The codes are actually designed to read&nbsp;&nbsp;</p>
<p>your model. Which may be different than a single &nbsp; factor model and fit it to the data. And so&nbsp;&nbsp;</p>
<p>we’ve already seen the fit of the model and&nbsp; those of you who’ve seen, seen model fits&nbsp;&nbsp;</p>
<p>before will know. That’s. S R M R Point 22 is&nbsp; pretty high in a CFI. point 85 pretty low. So&nbsp;&nbsp;</p>
<p>the fit of the model to the data is not great.&nbsp; And we can try and improve the fit to the model.&nbsp;&nbsp;</p>
<p>Okay, so we can try and fit. Another model.&nbsp; And to determine what kind of model we should&nbsp;&nbsp;</p>
<p>fit. We should definitely try and check out&nbsp; what the, what the residual co-variants is, are.&nbsp;&nbsp;</p>
<p>In the model. And so one of the arguments we&nbsp; can add to udermodel. Is imp_cov and it will give&nbsp;&nbsp;</p>
<p>us the implied covariance matrix. We’ll set that&nbsp; argument to true. And we’ll rerun the model. Now.&nbsp;&nbsp;</p>
<p>Doing so. gives us. The model implied covariance&nbsp; matrix and a difference between the model implied&nbsp;&nbsp;</p>
<p>and the observed covariance matrix, right. Which&nbsp; we calculate as observed minus implied. And it&nbsp;&nbsp;</p>
<p>will tell us. Where there is still covariance &nbsp; between traits that is not explained well by the&nbsp;&nbsp;</p>
<p>model. And if we look at this matrix, we’ll see&nbsp; that there’s actually. Slides. Well, actually,&nbsp;&nbsp;</p>
<p>maybe a substantial residual correlation between&nbsp; MDD and anxiety, which are very similar disorders.&nbsp;&nbsp;</p>
<p>And their covariance isn’t explained by only the&nbsp; common factor. And so a model we could consider.&nbsp;&nbsp;</p>
<p>Is a model in which we allow a residual &nbsp; covariance to exist between MDD. And.&nbsp;&nbsp;</p>
<p>Anxiety. And we’ll call it.common factor model&nbsp; two. We’ll call it output. common factor self&nbsp;&nbsp;</p>
<p>two. Right. To distinguish it from the previous&nbsp; model. And we can check whether this model fits&nbsp;&nbsp;</p>
<p>the data better. lets go, lets run it and scroll&nbsp; up and figure out. Whether there’s anything. In&nbsp;&nbsp;</p>
<p>terms of model fit tat improves. Well, Wow.&nbsp; So the CFI of this model, it was point 98,&nbsp;&nbsp;</p>
<p>which is way higher than the one before.&nbsp; Right. We can look back was like point 85. And&nbsp;&nbsp;</p>
<p>S R M R is . Way lower. So that those are in &nbsp; the correct direction. That’s what you want.&nbsp;&nbsp;</p>
<p>The model fits the data better. If we allow for&nbsp; residual covariance between MDD and anxiety.&nbsp;&nbsp;</p>
<p>So the last bit of this video went a bit chaotic.&nbsp; But that’s what you get. If you ad hoc try to&nbsp;&nbsp;</p>
<p>fit a new model. You can. Try and improve the&nbsp; model further. Or yourself you could consider.&nbsp;&nbsp;</p>
<p>Whether they are still residual. A genetic&nbsp; correlation between schizophrenia bipolar.&nbsp;&nbsp;</p>
<p>Maybe you removed to genetic residual correlation&nbsp; between anxiety and MDD, all kinds of things you&nbsp;&nbsp;</p>
<p>can consider. And I encourage you to try.&nbsp; And some of those things we may introduce&nbsp;&nbsp;</p>
<p><strong>in life practicals in June. Thank you for&nbsp; watching and catch you in the next one.</strong></p>
<hr>
</section>
<section id="sec-video5" class="level2">
<h2 class="anchored" data-anchor-id="sec-video5">Multivariate GWAS in Genomic SEM</h2>
<p><strong>Title</strong>: Multivariate GWAS in Genomic SEM</p>
<p><strong>Presenter(s)</strong>: Andrew Grotzinger</p>
<p><strong>In this video, we’ll be talking &nbsp; about how to perform multi-variate GWAS&nbsp;&nbsp; using genomic SEM. Multivariate GWAS&nbsp; consists of four primary steps. The first</strong></p>
<p>one being munging the summary statistics,&nbsp; which we’ll talk about in just a second,&nbsp;&nbsp; the second to run multi-variable LD score&nbsp; regression within genomic structural equation &nbsp;&nbsp;</p>
<p>modeling to obtain the genetic covariance and&nbsp; sampling covariance matrices across the GWAS&nbsp;&nbsp;</p>
<p>summary statistics. And note to say that these&nbsp; first two steps mirror the steps that you would&nbsp;&nbsp;</p>
<p>go through to estimate a model without individual&nbsp; SNP effects. Including for the user model and &nbsp;&nbsp;</p>
<p>common factor functions that Michel talked about&nbsp; in the previous video and do not need to be&nbsp;&nbsp; run again. Just for the purposes of running a&nbsp; multi-variate GWAS. And the third step you’ll&nbsp;&nbsp;</p>
<p>prepare the summary statistics for multi-variate&nbsp; GWAS using the sumstats function. And finally,&nbsp;&nbsp;</p>
<p>you’ll actually run the multi-variate&nbsp; GWAS using common factor or userGWASs.&nbsp;&nbsp;</p>
<p>For this example, we’re going to use the five&nbsp; psychiatric traits from the GitHub example for the&nbsp;&nbsp; P factor across schizophrenia, bipolar disorder,&nbsp; major depressive disorder, PTSD, and anxiety.&nbsp;&nbsp;</p>
<p>And these are all publicly available summary&nbsp; stats that are directly available for download&nbsp;&nbsp; The first step again is to manage the data&nbsp; where munge literally just refers to the general&nbsp;&nbsp;</p>
<p>process of converting raw data from one form to&nbsp; another. Munge primarily converting the summary&nbsp;&nbsp;</p>
<p>statistics, Z statistics. It’s aligning all&nbsp; the summary stats, the same reference, allele.&nbsp;&nbsp;</p>
<p>And it’s restricting them to hapmap3 SNPs, both&nbsp; because these tend to be well imputed and even&nbsp;&nbsp;</p>
<p>with just those 1.1 million hapmap3 SNPs you tend&nbsp; to get a reasonable estimate of the heritability.&nbsp;&nbsp;</p>
<p>So sometimes people will be really &nbsp; concerned when they have this large set&nbsp;&nbsp; of eight to 10 million SNPs and then they run&nbsp; it through munge and they only have about one&nbsp;&nbsp;</p>
<p>million SNPs left, but this &nbsp; isn’t cause for concern,&nbsp;&nbsp; because that is enough to get an accurate&nbsp; estimate of heritability using the LDSC equation.&nbsp;&nbsp;</p>
<p>When you run munge it’s going to produce &nbsp; a dot log file for each of your traits.&nbsp;&nbsp; And this is something that’s important to check,&nbsp; just to make sure all of your columns are being&nbsp;&nbsp;</p>
<p>interpreted correctly. I think in general, there&nbsp; can be this push to plug forward with the results&nbsp;&nbsp;</p>
<p>and not really take a look at your data or some&nbsp; of these log files that are produced by different&nbsp;&nbsp;</p>
<p>packages, but you definitely want to make sure&nbsp; before going through all of the additional steps&nbsp;&nbsp;</p>
<p>that the data is being read in appropriately.&nbsp; And one particular thing that I’ve highlighted&nbsp;&nbsp; here is for case control traits, you really&nbsp; want to make sure that that effect column&nbsp;&nbsp;</p>
<p>is being interpreted correctly&nbsp; as either an odds ratio or not.&nbsp;&nbsp; So for MDD I know that this is an odds ratio and&nbsp; I see that the munge function is interpreting that&nbsp;&nbsp;</p>
<p>as such. I just want to go over to R now just&nbsp; to walk through this code as we go along.&nbsp;&nbsp;</p>
<p>So up here, I’ve just set the working directory&nbsp; to where I’ve stored all of these files. This will&nbsp;&nbsp;</p>
<p>look a little bit different in terms of how you&nbsp; do this if you’re on something that’s not a Mac&nbsp;&nbsp; operating system and then I load in genomic&nbsp; SEM and also this function data dot table.&nbsp;&nbsp;</p>
<p>Before running munge something I want to&nbsp; highlight is that I actually have to do something&nbsp;&nbsp; to this schizophrenia summary statistics so&nbsp; that munge can read this data appropriately.&nbsp;&nbsp;</p>
<p>So I’ve already read in the schizophrenia &nbsp; summary statistics using F read. And if you&nbsp;&nbsp;</p>
<p>look at a particular row within schizophrenia,&nbsp; you’ll see that within that SNP column, it’s &nbsp;&nbsp; not just the RSID identifier for that SNP but it’s&nbsp; in the format of RSID. Colon based pear colon &nbsp;&nbsp;</p>
<p>a one colon eight two. And that’s not something&nbsp; that munge is going to know how to read. So&nbsp;&nbsp; prior to actually running munge I use these two&nbsp; lines of code to first split that SNP column so&nbsp;&nbsp;</p>
<p>it’s just pulling out the RSID using string split&nbsp; and sapply, and then writing out a new GWAS file&nbsp;&nbsp;</p>
<p>titled scz_withRS. And then for munge we list the&nbsp; files, the hpmap3 lists the names of the traits&nbsp;&nbsp;</p>
<p>and then the total sample size before running&nbsp; munge this is not something I’m going to do right&nbsp;&nbsp; now just for time reasons and because Michel will&nbsp; have gone over it in the previous video, but just&nbsp;&nbsp;</p>
<p>to show you what the code looks like for this&nbsp; first step. Switching back over to our slides, &nbsp;&nbsp;</p>
<p>the next step is, is going to be to run&nbsp; LD score regression, which computes that&nbsp;&nbsp; genetic covariance and sampling covariance matrix&nbsp; that was discussed in one of Michel’s videos.&nbsp;&nbsp;</p>
<p>So this is The level of genetic overlap across&nbsp; these different traits is estimated using LD&nbsp;&nbsp;</p>
<p>score regression. And then also the standard&nbsp; errors and dependencies across those estimates&nbsp;&nbsp;</p>
<p>as will be the case when there is sample&nbsp; overlap. And this sampling covariance matrix &nbsp;&nbsp; is what allows genomic SEM to produce accurate&nbsp; estimates, even in the face of unknown levels of&nbsp;&nbsp;</p>
<p>sample overlap across your traits. I’ll just note&nbsp; that before going on to steps three and four,&nbsp;&nbsp;</p>
<p>I would highly recommend pausing at step two&nbsp; and actually fitting what I sometimes call&nbsp;&nbsp;</p>
<p>the base model using the user model or common &nbsp; factor functions, that model that doesn’t include&nbsp;&nbsp;</p>
<p>the effect of an individual SNP on different&nbsp; parameters in the model, just to make sure that&nbsp;&nbsp; you’re getting reasonable estimates, that it fits&nbsp; well and that lavaan or genomic SEM don’t produce&nbsp;&nbsp;</p>
<p>any warnings or errors about this particular&nbsp; model, because odds are when you then carry&nbsp;&nbsp; that model forward to multivariate GWAS a lot of&nbsp; the same problems are going to start to show up.&nbsp;&nbsp;</p>
<p>So you just want to diagnose that right. Make&nbsp; sure you’ve got this solid base model and then&nbsp;&nbsp; carry that forward to multi-variate GWAS and&nbsp; step four. So going back over to the R script.&nbsp;&nbsp;</p>
<p>LD score regression takes the names of the month&nbsp; summary statistics for the case control trades. It&nbsp;&nbsp;</p>
<p>takes the sample prevalence of cases over the&nbsp; total sample size, the population prevalence,&nbsp;&nbsp;</p>
<p>which can be pulled from the research literature,&nbsp; the LD scores and the weights used for LD score&nbsp;&nbsp;</p>
<p>regression. Oftentimes this will be the same &nbsp; folder for both of these and the trait names for&nbsp;&nbsp;</p>
<p>your summary statistics. This particular argument&nbsp; trade names is important because this is how&nbsp;&nbsp;</p>
<p>you’re going to name these traits when you&nbsp; specify the model in lavaan. So you want to&nbsp;&nbsp; make sure you don’t name it something with&nbsp; a bunch of upper and lowercase characters, &nbsp;&nbsp;</p>
<p>something that’s easy to write out when&nbsp; you go to write your model on later steps,&nbsp;&nbsp; and then you just run. LDSC this’ll take&nbsp; about a minute with only five trades. Again,&nbsp;&nbsp;</p>
<p>I’m just not going to do it here for time reasons&nbsp; and I’m going to load in that LDSC output that&nbsp;&nbsp;</p>
<p>I created before which is something that I just&nbsp; saved using this command here. The third step is&nbsp;&nbsp;</p>
<p>sumstats and before I go back over to the slides&nbsp; to talk about some of the arguments for sumstats,&nbsp;&nbsp; I just want to reading these arguments and set&nbsp; sumstats up to run. So we’re going to just let&nbsp;&nbsp;</p>
<p>this run and go back over to the slides to&nbsp; talk about what sumstats is actually doing.&nbsp;&nbsp;</p>
<p>So just like munge sumstats to make sure that&nbsp; in all cases that the GWAS summary statistics&nbsp;&nbsp;</p>
<p>are aligned to the same reference to allele&nbsp; and further the coefficients and their standard&nbsp;&nbsp; errors are transformed so that they’re scaled&nbsp; relative to unit variance scaled phenotypes.&nbsp;&nbsp;</p>
<p>What that means is that it makes sure that&nbsp; the GWAS estimates are scaled relative to&nbsp;&nbsp;</p>
<p>a standardized outcome. Or what is sometimes&nbsp; referred to as STDY or partially standardized&nbsp;&nbsp;</p>
<p>regression, coefficients and standard errors.&nbsp; We are not standardizing with respect to the&nbsp;&nbsp; predictor. I E the SNP, but just to the outcome.&nbsp; And the reason that’s important is because&nbsp;&nbsp;</p>
<p>we’re going to take this some steps output, and&nbsp; we’re going to add it to the genetic covariance&nbsp;&nbsp; matrix from LD score regression that we just&nbsp; created in step two. And that genetic covariance&nbsp;&nbsp;</p>
<p>matrix from LD score regression is itself on a&nbsp; standardized scale where the heritabilities on&nbsp;&nbsp;</p>
<p>the diagonal are by definition scaled relative to&nbsp; a standardized phenotype. So we want to make sure&nbsp;&nbsp;</p>
<p>that when we add this, sumstats out, put to that&nbsp; LSDC matrix, which I’ll show you visually in just&nbsp;&nbsp; a couple of slides that they’re on the same scale&nbsp; so that we can produce the appropriate estimates.&nbsp;&nbsp;</p>
<p>In order to do that rescaling appropriately.&nbsp; sumstats needs to know a little bit of &nbsp;&nbsp; information about the scale of the outcome and&nbsp; how the GWAS was specifically run. So this takes&nbsp;&nbsp;</p>
<p>a number of arguments in order to make sure&nbsp; things are done appropriately. And I just want&nbsp;&nbsp; to walk through those arguments here. So the&nbsp; first argument for sumstats is the name of the&nbsp;&nbsp;</p>
<p>summary statistics files. This is not the munged&nbsp; files and should be the same as the name of the&nbsp;&nbsp;</p>
<p>files used for the munge function. So it’s the&nbsp; raw summary stats that you provide to munge.&nbsp;&nbsp;</p>
<p>And it should be listed in the same order that&nbsp; you listed them for the LDSC function in step two.&nbsp;&nbsp;</p>
<p>The second argument is the reference file that’s&nbsp; used to calculate SNP variance and aligned to a&nbsp;&nbsp; single reference allele across traits. Here&nbsp; we’re going to use an a thousand genomes&nbsp;&nbsp;</p>
<p>referenced file from a European population.&nbsp; The third argument is the name of the traits.&nbsp;&nbsp;</p>
<p>This’ll probably be the same as how you’ve been&nbsp; naming the traits for the ldsc and munge function.&nbsp;&nbsp; And the fourth argument is se.logit, which&nbsp; is a vector of that includes TRUE or FALSE&nbsp;&nbsp;</p>
<p>for each trait that indicates whether or not the&nbsp; standard errors in those GWAS summary statistics&nbsp;&nbsp;</p>
<p>are on a logistic scale. The reason that we make&nbsp; this a required argument is because oftentimes&nbsp;&nbsp;</p>
<p>GWAS summary statistics somewhat &nbsp; counter-intuitively will list an odds ratio,&nbsp;&nbsp;</p>
<p>but then they will list a standard error of a&nbsp; logistic beta and so we want to make sure that&nbsp;&nbsp;</p>
<p>the user is being sure to double check this. And&nbsp; this information, if you’re unsure, can often be&nbsp;&nbsp;</p>
<p>found in the readME file for the GWAS summary&nbsp; statistics for those case control outcomes.&nbsp;&nbsp;</p>
<p>The fifth argument is whether the phenotype&nbsp; was a continuous outcome analyzed using an&nbsp;&nbsp; observed least squares or what is referred to&nbsp; as an OLS or more commonly linear estimator.&nbsp;&nbsp;</p>
<p>The following the argument is linprob, which&nbsp; refers to an instance where a phenotype was a&nbsp;&nbsp;</p>
<p>dichotomous outcome analyzed using an OLS&nbsp; estimator. This is referred to as a linear &nbsp;&nbsp;</p>
<p>probability model and is often run just for&nbsp; simplicity sake, becauseis computationally&nbsp;&nbsp;</p>
<p>much easier to analyzea dichotomous outcome&nbsp; using OLS, but in order to do that rescaling,&nbsp;&nbsp;</p>
<p>we need to know whether or not this &nbsp; particular situation is occurring. Proportion&nbsp;&nbsp;</p>
<p>is something that is specified in&nbsp; conjunction with the lineprobargument&nbsp;&nbsp; and it’s necessary in order to perform the&nbsp; linear probability model I E LPM conversion above.&nbsp;&nbsp;</p>
<p>So it takes the proportion of cases over the&nbsp; total sample size. N is a provided sample size&nbsp;&nbsp;</p>
<p>in the order the traits are listed and as only&nbsp; needed when OLS or linprob is true for any of the&nbsp;&nbsp;</p>
<p>traits. Info and MAF filter are standard filters&nbsp; use to filter on amputation quality for info&nbsp;&nbsp;</p>
<p>and to filter on the minor of legal frequency&nbsp; with package defaults of 0.6, 0.01. Keep indel&nbsp;&nbsp;</p>
<p>refers to whether you want to retain insertion&nbsp; deletions with the default being FALSE. Parallel&nbsp;&nbsp;</p>
<p>refers to whether or not the function should be&nbsp; run in parallel and utilize multiple cores on the&nbsp;&nbsp;</p>
<p>computer with the default be to run FALSE and if&nbsp; you are running in parallel, you can specify the&nbsp;&nbsp;</p>
<p>core’s argument that’s indicates whether you want&nbsp; the computer to use a certain number of cores.&nbsp;&nbsp; The summary statistics or sumstats argument&nbsp; will typically only take in this case,&nbsp;&nbsp;</p>
<p>it’ll take about eight minutes for 30 trades it&nbsp; might take. Upwards of an hour. So you certainly&nbsp;&nbsp;</p>
<p>can run in parallel and speed things up, but it’s&nbsp; not necessary to run in parallel by any means.&nbsp;&nbsp;</p>
<p>So I know that the, sumstats argument can be&nbsp; a little bit confusing and for that reason,&nbsp;&nbsp;</p>
<p>I’ve created a schematic on the GitHub Wiki.&nbsp; So this is on the second page of the Wiki &nbsp;&nbsp;</p>
<p>important resources and key information, that just&nbsp; walks you through how to think about specifying&nbsp;&nbsp; these arguments. And it starts with this first&nbsp; question is the GWAS outcome binary continuous,&nbsp;&nbsp;</p>
<p>and just lets you know, what, how you &nbsp; should specify these different arguments.&nbsp;&nbsp;</p>
<p>If we go back over here to R you can see that&nbsp; I’ve specified those file names. The name of&nbsp;&nbsp;</p>
<p>that reference file, which is available in a&nbsp; box link listed on our Wiki. The trait names,&nbsp;&nbsp;</p>
<p>for all of these, these are case&nbsp; control outcomes and they are&nbsp;&nbsp; reporting standard errors and logistic scales&nbsp; so I set se.logit to TRUE for all of them and&nbsp;&nbsp;</p>
<p>I use the default info filters. For completeness,&nbsp; I’ve listed all of the different arguments here,&nbsp;&nbsp;</p>
<p>but you can certainly write this in a more&nbsp; compact form, you don’t have to write OLS&nbsp;&nbsp; equals NULL linprob NULL prop equals NULL if&nbsp; you don’t have any OLS or linprob outcomes.&nbsp;&nbsp;</p>
<p>And here I am running in parallel using four&nbsp; cores. We’re just going to let this finish up &nbsp;&nbsp; here and while that’s happening we’ll&nbsp; move on to talking about the functions.&nbsp;&nbsp;</p>
<p>Before doing that a note that the, sumstats&nbsp; function will also produce a log file like munge&nbsp;&nbsp;</p>
<p>and so, again, it’s imperative that you look at&nbsp; these log files and just make sure everything’s &nbsp;&nbsp; interpreted correctly and much like major&nbsp; depression that I showed you for munge we &nbsp;&nbsp;</p>
<p>want to check here that for bipolar, the effect&nbsp; column is in fact, appropriately interpreted as&nbsp;&nbsp;</p>
<p>an odds ratio. So I’m going to first talk about&nbsp; common factor GWAS a function and then I’ll&nbsp;&nbsp; end by talking about the userGWAS function. What&nbsp; commonfactorGWAS is doing is it’s automatically&nbsp;&nbsp;</p>
<p>specifying a common factor model where the SNP&nbsp; is specified to predict the common factor.&nbsp;&nbsp;</p>
<p>What’s happening behind the scenes for both of&nbsp; the GWAS functions is it’s automatically combining&nbsp;&nbsp; the output from step two from LD score regression&nbsp; and step three, which we’re running right now&nbsp;&nbsp;</p>
<p>from sumstats. So what it does is it one by one&nbsp; takes the LDSC matrix, it takes a particular row&nbsp;&nbsp;</p>
<p>for an individual SNP from sumstats, and it&nbsp; adds it to that matrix. So now that you’ve got&nbsp;&nbsp;</p>
<p>the LDSC matrix and then this appended&nbsp; column or vector of individuals SNP&nbsp;&nbsp;</p>
<p>covariance affects between the SNP and these&nbsp; five psychiatric traits. And what it’s going&nbsp;&nbsp; to do is it’s going to create this matrix,&nbsp; run the model, and then discard the matrix.&nbsp;&nbsp;</p>
<p>And so it’s going to create as many covariance&nbsp; matrix sees as there are SNPs across the trait.&nbsp;&nbsp;</p>
<p>So effectively, if we then take that matrix&nbsp; and run the model, it’s then specifying this&nbsp;&nbsp; model where the SNP is predicting this general&nbsp; factor that indexesrisk sharingacross these five&nbsp;&nbsp;</p>
<p>psychiatric traits. So this is an example of&nbsp; just one model that’s being run, but again,&nbsp;&nbsp;</p>
<p>this first vector here is swapped&nbsp; out as many times as there are SNPs&nbsp;&nbsp; and it’s re estimated to get that updated &nbsp; estimate of the SNP effect on the factor&nbsp;&nbsp;</p>
<p>commonfactorGWAS takes a couple of arguments.&nbsp; The first is covstruc, which is the output&nbsp;&nbsp;</p>
<p>from LD score regression. The second is&nbsp; SNPs, which is the output from sumstats.&nbsp;&nbsp;</p>
<p>The third optional argument is estimation,&nbsp; which specifies whether models should be&nbsp;&nbsp; estimated using DWLS, which refers to diagonally&nbsp; weighted least squares, or ML, which refers to&nbsp;&nbsp;</p>
<p>maximum likelihood estimation where the package&nbsp; default is DWLS. The way to think about the&nbsp;&nbsp;</p>
<p>difference between these two is DWLS will look&nbsp; to produce model estimates that are trying to&nbsp;&nbsp;</p>
<p>recapture the parts of the observed covariance&nbsp; matrix that are estimated with greater precision.&nbsp;&nbsp;</p>
<p>This does not mean that DWLS is going &nbsp; to automatically produce things like&nbsp;&nbsp;</p>
<p>larger factor loadings for the GWAS &nbsp; traits with a larger sample size.&nbsp;&nbsp;</p>
<p>Instead if you’ve got a particularly &nbsp; well powered GWAS that goes into this model&nbsp;&nbsp; and that GWAS does not correlate very highly&nbsp; with the other traits, then the model will&nbsp;&nbsp;</p>
<p>actually prioritize producing, in the context of&nbsp; a common factor model, a particularly low factor &nbsp;&nbsp;</p>
<p>loading for that well powered trait. So again,&nbsp; it doesn’t mean that the well powered trait&nbsp;&nbsp;</p>
<p>dominates the model per se, in the sense&nbsp; that it’s producing larger estimates,&nbsp;&nbsp;</p>
<p>it just means that DWLS is taking into account &nbsp; the information that’s available. Depending on&nbsp;&nbsp;</p>
<p>how you think about statistical modeling, you&nbsp; might have a different preference between them, &nbsp;&nbsp; but to our mind, if you’ve got more information&nbsp; about a particular cell in that covariance&nbsp;&nbsp;</p>
<p>matrix, that’s going to reflect a GWAS that’s&nbsp; better powered, why not use that information&nbsp;&nbsp; appropriately and let the model appropriately&nbsp; favor reproducing that part of the matrix.&nbsp;&nbsp;</p>
<p>Cores is how many computer cores &nbsp; to use when running in parallel,&nbsp;&nbsp; where the default is to use one less core than&nbsp; it’s available in the local computing environment.&nbsp;&nbsp;</p>
<p>But you can specify as many cores you want&nbsp; using this argument. Tolerance is only relevant&nbsp;&nbsp;</p>
<p>if you start getting errors or warnings&nbsp; about matrix inversion, but beyond that,&nbsp;&nbsp; it’s not something that you need to be concerned&nbsp; about . Parallel is an optional argument&nbsp;&nbsp;</p>
<p>specifying whether you want the function to be &nbsp; run in parallel or to be run serially. GCs, the&nbsp;&nbsp;</p>
<p>level of genomic control you want the function&nbsp; to use. The default is to adjust the univariate&nbsp;&nbsp; GWAS standard errors by multiplying them by the&nbsp; square root of the univariate LDSC intercept.&nbsp;&nbsp;</p>
<p>What that does is it takes this univariate LDSC&nbsp; intercept, which is intended to index uncontrolled&nbsp;&nbsp;</p>
<p>for population stratification and that it&nbsp; appropriately corrects those standard errors by&nbsp;&nbsp; the intercept so that you’re producing estimates&nbsp; that pull out that uncontrolled for pop Strat.&nbsp;&nbsp;</p>
<p>If the LDSC intercept is below one, I’ll just&nbsp; note that what the package is going to do is&nbsp;&nbsp; not correct for the intercept at all. So it’s&nbsp; never going to produce more liberal estimates&nbsp;&nbsp;</p>
<p>than a univariate GWAS going in, but it’s&nbsp; going to be more conservative as a default.&nbsp;&nbsp;</p>
<p>MPI is whether the function should &nbsp; use message passage interfacing which&nbsp;&nbsp; allows you to use multi-node processing. Which&nbsp; we’ll talk a little bit more at the very end,&nbsp;&nbsp;</p>
<p>when we talk about runtime considerations &nbsp; for these different functions.&nbsp;&nbsp; So now if we go back over to R we can see that&nbsp; the sumstats function has finished up running.&nbsp;&nbsp;</p>
<p>It took about seven minutes . And now going on&nbsp; to step four of actually running the common factor&nbsp;&nbsp;</p>
<p>GWAS just for the purposes of this exercise,&nbsp; I’m just going to subset to the first 100 rows.&nbsp;&nbsp;</p>
<p>So that’s sumstats output just so we can see how&nbsp; the common factor GWAS functions are running. So&nbsp;&nbsp;</p>
<p>we’re just going to let this run here. And as it’s&nbsp; doing that, I’ll just show you that we’ve got.&nbsp;&nbsp; covstruc that lists the LDSC output, SNPs,&nbsp; that list, that subset output from sumstats&nbsp;&nbsp;</p>
<p>that we’re using DWLS we’re using four cores&nbsp; and we don’t need to set the tolerance lower.&nbsp;&nbsp;</p>
<p>We’re not changing the SNP standard error that&nbsp; it uses. We’re running in parallel. We’re using&nbsp;&nbsp; the standard GC correction and we’re not using&nbsp; MPI. SNP standard error just refers to whether or&nbsp;&nbsp;</p>
<p>not you want to change the standard error of the&nbsp; SNP, this is just set to a really small value to&nbsp;&nbsp;</p>
<p>reflect the fact that that’s coming from our&nbsp; reference panels, so we essentially treat it&nbsp;&nbsp; as fixed. But it is not something that &nbsp; really affects your model estimates out to&nbsp;&nbsp;</p>
<p>the fifth decimal place. So that finished running.&nbsp; So let’s just take a look at the first five rows.&nbsp;&nbsp;</p>
<p>And what you can see here is that it’s pulling&nbsp; the SNP RSID, the chromosome, the base pair,&nbsp;&nbsp;</p>
<p>the minor allele frequency from the reference&nbsp; file that you fed to sumstats, A1 and A2,&nbsp;&nbsp;</p>
<p>just the run number, the particular estimate from&nbsp; the model that was saved, which for common factor&nbsp;&nbsp;</p>
<p>GWAS is always going to be the effect of the SNP&nbsp; on the common factor. The corresponding estimate&nbsp;&nbsp;</p>
<p>for that parameter, the sandwich corrected&nbsp; standard error, the Z statistic, the P value. And&nbsp;&nbsp;</p>
<p>then this Q statistic and it’s degrees of freedom&nbsp; and P value. There’s also this fail and warning&nbsp;&nbsp;</p>
<p>column at the end. That can be good to check&nbsp; using something like the table argument in R&nbsp;&nbsp; just to see if any warnings or runs were &nbsp; just failing to produce any output. Zero&nbsp;&nbsp;</p>
<p>indicates that there was no warnings run. And&nbsp; we can see here that for these a hundred SNPs,&nbsp;&nbsp; that there were no issues that were raised before&nbsp; I switched back over to the slides to talk about&nbsp;&nbsp;</p>
<p>Q some more. I’ll just highlight that for a lot &nbsp; of this code I’m just including for completeness,&nbsp;&nbsp;</p>
<p>the arguments that are listed, including their&nbsp; defaults. So MPI is automatically set to false &nbsp;&nbsp;</p>
<p>GCs, automatically set to standard. So we could&nbsp; produce the same output in a much more compact&nbsp;&nbsp;</p>
<p>form, writing this code here below. So this&nbsp; will just produce the same results. And it’s&nbsp;&nbsp; just a highlight that , if you’re setting&nbsp; the arguments to the default behavior,&nbsp;&nbsp;</p>
<p>you don’t have to list them. So what you saw on&nbsp; that output was three columns related to this&nbsp;&nbsp;</p>
<p>Q SNPs statistic, which is an estimate of SNP&nbsp; level heterogeneity. And the way to think about&nbsp;&nbsp;</p>
<p>Q SNP is it asked the extent to which the effect&nbsp; of a SNP operates through a common factor. It’s&nbsp;&nbsp;</p>
<p>a chi-square distributed test statistic that is&nbsp; essentially comparing the fit of a common pathways&nbsp;&nbsp;</p>
<p>model in which this SNP operates strictly via the&nbsp; common factor to an independent pathways model in&nbsp;&nbsp;</p>
<p>which the SNP directly predicts the indicators of&nbsp; that common factor. If this independent pathways&nbsp;&nbsp;</p>
<p>model fits much better than this common pathways&nbsp; model, then that suggests that the SNP is not&nbsp;&nbsp; really operating through the common factor,&nbsp; that this single regression relationship is&nbsp;&nbsp;</p>
<p>not sufficient for capturing the pattern of the&nbsp; relationships across these five indicators here.&nbsp;&nbsp;</p>
<p>Instances where you might expect Q&nbsp; SNP to be significant include when,&nbsp;&nbsp; for example, there are directionally opposing&nbsp; effects of the SNP on different indicators.&nbsp;&nbsp;</p>
<p>So let’s say the SNP is risk conferring &nbsp; for the first two indicators&nbsp;&nbsp;</p>
<p>and is actually protective for the last three&nbsp; indicators . In that case, it’s clearly not&nbsp;&nbsp; operating through some general common factor&nbsp; and we would expect Q SNP to be significant.&nbsp;&nbsp;</p>
<p>Another instance might be at the SNP has a&nbsp; really strong effect on one of the indicators.&nbsp;&nbsp; And I sort of null or at least a much weaker&nbsp; effect across the remaining indicators.&nbsp;&nbsp;</p>
<p>As a canonical example of this if we ever include&nbsp; alcohol use disorder or any alcohol use phenotype,&nbsp;&nbsp;</p>
<p>really within a genomic structural equation&nbsp; model, we often find that the variants that &nbsp;&nbsp; exist within the alcohol dehydrogenase genes&nbsp; will pop a significant for Q SNP. And that’s&nbsp;&nbsp;</p>
<p>because those tend to be genetic variants that&nbsp; are not associated with the general factor that&nbsp;&nbsp;</p>
<p>alcohol use is loading on but are instead of&nbsp; highly specific to that alcohol use phenotype.&nbsp;&nbsp;</p>
<p>And what is cool about Q SNP is that when you’ve&nbsp; got a set of really highly correlated trades,&nbsp;&nbsp; In fact, what might be more interesting is&nbsp; what actually causes these traits to diverged.&nbsp;&nbsp;</p>
<p>Is to identify via this Q SNP statistic, what&nbsp; it is that really genetically differentiates&nbsp;&nbsp;</p>
<p>this disorders. Wouldn’t it be nice if we&nbsp; could use Q SNP to gain some novel insight&nbsp;&nbsp;</p>
<p>about what causes these things to have &nbsp; a slightly different presentation.&nbsp;&nbsp;</p>
<p>if you’re a specifying a model that is &nbsp; something that is not a common factor model,&nbsp;&nbsp; then you’re going to want to use userGWAS, which&nbsp; allows the user to specify any model that includes&nbsp;&nbsp;</p>
<p>the effect of individual SNPs, such as a SNP,&nbsp; predicting multiple correlated factors in the&nbsp;&nbsp;</p>
<p>model. userGWAS takes all of the same arguments&nbsp; that I just showed you for commonfactorGWAS,&nbsp;&nbsp;</p>
<p>along with two additional arguments. One of&nbsp; those is the model that you’re estimating&nbsp;&nbsp; written using lavaan syntax. And for this model,&nbsp; the way that you’re going to include the SNP in&nbsp;&nbsp;</p>
<p>the model is just to literally refer to it as SNP&nbsp; or SNP in all capital letters. And I’ll show that&nbsp;&nbsp;</p>
<p>model over in the R script. in just a second.&nbsp; The second is the sub argument and this is an&nbsp;&nbsp;</p>
<p>optional argument specifying whether or not you’re&nbsp; going to request to save only specific components&nbsp;&nbsp; of the model output. The reason I would recommend&nbsp; almost always setting this argument to something&nbsp;&nbsp;</p>
<p>is that there’s a lot of different rows for any&nbsp; given model that lavaan is going to produce. So&nbsp;&nbsp;</p>
<p>for example, for the common factor model, there’s&nbsp; the five factor loadings, the five residual&nbsp;&nbsp; variances of the indicators, all of which are&nbsp; going to be fairly similar across all of the SNPs.&nbsp;&nbsp;</p>
<p>And it would take up a lot of space to save all&nbsp; of that output for each individual SNP. And what&nbsp;&nbsp;</p>
<p>we’re really interested is just the effect of the&nbsp; SNP on the common factor. And so what sub allows&nbsp;&nbsp; us to do is say, I just want you to save that&nbsp; output for the SNP effect on the common factor.&nbsp;&nbsp;</p>
<p>And if you’re specifying a model in which you’re&nbsp; interested in multiple different parameters,&nbsp;&nbsp; you can also set sub to include more than just&nbsp; one parameter, but again, it’s rarely going to&nbsp;&nbsp;</p>
<p>be the case that you’re interested in saving every&nbsp; single piece of the model output for each SNP.&nbsp;&nbsp;</p>
<p>And instead you should think about just&nbsp; saving those pieces that you’re interested in.&nbsp;&nbsp;</p>
<p>If we switch back over to Rstudio to run&nbsp; userGWAS, what I’m going to do is I’m going to&nbsp;&nbsp; run the userGWAS, but for the exact same model as&nbsp; common factor, GWAS is automatically specifying.&nbsp;&nbsp;</p>
<p>So here we’ve written the common factor model&nbsp; with the factor regressed on the SNP here on the&nbsp;&nbsp;</p>
<p>bottom and we’re also setting that sub argument&nbsp; to just save the effect of the SNP on the factor.&nbsp;&nbsp;</p>
<p>So let’s set that up to run. And what this should&nbsp; do is produce the exact same estimates that we&nbsp;&nbsp;</p>
<p>saw for common factor GWAS. And I’ll show that&nbsp; to you in just a second, when this finishes up.&nbsp;&nbsp;</p>
<p>So if we look at the first five rows from the&nbsp; user GWAS output and the first five rows from&nbsp;&nbsp;</p>
<p>the common factor, GWAS output, you can&nbsp; see that these are exactly the same 0.413.&nbsp;&nbsp;</p>
<p>And so on the user, GWAS, output’s going to look&nbsp; a little bit different. It’s not going to include&nbsp;&nbsp;</p>
<p>the Q statistic, but instead it’s going to&nbsp; include model fit statistics. What’s the overall&nbsp;&nbsp; fit of that model. So it’s going to include Chi &nbsp; square, Chi square degrees of speed, chi-square P&nbsp;&nbsp;</p>
<p>value, and AIC. And those can be used to compare&nbsp; to what are referred to as nested models.&nbsp;&nbsp;</p>
<p>So you could examine a independent pathways&nbsp; model where that SNP is predicting each of&nbsp;&nbsp;</p>
<p>the five indicators and then if you did a&nbsp; model comparison across those two models, &nbsp;&nbsp;</p>
<p>you would find that that produces the same thing&nbsp; as Q SNP down here. So if we take a look at the&nbsp;&nbsp;</p>
<p>run times across this. I know for the first two &nbsp; steps, I didn’t run them now. But if you look at&nbsp;&nbsp; the output files, you’ll find that for munch&nbsp; on my own laptop and took about eight minutes.&nbsp;&nbsp;</p>
<p>LDSC took a little over a minute. sumstats took&nbsp; about seven minutes. The common factor GWAS took&nbsp;&nbsp;</p>
<p>about 17 seconds and the user GWAS 10 seconds.&nbsp; For those GWAS functions, of course, we only ran&nbsp;&nbsp;</p>
<p>it on the first a hundred SNP and we did run it in&nbsp; parallel. This is not necessarily indicative of &nbsp;&nbsp;</p>
<p>how long it would take for a million SNPs&nbsp; you wouldn’t just multiply these numbers&nbsp;&nbsp;</p>
<p>by a certain amount because there’s certain&nbsp; initial steps that the GWAS functions need&nbsp;&nbsp; to go through. At the same time, the GWAS &nbsp; functions do take a while. How long that takes&nbsp;&nbsp;</p>
<p>exactly. It’s going to depend on the number of &nbsp; traits and how complicated your model is. So,&nbsp;&nbsp;</p>
<p>I never know exact runtime considerations,&nbsp; but these are things that you are going to&nbsp;&nbsp;</p>
<p>ideally be running on a computing cluster and I&nbsp; want to talk finally about how to really speed&nbsp;&nbsp;</p>
<p>this up so that you can get results as quick as&nbsp; possible. So both parallel and MPI processing&nbsp;&nbsp;</p>
<p>are available for userGWAS and commonfactorGWAS.&nbsp; Where parallel and serial processing are doing&nbsp;&nbsp;</p>
<p>the exact same thing with the exception&nbsp; that parallel processing is utilizing&nbsp;&nbsp; the core is available in your computing&nbsp; environment to send off different chunks of SNPs,&nbsp;&nbsp;</p>
<p>to the different cores, to then run the GWAS on&nbsp; those cores. MPI takes advantage of a multi-node&nbsp;&nbsp;</p>
<p>computing environment. It does require that Rmpi&nbsp; is already installed on the computing cluster,&nbsp;&nbsp;</p>
<p>but that then adds this additional layer that&nbsp; it sends the output off to multiple nodes and&nbsp;&nbsp;</p>
<p>then often multiple cores within those nodes.&nbsp; And then finally, you can speed this up just&nbsp;&nbsp;</p>
<p>that much more by sending off separate jobs that&nbsp; then themselves use MPI processing, where they&nbsp;&nbsp;</p>
<p>send it off to different nodes in different&nbsp; cores within those nodes. The important thing&nbsp;&nbsp; to know is that all runs are independent of one&nbsp; another. So you can dice up that sumstats output,&nbsp;&nbsp;</p>
<p>however you want, and you’ll still get the&nbsp; same output. So for me, anytime I run a GWAS&nbsp;&nbsp;</p>
<p>on the computing cluster , I will send off 40&nbsp; jobs that then run in MPI. And for this common&nbsp;&nbsp;</p>
<p>factor, GWAS example for two ish million SNPs&nbsp; that only ends up taking about two to three hours.&nbsp;&nbsp;</p>
<p>So again, if you reach out to me and ask, what’s&nbsp; the exact runtime I should expect for this model,&nbsp;&nbsp; I’m not going to know because it’s really gonna&nbsp; depend on the type of model you’re running.&nbsp;&nbsp;</p>
<p>For sure there are indicators that something is&nbsp; going wrong. Like if you submit a hundred SNPs &nbsp;&nbsp;</p>
<p>and it’s taking 12 hours to run that suggests that&nbsp; something is just breaking apart on the computing&nbsp;&nbsp;</p>
<p>cluster. And you’re certainly welcome to reach&nbsp; out on the Google group to see if we have any&nbsp;&nbsp; input about how best to speed things up. So with&nbsp; that, I’ll just end here and in the next videos,&nbsp;&nbsp;</p>
<p>we’ll talk about some of the newer functionality&nbsp; available in genomic SEM including the ability to&nbsp;&nbsp; examine multi-variate enrichment, using &nbsp; what we call stratified genomic SEM.</p>
<section id="section-1" class="level3">
<h3 class="anchored" data-anchor-id="section-1"></h3>
<hr>
</section>
</section>
<section id="sec-video6" class="level2">
<h2 class="anchored" data-anchor-id="sec-video6">Using Genomic SEM to Understand Psychiatric Comorbidity</h2>
<p><strong>Title</strong>: Using Genomic SEM to Understand Psychiatric Comorbidity</p>
<p><strong>Presenter(s)</strong>: Andrew Grotzinger</p>
<p>so andrew thanks so much for coming we are just super excited to hear about your work many of us know about genomics sound but</p>
<p>really want to get a more in-depth knowledge so uh very very</p>
<p>uh happy to have you here and welcome thank you um yeah it’s a real pleasure to be speaking</p>
<p>to this group in particular um and today i’m gonna be talking about</p>
<p>genomics sem overall um but i really want to focus the second half of my talk on the application of</p>
<p>genomic sem to psychiatric traits um and i know a number of you have heard me talk about</p>
<p>genomics and before so i’ll try to keep this first part relatively brief and more just a refresher</p>
<p>um but there is a new package update within the last couple months that i’ve put on the github for</p>
<p>stratified genomics m so hopefully that’ll be kind of a new thing for some people here</p>
<p>um so just to start giving an overview of genomics them and kind of the motivation for developing this package um</p>
<p>i’m just showing here a old plot from kendler at all 2012 showing g was hits on the y-axis</p>
<p>and different traits on the x-axis and what this is demonstrating is something that’s well known to</p>
<p>everyone here that as the sample sizes have increased for different gewa studies that the</p>
<p>number of hits that we’ve identified has increased in a corresponding way pretty rapidly where we’re now identifying</p>
<p>hundreds of different genetic variants under underlying complex traits that are of interest to people</p>
<p>and so for me as someone who’s interested in psychiatric outcomes like schizophrenia and depression if we</p>
<p>look at these two manhattan plots from some of the more recent efforts from these groups these traits are so</p>
<p>polygenic that if you’re trying to figure out what actually is shared across these two traits it’s not just a matter of</p>
<p>identifying um five or ten overlapping genes or loci that are shared across these manhattan</p>
<p>plots and it really required people to think about how we could actually quantify the level of genetic overlap</p>
<p>and that was done really beautifully in 2015 when the group from the broad introduced</p>
<p>ld score regression and more specifically bivariate ld score regression for examining</p>
<p>shared genetic overlap across traits which allows you to estimate genetic correlations between samples</p>
<p>with varying degrees of sample overlap using what is often publicly available gwas summary data</p>
<p>and when people apply genomic sem like they did in the brainstorm consortium paper in 2018 you can produce these genetic</p>
<p>heat maps across different sets of traits where on the left you’ve got psychiatric phenotypes</p>
<p>and on the right across a wider range of kind of brain disorders and behavioral cognitive phenotypes where the darker</p>
<p>shading indicates higher levels of genetic overlap um and unsurprisingly we see that</p>
<p>there’s certain clusters of traits within these heat maps where for example psychiatric disorders tend to show</p>
<p>a pretty strong level of genetic overlap which is something we might expect based on high levels of comorbidity that</p>
<p>we observe among psychiatric disorders well at the same time some genetic correlations were maybe</p>
<p>particularly or even surprisingly high such as genetic correlations between bipolar disorder and schizophrenia</p>
<p>and the range of 0.6 or 0.8 as you can kind of see indicated by this particularly dark blue box</p>
<p>between those two disorders um so when these sorts of papers were coming out i was</p>
<p>in the midst of running twin models and helping um navigate and manage a twin study down</p>
<p>at ut austin and running different multivariate models of twin correlation matrices and</p>
<p>so seeing these correlation matrices coming out based on genomic patterns of convergence</p>
<p>there seemed to be this kind of strong need to really develop and apply multivariate methods to actually model</p>
<p>these constellations of genetic overlap and so that led us to develop and</p>
<p>publish this paper that introduced genomic structural equation modeling in 2019 and nature human behavior which is kind</p>
<p>of broadly speaking a framework for modeling patterns of genetic associations</p>
<p>across wide constellations of traits and so in general genomic sem uses a</p>
<p>two-stage estimation procedure where in stage one you estimate the genetic covariance matrix</p>
<p>and associated sampling covariance matrix of standard errors and their code dependencies we use ld</p>
<p>score regression within the context of the package but you could hypothetically use any sort of</p>
<p>genetic covariance matrix such as you might get from greml um and then in stage two we actually fit</p>
<p>the structural equation model to the matrices that are estimated from stage one</p>
<p>and so just to kind of show you visually what those stages look like and so in stage one we’d create this</p>
<p>genetic covariance matrix or what we call s that has the heritabilities estimated from the genome-wide data</p>
<p>on the diagonal and those genetic covariances are cohered abilities on the off diagonal and then critically</p>
<p>we’re also estimating this sampling covariance matrix v that contains the squared standard</p>
<p>errors on the diagonal and the sampling dependencies on the off diagonal which indexes</p>
<p>the dependencies between estimation errors and that’s what allows us to apply genomic sem</p>
<p>for samples that have different levels of sample overlap and that doesn’t need to be known that</p>
<p>is directly estimated from the data using a block jackknife procedure but again</p>
<p>if you have different sets of summary statistics and you’re worried about some level level of overlapping controls</p>
<p>this sampling covariance matrix is going to allow you to produce unbiased standard errors even in the presence of that</p>
<p>sample overlap and then in stage two you take those two matrices</p>
<p>and feed it into the genomics mr package and specify some sort of model like this genetic</p>
<p>multiple regression model in which we have schizophrenia and bipolar disorder as correlated predictors of</p>
<p>educational attainment and then parameters are estimated that fit the observed genetic covariance</p>
<p>matrix as close as possible and since this is a fully saturated model and the model parameters are</p>
<p>simply a transformation of the observed matrix um one thing that i like to highlight</p>
<p>when i’m talking about this and i know that this kind of first part of this phrase is not</p>
<p>applicable to this group but even if you are not interested in genetics i think genomic sem offers some kind of valuable tools</p>
<p>because it allows you to look at systems of relationships across a wide array of rare traits that could not be</p>
<p>measured um in the same sample and so if we think about just a case example of what that might look like</p>
<p>let’s say that as someone interested in clinical phenotypes you have a real interest in the relationships between</p>
<p>schizophrenia and bipolar disorder you’ve read the research literature and see a lot of convergence across</p>
<p>different risk factors for these disorders you have a pretty good understanding that these phenotypically can often look pretty similar</p>
<p>and you also notice pretty similar kind of age of onset distributions for these two disorders so in that case you might</p>
<p>be interested in looking and quantifying um in a sort of cross-leg panel like this</p>
<p>the relationships between both early and late onset versions of schizophrenia bipolar disorder</p>
<p>the issue is that these two disorders are actually not you can’t diagnose them together in</p>
<p>the dsm these would be rule outs of one another so you couldn’t in a phenotypic sample actually observe these two disorders</p>
<p>within the same individual [Music] and so you wouldn’t be able to estimate</p>
<p>this part of the model using phenotypic data and of course you also can’t observe</p>
<p>both early and late onset versions of a disorder within the same person so you couldn’t look at this part of the</p>
<p>model but with genomics m you can actually stratify the g was</p>
<p>summary statistics by early and late onset versions of these disorders and you could actually fit this sort of model</p>
<p>and actually start to test the sorts of relationships that we’ve been left to really just hypothesize about and make</p>
<p>qualitative conclusions around based on convergence from different separate univariate studies</p>
<p>at this point stratified genomic sem can be used to look at convergence at three main levels of</p>
<p>analysis and i just want to walk through those so at the genome-wide level um this is actually just a</p>
<p>recapitulation of that multiple regression model i showed earlier as an example of stage two</p>
<p>estimation where we’re just looking at the system of relationships between schizophrenia and bipolar and</p>
<p>educational attainment but this is just to highlight that for people who are interested in sort of</p>
<p>mediation type hypotheses that within genomic sem you can kind of quantify things like a total indirect and direct</p>
<p>effect um between different disorders um within genomic sem</p>
<p>you can also get standard model fit indices like aic model chi square cfi and srmr</p>
<p>and that allows you to go through kind of classic model fitting procedures to try and decide between different</p>
<p>competing models [Music] and decide what kind of patterns of relationships best fit the data</p>
<p>so in that original paper we looked at a series of models fit to the covariance matrix estimated across</p>
<p>these 12 neuroticism items and what we found is that a common factor model fit the data pretty well a</p>
<p>two factor model did a little bit better but a three factor model really seemed to balance</p>
<p>that um relationship between fit and parsimony in terms of how we were representing the data</p>
<p>and what i would highlight here is that the way that the items kind of segregated across these factors actually does make a lot of post-hoc</p>
<p>theoretical sense so you see on factor one this kind of mood misery and irritability items</p>
<p>maybe on this kind of negative affect factor guilt hurt and embarrassment around</p>
<p>maybe this kind of social reactivity factor and nervous worry tense and nerves maybe this kind of more</p>
<p>anxiety type factor and while these factors are still highly correlated they are somewhat</p>
<p>dissociable and in fact when we run multivariate g wasps to look at snip</p>
<p>effects on these factors we do find somewhat divergent biological pathways that we might miss</p>
<p>if we were we were to employ approach where say we just kind of sum across these items and run a g was on a</p>
<p>sum score of the 12 neuroticism items so i think this really highlights the ability of these sort of model</p>
<p>fitting procedures to pull out some pretty interesting patterns in the data</p>
<p>moving on to this new level of analysis stratified genomic stem that we introduced in a paper that’s</p>
<p>currently on meta-archive and out for review right now but the code for that is live on the github</p>
<p>along with a tutorial page for that um is really designed to think about how we can start to make sense</p>
<p>of gwas findings characterized by thousands of genes that really individually explain only a</p>
<p>very small portion of the phenotypic variants so just as sort of a kind of hypothetical example let’s think</p>
<p>about these future manhattan plots where the gy sample sizes are getting in the millions and now we’re starting to see</p>
<p>that um basically the entire genome is somehow associated with the phenotype again i know this is just sort of a case</p>
<p>example but it just highlights that you know at an individual snip level we’re going to get to a point where the</p>
<p>picture is so complicated that it’s really hard to make sense of what’s going on just based on a manhattan plot</p>
<p>already a number of methods out there that in the univariate case can be used to</p>
<p>basically partition heritability by using collateral gene expression data such as</p>
<p>what you might get from rna sequencing methods to try to lump associated genetic variants um and</p>
<p>portions of heritability into meaningful categories so in this partitioned ld score regression</p>
<p>paper um from 2015 they showed that disorders like schizophrenia and bipolar disorder</p>
<p>are enriched in the central nervous system which you can see here based on these orange bars for that</p>
<p>annotation including for years of education as well which of course um makes a lot of sense</p>
<p>um so we extend that same model to be able to look at partitioned coherent ability</p>
<p>um so this will look familiar to anyone who’s um worked with the bivariate ld score</p>
<p>equation before and really all we’re doing now is that instead of using</p>
<p>um the ld scores here we’re using the partitioned ld scores so the ld scores within a particular functional annotation so</p>
<p>we develop this and validate it um as a means to an end for really being able to then feed these</p>
<p>partitioned covariance matrix matrices into genomic sem to then be able to examine</p>
<p>genetic enrichment of any model parameter estimated in genomics m for this kind of new extension that we’re calling stratify genomics m</p>
<p>so you can look at enrichment of residuals in a structural equation model enrichment of correlations between</p>
<p>factors and i think what people would typically be interested in enrichment of the factor variances</p>
<p>to see where these kind of overarching factors that explain variance in the indicators</p>
<p>are really enriched so in that way we can take a manhattan plot of</p>
<p>these common factors and start to look at these kind of top peaks and ask whether or not these hits are really enriched within</p>
<p>genes that are expressed during certain developmental periods such as during early kind of even prenatal periods or</p>
<p>later in life whether they’re enriching specific brain regions or even in certain neuronal subtypes um and this</p>
<p>method really starts to and you know any kind of partitioning method starts to become increasingly</p>
<p>exciting as the gene expression work starts to move at a rapid pace and our ability to build</p>
<p>these categories um in meaningful ways starts to also really increase and become quite</p>
<p>exciting so again this method is about asking whether there are certain biological</p>
<p>functions that can characterize genetic variants with plyotropic effects which you know there’s a lot of kind of</p>
<p>convergence of findings across disorders that tend to cluster together unsurprisingly psychiatric disorders</p>
<p>tend to be enriched within brain regions but now we’re really trying to quantify that using this multivariate method</p>
<p>for stratified analyses and at the most fine-grained level of analysis genomicsum can be used to</p>
<p>perform multivariate g wasps to look at snip effects on any model parameter that you would</p>
<p>estimate in genomics m and the way we do that is that we extend that s matrix i showed you earlier</p>
<p>when walking through the two-stage process we’ve got that same genetic covariance matrix from ld score</p>
<p>regression here in blue and then we append this snip column</p>
<p>that include the snip variance from a reference panel and the betas from the g-was summary statistic scaled to covariances</p>
<p>using that same snip variance from the reference panel and so what you would do is the package</p>
<p>builds this matrix as many times as there are snips present across the indicators and then runs</p>
<p>any particular model that you might specify that includes an individual snip um so for example we look at snip</p>
<p>effects on a p factor that’s defined by these five psychiatric indicators of schizophrenia bipolar major depression</p>
<p>ptsd and anxiety we take this ld score regression matrix and append</p>
<p>the snip column and then we’re able to look at the effects of an individual snip such as this particular snip that</p>
<p>we find is genome-wide significant with respect to its effect on the p-factor</p>
<p>in the context of multivariate g-wasps we also have developed this snip heterogeneity metric which we call</p>
<p>q-snip because of its similarity to the meta-analytic cue statistic that really ask whether or not the</p>
<p>associations between a given snip and the individual disorders like i’m showing here in panel a</p>
<p>is sufficiently captured by a model that posits a single association between the snip and the factor so really is it</p>
<p>kind of if you just fit this one relationship is that obscuring the relationships that</p>
<p>you might get if you fit all of these individual relationships so we compare this common and independent pathways model</p>
<p>and if this model and panel a fits much better then that suggests that this snip is not really operating through the</p>
<p>factor and an instance where you might see that is if for example there’s highly disorder specific effects so if a snip</p>
<p>really is specific to one of the indicators and has a null effect or an opposite effect on</p>
<p>the other indicators then you would expect to get a significant q-snip metric and this really highlights that</p>
<p>genomics and is not about boosting power for the individual traits and the way that some other multivariate methods are</p>
<p>designed like mtag but it’s really about finding the snips that operate through the factors</p>
<p>and the snips that are highly specific to the disorders so we can start to get a sense of the multivariate picture</p>
<p>across the different disorders that we include in the model</p>
<p>um this is one particular application of a model that you could fit in genomic sem that</p>
<p>people have shown some interest in namely g wasps by subtraction where you fit this sort of koleski model</p>
<p>for two traits and then you have the snip predict the two latent factors within the</p>
<p>koleski model so in this particular example we’re looking at the effects of</p>
<p>a snip on cognitive performance and on educational attainment minus the genetic overlap with cognitive</p>
<p>performance for what we’ve called this kind of non-cognitive element so that then you can start to</p>
<p>kind of break apart something that’s really multifaceted like educational attainment and ask what snips underlie this overall</p>
<p>genetic signal that are separate from the cognitive component this is in a paper that is currently on</p>
<p>bioarchive but is forthcoming and this is just a highlight that then you can produce these manhattan plots</p>
<p>for the cognitive um phenotype and the non-cognitive phenotype down here</p>
<p>and identify these kind of dissociable genetic signals and then in the paper they also look at</p>
<p>kind of polygenic score prediction for these two different phenotypes and find divergent patterns of prediction and also genetic correlations with outside</p>
<p>traits so this is just kind of one way that you can apply genomic sem</p>
<p>in interesting ways um in general it’s just a kind of sales pitch for genomics</p>
<p>m the different groups that have used it and using the open source r package have</p>
<p>been fairly successful in publishing um in a lot of different outlets</p>
<p>so this is just kind of a flavor of the different ways that people have been using it and the outlets that they have been</p>
<p>publishing in using genomic sem um so with that i want to transition as</p>
<p>someone who’s trained in clinical psychology to my main interest in psychiatric phenotypes</p>
<p>and how i’ve used genomics m to really understand the multivariate genomic architecture across psychiatric traits so</p>
<p>i just want to kind of start by explaining why i think um multivariate work and</p>
<p>psychiatric disorders is so important to begin with even ignoring the genomic piece so in this orange circle i’m just</p>
<p>showing kind of all individuals with mental disorders um that will meet criteria for a</p>
<p>disorder in their lifetime and among that group of people about two-thirds are going to meet criteria</p>
<p>for a second disorder half will meet criteria for a third disorder and 41</p>
<p>will meet criteria for a fourth disorder and while we know that um our just our categories are not</p>
<p>perfect we do kind of think of them as sort of these mutually exclusive things where i think when clinicians</p>
<p>sometimes talk about people having multiple disorders there’s this sense that they’ve just kind of</p>
<p>had bad luck in terms of maybe the environments or genetic risk factors that they’ve been exposed</p>
<p>to but really at the end of the day i think this speaks to how much our categories overlap pretty substantially</p>
<p>and how much we should think about kind of refining future versions of our diagnostic manuals so that we can create</p>
<p>more mutually exclusive categories and i think there’s a lot of really compelling reasons to think about why we would want</p>
<p>to do that um but before i get to that this is just kind of depicting the extent to which</p>
<p>we might kind of loosely think about um these patterns of comorbidity and</p>
<p>kind of the loose um rough borders that we’ve drawn between the disorders as being somewhat</p>
<p>genetic in nature so on the x-axis here we have parent disorders across depression</p>
<p>generalized anxiety panic substance use and antisocial personality disorder and on the y-axis the odds ratio for</p>
<p>their child developing a particular disorder and what we see is that the children are really at risk for any disorder and not</p>
<p>just the disorder present in the parent now of course that could just mean that a parent having a mental disorder is</p>
<p>sort of generally stressful through an environmental component that kind of generally leads you at risk to any disorder or</p>
<p>it could mean that the genetics passed down from the parents are really kind of unspecific in terms of how they convey</p>
<p>risk but at the very least that suggests that the boundaries between the disorders are pretty blurry</p>
<p>at the end of the day um and so again that’s important because um as someone who also um</p>
<p>currently practices it can be very stressful to meet with someone and tell them that they’ve got every disorder in the book i think this</p>
<p>has real clinical implications in terms of the message that sends to the patient in the room and also what it means for a treatment</p>
<p>provider to think about what kind of intervention to give somebody when they’re meeting criteria for multiple</p>
<p>categories and from a scientific perspective i think this also has</p>
<p>a lot of important ramifications where if you have scientists a studying bipolar disorder scientists be studying</p>
<p>schizophrenia um and this fellow is studying ocd but at the end of the day we know that these</p>
<p>disorders are all related in some pretty substantial way it probably isn’t the best use of grant</p>
<p>funding money to give all these people a separate pool of money and then just kind of send them off in separate directions when they’re really</p>
<p>studying these phenomena that are actually interrelated in pretty substantial ways in some level</p>
<p>um and so that is why as a kind of backstory i’m particularly interested in</p>
<p>understanding the genomic architecture across different disorders which i think</p>
<p>doing it in a genomic space has a number of advantages one it can give us insight into what we know is a pretty important</p>
<p>component of these disorders since they’re all estimated to be pretty heritable but one limitation when people are</p>
<p>understanding what’s called as this general psychopathology factor a trans</p>
<p>diagnostic p factor is family-based research on p is inherently limited to relatively common</p>
<p>disorders because it’s going to be next to impossible to obtain genetically informed samples on</p>
<p>rare disorders and in just a basic cross-sectional sample again i noted that some of the disorders actually disallow one another</p>
<p>so it would be not possible to actually examine disorders within the same sample</p>
<p>so for the first time methods like genomic sem building off ld score regression allow us to look at the</p>
<p>genetic structure across both common and rare disorders because ld score regression is able to</p>
<p>estimate the genetic relationships across samples that are potentially independent</p>
<p>at the end of the day um i want to walk through the different iterations of these factor models that</p>
<p>we’ve done now so i showed you this earlier in the context of the snip model but um at the base model</p>
<p>we modeled in that initial paper the relationships across these five disorders and pulled out what we called at the</p>
<p>time this kind of general psychopathology factor um i kind of am referring to it as a</p>
<p>so-called general psychopathology factor because um we also only had five disorders at</p>
<p>the time that were sufficiently powered to put in the model and as we started to</p>
<p>include more disorders this model started to look a little bit more nuanced than just a single common factor so in the second major iteration of this</p>
<p>we worked with the cross disorder group from the psychiatric genomics consortium to publish this paper in cell where we</p>
<p>looked at the genomic relationships across these eight disorders of anorexia ocd tourettes</p>
<p>schizophrenia bipolar mdd adhd and autism and what we found is that these kind of segregated into these three factors</p>
<p>that we loosely call a compulsive disorders factor a psychotic disorders factor and a</p>
<p>neural developmental disorders factor and let’s briefly mention too that um</p>
<p>you know things like an ocd and tourette’s loading under the same factor is very consistent with what we might</p>
<p>expect based on comorbidity rates and kind of convergent patterns across different research groups same thing for</p>
<p>schizophrenia and bipolar um one kind of lone wolf here is mdd</p>
<p>and we were able to improve on that when we in our most recent iteration of this</p>
<p>model now include 11 major disorders now with alcohol use disorder here in red ptsd and anxiety and with the</p>
<p>inclusion of ptsd anxiety we’re now pulling this fourth internalizing disorders factor</p>
<p>um but i would highlight also that for a number of these disorders the sample size is updated pretty substantially</p>
<p>relative to the previous iteration and even with that update we were still pulling out the same</p>
<p>three factors when we going through the exploratory factor analyses um so again this kind of indicates that</p>
<p>there is a lot of intercorrelations across these disorders but there is some kind of nuance in terms of how these disorders</p>
<p>kind of segregate into these subgroups and in fact if you just kind of look at the genetic correlation matrix across</p>
<p>these 11 disorders you can kind of see these factors kind of pop out when you</p>
<p>order the matrix according to the factors that we modeled where you’ve got this kind of subcluster up here factor one this really tight cluster</p>
<p>between schizophrenia bipolar and factor two and in particular this really um apparent cluster between ptsd and mdd</p>
<p>and anxiety on that internalizing fourth factor because there were you know correlations</p>
<p>across these factors and because of the kind of growing interest in this overall p factor we did model</p>
<p>an overarching p factor that explained the genetic relationships between these four</p>
<p>different factors and found that this fit the data pretty well but given these kind of partially</p>
<p>competing models of either kind of four correlated factors or an overarching factor we wanted to go on to do</p>
<p>some other analyses to really evaluate the utility of each of these factors for understanding shared biology</p>
<p>across their indicators and we did that in a number of ways one is we took</p>
<p>the same logic that we developed for q-snip and applied it to examining the relationships between</p>
<p>relevant external correlates for psychiatric disorders and so again in a very similar manner to</p>
<p>q-snip we ask whether or not the associations between an external trait and the individual disorder shown</p>
<p>in panel a is sufficiently captured by a model that just shows a single relationship between</p>
<p>the external trait and factor one and we compare the fit of these models and would expect there to be</p>
<p>a really significant decrease in fit by just modeling this common pathways model when these associations are really</p>
<p>discrepant across one another um we fit these sorts of models for 49</p>
<p>different external traits and i just want to walk through um a number of these findings so</p>
<p>i’m showing a couple different things here and color-coded at the top are the four different factors from the correlated</p>
<p>factors model and then the p factor in turquoise and then whether or not the bar is shown with a solid or dashed</p>
<p>outline indicates whether or not it was significant for that cute trait metric where bars with a dashed out line</p>
<p>we found to be significantly heterogeneous across the indicators so within socioeconomic outcomes we see</p>
<p>that there’s a relatively homogeneous relationship between a lot of these outcomes and the compulsive disorders</p>
<p>factor in the positive direction when we look at health and disease we see</p>
<p>a lot of positive correlations the internalizing disorders factor</p>
<p>um and these health disease outcomes which is very consistent with phenotypic work</p>
<p>and within anthropomorphic traits we do see i think a particularly interesting finding for the compulsive disorders</p>
<p>factor of a negative correlation between body mass index and waist to hip ratio</p>
<p>and i mark that as interesting because anorexia loads on that factor and you might think that that is really</p>
<p>driving the relationship between bmi and waist to hip ratio given low weight status as</p>
<p>a diagnostic prerequisite for meeting criteria for anorexia but in fact we see</p>
<p>that there are actually shared pathways with ocd and tourette’s between</p>
<p>um these external correlates indicating that there’s some sort of shared general risk between um kind of these</p>
<p>anthropomorphic traits and this compulsive disorders factor and then finally we see that there’s a lot of homogeneous relationships</p>
<p>with neuroticism but not with this internalizing factor in neuroticism which might come as some surprise but</p>
<p>it’s largely driven by a much higher genetic correlation with</p>
<p>the mdd indicator and if we look at these correlations overall</p>
<p>we see that in particular um there’s the significant q trait metric for the</p>
<p>neurodevelopmental and p factor indicating that a lot of the relationships with external traits are not</p>
<p>operating through these factors and suggesting somewhat limited clinical utility for these two factors relative to these</p>
<p>compulsive psychotic and internalizing disorders factor</p>
<p>we when then went on to perform multivariate wasps and sort of two main steps um in the</p>
<p>first one we looked at the snip effect as it concurrently predicted these four correlated factors and then a snip predicting this</p>
<p>overarching general psychopathology factor um just to orient you to these miami</p>
<p>plots i’m showing on the top half the factor snip effects and on the bottom half the q snip</p>
<p>effects um that i’ve talked about earlier in this talk in black triangles i’m showing the 132</p>
<p>hits across these four factors that were nld with hits that were identified for the individual disorders</p>
<p>that defined the factors in red i’m showing 20 novel hits that were not significant</p>
<p>for any of the individual disorders which highlights the ability of genomic stem to make novel discovery even without</p>
<p>collecting any new data and again i’ll say that with the caveat that i really</p>
<p>try to be careful to not frame genomic sam as a method for boosting power but for ultimately looking at</p>
<p>shared genetic signal and divergent genetic signal across different traits but at the same time because you are</p>
<p>leveraging shared power you are going to get some kind of boost in signal for a lot of these disorders and then in</p>
<p>purple i’m showing the purple diamonds the significant q snip effects so for the compulsive disorders factor</p>
<p>these particular disorders were not super well powered so there’s not much signal we see a lot of shared signal for</p>
<p>the psychotic disorders factor for the neurodevelopmental disorders factor we see a sort of</p>
<p>um somewhat even balance of factor and q snip signal and internalizing disorders factor a</p>
<p>much stronger signal for the factor and if we look at the qq plots for these different disorders</p>
<p>what i’m showing here in blue is the signal for the factor and in pink the signal for q-snip and</p>
<p>what we would expect if the factor is generally capturing the relationship between the individual</p>
<p>snips and the individual disorders that define the factor is that this blue line would sit kind of nicely above this pink line</p>
<p>and that is what we observe for the compulsive psychotic and internalizing disorders factor but</p>
<p>on the other end we see that the qcnt metric is actually much stronger</p>
<p>than the factor signal for the neural developmental disorders factor which indicates that a lot of the</p>
<p>genetic signal is not operating through the factors so similar to what we observed for the patterns with external traits</p>
<p>for individual steps we find that they are often not operating through that neurodevelopmental factor</p>
<p>and if we look at the individual snip effects for some of the snips that were particularly q snip significant we see</p>
<p>that a lot of that is due to divergent effects for autism which also loads on that factor it may</p>
<p>come as no surprise so that’s not to say that a neurodevelopmental factor in a kind of</p>
<p>hypothetical sense might not prove to be useful but at least in the way that we’ve defined it based on the data that we had it doesn’t</p>
<p>seem to be sufficiently kind of explaining the shared signal across its disorders</p>
<p>and then if we look at the signal for the p factor we see a really striking imbalance</p>
<p>between the factor signal and the q snip sniggle where we see only one hit um that was in ld with an individual</p>
<p>disorder hit no new loci and 69 cue snip hits and just a really</p>
<p>elevated pink line relative to that blue line indicating that almost none of the snip effects are</p>
<p>operating through that p factor which really suggests that there is kind of limited utility</p>
<p>to a p factor for actually understanding shared biology across disorders</p>
<p>um finally i just want to kind of go over the um stratified genomic stem findings</p>
<p>for this particular 11 disorders model and i want to focus on</p>
<p>some findings for enrichment of brain cell types so we know that psychiatric disorders</p>
<p>are generally enriched for genes expressed in the brain which is sort of i feel like more of a</p>
<p>sanity check to see that it’s not expressed in you know the spleen or the stomach but is really</p>
<p>in the central nervous system like we’d expect but with more recent single cell sequencing</p>
<p>um efforts coming out people have been able to pair that up with gywas summary data to actually look</p>
<p>at enrichment of specific brain cell subtypes which gives us maybe a little bit better target in terms of</p>
<p>where that signal is coming from within the brain we also know that protein truncating</p>
<p>variant intolerant genes which is referring to specific genes that</p>
<p>generally do not show mutations are enriched across disorders so these</p>
<p>genes might be particularly relevant for just kind of functioning in general and so what we did is we created annotations</p>
<p>for pi genes brain cell subtypes and their intersection to examine whether or not prior</p>
<p>enrichment patterns actually reflect some sort of pliotropic signal across disorders</p>
<p>and so here i’m showing those stratified genomic sem findings for examining enrichment of the factors in</p>
<p>orange i’m sewing the glial cell category in dark blue</p>
<p>slash purple the excitatory brain cell subtypes and then the gabaergic subtypes the pi</p>
<p>genes and then their intersection over here in the right most part of the plot for the different factors</p>
<p>and what we see is that there’s a really unique signal for the psychotic disorders factor with an excitatory and</p>
<p>gabaergic um genes um within the pi genes and a signal that is particularly enriched for</p>
<p>their intersection and so i think this starts to give us some real traction</p>
<p>in terms of being able to understand what it is that the psychotic disorders factor is capturing in terms of where</p>
<p>that genetic signal is coming from and also starts to point towards some reasons that these disorders might</p>
<p>actually diverge and actually look both phenotypically different and not share genetic signal at the level of this p</p>
<p>factor over here um [Music] and i also would just highlight that if</p>
<p>you were to go into google scholar right now and type in any of these um sub neuronal sub cell types for</p>
<p>bipolar disorder schizophrenia you could really make a case based on the prior literature that really any of these are relevant to</p>
<p>the factor and of course this is just one study among many um but we’re using a pretty high powered</p>
<p>set of g-was summary statistics paired with some pretty cutting-edge rna-seq data that shows that really these glial cells</p>
<p>are not particularly relevant for the psychotic disorders factor as we’ve defined it here</p>
<p>so in conclusion um we’ve really expanded the genetic factor model of psychiatric risk to identify</p>
<p>four major factors of genetic risk sharing we find relatively high utility of the</p>
<p>psychotic and internalizing disorders factor when we go on to really kind of stress test these factors</p>
<p>using different follow-up analyses including those q-snip and q-trait findings i talked about earlier</p>
<p>where we find that the associations between relevant external traits and individual snips</p>
<p>are generally captured by the factor for the compulsive disorders factor i</p>
<p>would really frame this as a factor where the jury is still out in terms of its utility</p>
<p>namely because the gwas summary statistics that define that factor are still relatively low powered</p>
<p>we do see that it does a pretty good job of explaining relationships with external traits but at the level of</p>
<p>individual snips there’s just not really the signal there to see whether or not it’s operating through the factor or through the</p>
<p>individual disorders and for the neurodevelopmental factor we really see</p>
<p>some pretty low utility where a lot of the relations and the disorders that define this</p>
<p>factor are relatively unique in terms of their patterns of genetic correlations with external traits and a lot of the snip</p>
<p>associations did not operate through the factor in a way that seemed largely attributable attributable to</p>
<p>a signal that was unique to autism relative to ptsd and adhd that also</p>
<p>loaded on this factor um we also know that we can model a p</p>
<p>factor using a genetic correlation matrix um in line with a lot of phenotypic and family based work that’s been done</p>
<p>but when we stress test this factor we find that this in particular has incredibly low utility to the extent</p>
<p>that it obscures relationships with external correlates and sniff associations</p>
<p>this might be due to the fact that there are sort of kind of unique um bivariate associations between</p>
<p>different factors that are not captured across the factors as a whole so for example there might be some sort of</p>
<p>shared signal between the psychotic disorders factor and compulsive disorders factor</p>
<p>that results in that genetic correlation between those two factors that is really dissociable from the signal between a psychotic disorders</p>
<p>factor and an internalizing disorders factor um so it’s kind of this</p>
<p>complex venn diagram across these factors that does not include this kind of p factor at the center at</p>
<p>least in the way that we’ve examined it here which we think has pretty broad implications for a pretty rapidly expanding p factor</p>
<p>literature with um a lot of articles coming out all the time about this p factor</p>
<p>using stratified genomic sem which is that new genomics sum edition that is live on our</p>
<p>github we find that prior enrichment findings generally reflect broad pathways of risk and we find in particular the</p>
<p>intersection of pi excitatory and gabaergic genes are in which for this psychotic disorders</p>
<p>factor which gives some real insight into the biological pathways that might underlie the really high</p>
<p>genetic correlation between these two very debilitating disorders of bipolar disorder and schizophrenia</p>
<p>and again as rna-seq methods get even better and the corresponding univariate g-wasps become even better powered</p>
<p>we’re going to be able to make these categories even more refined and even put them within developmentally specific windows such as excitatory</p>
<p>neurons expressed during a specific period of development which i think is</p>
<p>you know just at face value could be a really exciting set of findings</p>
<p>um and just to end on a kind of sales pitch note um a lot of you have heard me talk about genomic sem but i hope that</p>
<p>it’s clear that this is a pretty flexible method in terms of its ability to ask a number</p>
<p>of different interesting questions whether you’re looking at something like g was by subtraction just doing some general factor modeling</p>
<p>um or trying to examine systems with relationships across traits that you might not be able to otherwise examine</p>
<p>because of how rare or mutually exclusive they are it is an open source r package that’s publicly available with</p>
<p>a github um and a uh google group that you can ask</p>
<p>questions on and stratify genomics m is now live on the github and</p>
<p>you know one of the reasons that it’s exciting to talk to a group like this is not just to talk about the work that i’m doing which in and of</p>
<p>itself is you know fun to do but it’s also great to hear what kind of questions people have and also</p>
<p>potentially develop collaborations projects or grant ideas and</p>
<p>just as an aside i’m on my internship my clinical internship year at mass general hospital in boston but i will be</p>
<p>starting as an assistant professor at cu boulder in the fall so again if people have projects or grants that they want to</p>
<p>work on this is obviously a group that i would be particularly interested in collaborating with</p>
<p>and so i’ll just end by um [Music] naming and thanking a number of different people in in particular elliot</p>
<p>tucker drove and michelle navarre who have been really central to working with me to develop genomics</p>
<p>its extensions and a number of different people named here and of course also thanking groups like the</p>
<p>psychiatric genomics consortium isec and uk biobank that really contributed to the data sets that i presented here</p>
<p>in terms of the application of genomic stem to psychiatric traits so that’s all i</p>
<p>have um but again i just want to thank everyone for inviting me and for your time and curious to hear what</p>
<p>questions people may have andrew thank you for a fascinating talk how i’d like to structure it</p>
<p>the q a is that sam trejo who suggested you come talk to us and we really appreciate that suggestion will give us</p>
<p>the first question and for those who have follow-up questions in that conversation i suggest you jump</p>
<p>right in but for those who have other questions if you could just queue up in the chat i’ll moderate that to tell who</p>
<p>to tell us who’s next so sam’s going to give us the first question and then we’ll go from there sounds great hey andrew really cool talk</p>
<p>i sam thank you um my question is is kind of about this idea that i think is true for this earlier</p>
<p>stuff you talked about with the geos by subtraction and the sort of non-cognitive cognitive</p>
<p>parts of educational attainment but but it seems like it extends later on into the stuff that you’re doing with um</p>
<p>like the p factor and all these different sort of um kind of like psychiatric factors uh so so the first</p>
<p>question is like with did you us by subtraction if like if i were just to take the linear</p>
<p>difference between the uh ea some steps like you know beta weights and the um</p>
<p>iq beta weights uh you know i would do like a less sophisticated version of i think what you guys do in that paper</p>
<p>right like i’m just sort of taking the bits in one g-wash that aren’t in the other gus and i was kind of curious like how</p>
<p>similar of an answer would i get do you think or do you know to you know what the genomics m model fits</p>
<p>um and then what are the advantages using genomic sams and then my kind of second question that’s related to all</p>
<p>this is like um well actually i’ll just let you into that one</p>
<p>first yeah now that’s a great question um so michelle navarre actually has</p>
<p>an alternative method that people are probably aware of um geoist you know wide inferred summary statistics that</p>
<p>does something very similar to what you’re describing that just kind of takes the summary statistics</p>
<p>and i’m at that level just kind of pulls out um the shared and unique genetic signal i think the advantage of</p>
<p>genomics m is that um is two things one that you</p>
<p>can kind of actually depict the relationship between these two different sets of traits within like a classic</p>
<p>koleski model in a way that’s sort of intuitive in terms of how the genetic relationships are shared</p>
<p>across these different traits that you’re including um and the other is that my sense is</p>
<p>that if you do um just kind of what you’re describing</p>
<p>you’re potentially gonna get biased results because of that sample overlap piece that</p>
<p>genomic sem is able to account for using the v matrix so if you know that you have two</p>
<p>entirely independent samples and you have no concern about that then i don’t know i think it’s kind of</p>
<p>an open question whether or not the the answer would be pretty similar but my sense is that people are generally</p>
<p>pretty concerned about some level of unknown sample overlap and genomic stem is going to give you</p>
<p>um some ease of mind in that case that you’re actually appropriately accounting for that</p>
<p>yeah that’s helpful that’s helpful and so then kind of the next question is like in both cases i think with the cognitive</p>
<p>non-cognitive and then all these psychiatric factors like we’re now able to basically you know isolate and generate polygenic scores</p>
<p>for traits that just don’t exist and and i guess i mean by that i mean they don’t exist it’s like they don’t they’ve never been measured and it’s not</p>
<p>clear that we would ever able to be able to measure them um and i was just curious if you you know what you thought about that and</p>
<p>whether those sort of apologetic scores um should we like you know we should use them differently or think about them differently</p>
<p>um yeah that’s another great question i mean i think about that too in terms of the factors that we pull out</p>
<p>too i mean this reflects some sort of shared genetic signal across these disorders that isn’t actually directly observed and so</p>
<p>i think it’s always really important to kind of do some follow-up just for yourself um</p>
<p>and for the people who are reading this kind of hypothetical article that you’re putting together to actually characterize what that</p>
<p>kind of new polygenic score looks like so for example by taking non-cognitive</p>
<p>summary statistics and looking at the genetic correlation between a bunch of external correlates so you get a sense of what that signal</p>
<p>is actually picking up on in a sort of kind of multi-dimensional space so um</p>
<p>i totally agree i don’t think we should just start like kind of removing things from one another and just start kind of kitchen sinking things without</p>
<p>any kind of hypothetical guiding force or sense of what these these new summary statistics are picking</p>
<p>up on at the end of the day but i do think there’s a number of things within genomics m um that you can do to kind of clarify</p>
<p>that thanks super helpful yeah thank you everyone</p>
<p>oh yes um thank you for the talk it’s really comprehensive pretty much covered everything about genomicsm um so so i have questions</p>
<p>about some technical details but for the follow-ups probably you can continue in our</p>
<p>individual session after this but for now i i’m very interested in this annotation stratified janome icm so i’m</p>
<p>wondering because if you’re interested in the heritability enrichment of factors in certain regions you actually</p>
<p>don’t have to fit annotation stratified version of genomic sem right you can just run the standard xiaomi sem and get the</p>
<p>juva summary set for those factors and then test if their herd ability uh is enriched in</p>
<p>in certain annotation categories i wonder empirically do you actually see differences when you run the annotation stratified</p>
<p>version of gsem and then characterize you know annotation enrichment</p>
<p>um you do see some differences in general you just see kind of</p>
<p>deflation of signal um i think that’s a great question you know i think that’s one thing that comes</p>
<p>up a lot is just this general idea of like couldn’t you do this in a much simpler kind of more straightforward way um by</p>
<p>yeah just taking the summary statistics for the factors and um running partitioned heritability</p>
<p>on that um the reason that you see deflated signal is that the factor summary statistics are estimated with</p>
<p>error and what i mean by that is those summary statistics are going to include some of that q signal</p>
<p>or signal that is not actually operating through the factor itself so you could think</p>
<p>about kind of pruning based on significant q-snips and then feeding those summary statistics into</p>
<p>partitioned heritability um but i think it’s kind of unclear what threshold to use when you do that</p>
<p>whereas if you’re doing it strictly within a genomic sam sem framework by looking</p>
<p>at enrichment using partition covariance matrices you’re not including that kind of error</p>
<p>that gets introduced into the summary statistics in that way um another thing i would say</p>
<p>is that you can also look at enrichment of the uniquenesses and enrichment of things like factor</p>
<p>correlations so that is sort of a tangent to the question that you’re asking but just to</p>
<p>say that stratified genomic stem i think is kind of more broadly useful in the sense that you can look at things</p>
<p>that you couldn’t really feed into a partitioned heritability analysis like enrichment of factor correlations</p>
<p>um or kind of concurrently looking at enrichment of the uniquenesses within the same model</p>
<p>yeah this is very helpful so a quick follow-up would be that um do you have a sense about how big the</p>
<p>annotation need to be for this to work because my intuition would be that if you have a very small function annotation</p>
<p>um the the annotation stratified genetic covariance estimate will become very noisy so then when you fit a separate genomic</p>
<p>sem in in that you know genomic region alone maybe maybe it will be challenging to</p>
<p>converge right so empirically based on the sample size in your analyze summary stats how big can annotation be</p>
<p>um one thing as far as the model converging is that and the way that the estimation procedure is coded</p>
<p>is that we kind of fix the estimates from the annotation that includes all snips</p>
<p>and then re-estimate the model with those fixed estimates and the partition specific covariance matrices</p>
<p>so that helps a little bit with just kind of wonky model estimation in terms of just like um genetic</p>
<p>covariance estimates that are really imprecise you know i know that this is i’m clear</p>
<p>to you but just to sort of um put out there that you know we have the partitioned sampling covariance</p>
<p>matrices too so you don’t run a danger of false positives in the sense that if a covariance estimate</p>
<p>and the partition space is really imprecise then it’s also going to have a huge standard error that ports over to the enrichment</p>
<p>estimate so there are certain annotations that are really small where you get like a huge enrichment estimate but with</p>
<p>a a confidence interval around it that is humongous at the same time um</p>
<p>so big point estimate but not significant in that sense in terms of annotation size i don’t have</p>
<p>like a great sense of how small um it needs to be</p>
<p>i mean these pi by brain cell subtype annotations are not humongous um</p>
<p>[Music] but um yeah i don’t i don’t have a concrete answer for that</p>
<p>the other thing i’ll say is that when we first started this project my interest was in actually looking at whether or not the factor structure changes across</p>
<p>annotations and that we are not powered to do for the reason that you’re</p>
<p>kind of highlighting that there’s a lot of just kind of random noise in the covariance estimates so that you get these kind of fluctuating</p>
<p>factor structures that don’t actually reflect something that seems to actually be changing in the population</p>
<p>so that’s why we’re not doing kind of partition specific factor structures but</p>
<p>more kind of fixing the model in the genome-wide sense and then looking at enrichment of particular model parameters</p>
<p>yes great thank you of course we had an overlapping question that</p>
<p>philip and james asked about modelfit i think the general question is how you think about model fit</p>
<p>but maybe james could fill in a more precise targeted question</p>
<p>sure yeah thanks for the talk andrew that was extremely helpful and informative and exciting um</p>
<p>so my question i i think it’s similar to phillips although he can certainly jump in here is</p>
<p>is that when we’ve tried to fit these more complicated models in gsam</p>
<p>where we have more than just the five right like you did with the 11 the problem that we ran into was that</p>
<p>the the more complicated your model gets the harder it is to actually produce a strong fitting model</p>
<p>so i’m just wondering since you didn’t really talk about it in your slide is is uh when you were able to successfully</p>
<p>extract these uh four different latent factors how well would you say that the overall</p>
<p>model actually fit the data to the extent that you feel confident that this neurodevelopmental factor is</p>
<p>in fact a truly unique factor can you speak a little bit about that yeah so um</p>
<p>that four factor model does fit the data well by conventional standards so cfi i think is</p>
<p>like .96 um [Music] srmr is i think .06 for that model so</p>
<p>using like these kind of arbitrary cutoffs um we find that the model fits pretty well</p>
<p>we see really clear increase in model fit as we kind of move from a common factor model to this more nuanced four</p>
<p>factor model um of course you know there’s the trade-off of</p>
<p>you know a more complicated factor model is always going to fit the data better um but it it kind of hit this point</p>
<p>where hypothetically the factors that we were pulling out made a lot of sense um it seemed to fit the data pretty well</p>
<p>and as we kind of included you know updated summary statistics we were consistently pulling</p>
<p>out the same factors using um a kind of restarted exploratory procedure</p>
<p>so you know at the same time i think that you can have genetic correlations</p>
<p>are such a broad kind of 10 000 foot metric that in the way that we showed with these kind of q</p>
<p>follow-up analysis that’s important to really stress test these factors because you know we can model a p factor we can</p>
<p>model a neural developmental factor but that might be that it’s kind of aggregating across these really</p>
<p>dissociable pathways um at different levels of analysis so i think that model fit is just one</p>
<p>piece of this puzzle i agree entirely and i’ll follow up with you in our individual meeting but</p>
<p>one one additional thing i just wanted to add was was the the alignment of the models that you</p>
<p>extracted and with theoretical uh alignment with our theory of what these</p>
<p>factors should be so for instance in your neural developmental factors disorders you had ptsd</p>
<p>autism adhd and i think tourette’s right so you know to what extent does that align</p>
<p>with for instance high top models of neurodevelopmental disorders or or even dsm</p>
<p>perspectives of what neurodevelopmental disorders are classified as not that we necessarily agree with the dsm but</p>
<p>but i’m just saying that you know there’s this the quantitative piece in which the the disorders fit these this type of</p>
<p>structure but then there’s also how well does that fit with our theoretical understanding of how these disorders should look or how they</p>
<p>present yeah i mean um it’s sort of a mix of</p>
<p>both and i think that that’s you know in some ways kind of nice like you would hope that after spending</p>
<p>millions of dollars to do genomics we don’t just recapitulate what we already knew in some way but actually get some kind</p>
<p>of novel insight and the real interesting thing within this neurodevelopmental factor is ptsd</p>
<p>and the reason i highlight that is we actually see that ptsd and adhd are correlated</p>
<p>greater than 0.7 across multiple separate cohorts which is not something that you would</p>
<p>get from reading the dsm or just from practicing clinically i don’t think</p>
<p>and so there’s sort of a separate project going on that’s really trying to tease that apart adhd and autism i would argue you know</p>
<p>there’s some good reason to think they would load together um but in a purely kind of exploratory sense that particular factor</p>
<p>i think is is the odd one out particularly because ptsd is is loaded so strongly due to its</p>
<p>relationship with adhd but that relationship is there and we</p>
<p>feel pretty confident that it’s there because of how consistently we see that across independent cohorts</p>
<p>is one of your questions short enough that it would be a minute or two long um oh my god</p>
<p>i’m not really sure but but anyways let me just briefly say andrew i’m so glad that i that i heard that you accepted this job</p>
<p>offer from boulder so i i know that matt keller is like super excited about you know that that you’re coming there</p>
<p>and i only heard it from him like very recently that this is finally working out so thumbs up congratulations</p>
<p>so actually i had a lot of like very far drifting like comments and questions that may actually be really better if</p>
<p>i talk to you separately about this but maybe just one very concrete thing so um i was just wondering if genomic</p>
<p>sem actually makes use of the standard errors that uh ld score regression rg estimates spit</p>
<p>out or are you only losing using the point estimates themselves we’re also using the standard errors</p>
<p>in that in that v matrix okay well so then there is this um there is a</p>
<p>slightly weird thing that um if you construct the the genetic correlation matrix with a bivariate</p>
<p>method that doesn’t take the entire multivariate structure into account like lesd ldsc right so that’s</p>
<p>really just bivariate by variant then the resulting um matrix may actually not be a</p>
<p>positive semi-definite and the uh the standard errors are actually not necessarily theoretically correct</p>
<p>so um i mean there is a way how you can actually uh uh get the correct standard errors but</p>
<p>it would be a completely different method it will basically be a multivariate version of of grammar</p>
<p>uh which would have some advantage of some disadvantages but i’m just thinking is it theoretically</p>
<p>possible that you fit that that you built your genomic sem model</p>
<p>based on standard errors and rg estimates that are not coming</p>
<p>from ldsc but let’s say from multivariate grammar um it is and i think at one point</p>
<p>ronald was maybe working on that even um exactly yes this is where this is</p>
<p>coming from exactly yeah yeah um and you know there’s it’s sort of</p>
<p>like this um kind of constant thing that is like you know these different kind of bivariate methods come out</p>
<p>to how we could maybe incorporate that to kind of build out these matrices i will say that we</p>
<p>um you know the sampling covariance matrix is estimated within our multi-variable</p>
<p>version of ldsc um but and the block jackknife kind of precedes</p>
<p>in a way that is similar but different in that we’re also populating those off diagonal elements but that actually doesn’t answer your</p>
<p>question so your point still holds um and i think yeah um</p>
<p>trying to incorporate some of the stuff that ronald’s been working on as a real interest cool all right thanks of course</p>
<p>i think we could keep you for a long time with these uh with this question some answers andrew but we thank you again for coming i know you’re going to</p>
<p>stick around for the beginning of your individual meetings yes i want to just on behalf of the group thanks for such a clear</p>
<p>and interesting uh discussion and presentation yeah thanks everyone really great</p>
<p>questions and it was a real privilege to present to you all.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>