<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>PGC Video Textbook - Chapter 8.5: Fine-mapping (Video Transcript)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">


<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">PGC Video Textbook</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./contact.html" rel="" target="">
 <span class="menu-text">Contact us</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://pgc.unc.edu/" rel="" target="">
 <span class="menu-text">PGC Website</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Chapter 8.5: Fine-mapping (Video Transcript)</li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      <img src="./pgc_logo_website_v3.jpeg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <div class="dropdown">
      <a href="" title="" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label=""><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="">
            Source code
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="">
            Report a bug
            </a>
          </li>
      </ul>
    </div>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./welcome.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to the PGC Video Textbook!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./toc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Table of Contents</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Chapters</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: The Genome</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Technologies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Study designs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: GWAS analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Polygenic Scores</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 7: Ancestry-Specific Analyses and Considerations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 8: Post-GWAS bioinformatics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 9: Advanced Topics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 10: Other Considerations</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Software Tutorials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_cnvs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CNVs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_conditional.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conditional Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_crossdisorder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cross-disorder Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_ewas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EWAS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_geneset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gene Set Identification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_gwas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GWAS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_genomicSEM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Genomic SEM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_imaging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Imaging</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_MR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mendelian Randomization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_prs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PRS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software_correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">SNP Heritability and Genetic Correlation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Additional Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Glossary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Software Resources</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./addreading.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Additional Reading</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://pgc.unc.edu/for-researchers/download-results/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PGC Summary Statistics</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Chapter 8.5: Fine-mapping (Video Transcript)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><strong>Title</strong>: Introduction to fine-mapping methods</p>
<p><strong>Presenter(s)</strong>: Hilary Finucane</p>
<p>good morning everyone and welcome to the MGP primer for today it’s 8:30 so we’ll go ahead and get</p>
<p>started with the introductions so this is our penultimate primer for the season</p>
<p>and we are very happy today to have dr. Hillary Hillary then who can today to</p>
<p>speak to us about fine math dating methods her background includes bachelor’s in Harvard in math from</p>
<p>Harvard she then followed that up with a master’s in theoretical computer science</p>
<p>him went on to then complete a PhD in applied math at MIT she was selected for</p>
<p>a very prestigious and IH director’s early independence award and has been</p>
<p>doing wonderful work here at the broad she’s now co-director of the program in</p>
<p>medical and population genetics and she’s also a assistant investigation at</p>
<p>the analytic and translational genetics unit at MGH and is about to being the</p>
<p>assistant professor at HMS and we are so thankful for her today for sharing this presentation with us she’s happy to take</p>
<p>questions and has natural pauses built in her talk but I will also keep an eye on any raised hands and Q&amp;A and so we</p>
<p>welcome your participation thank you very much thanks very much Sarah for</p>
<p>that lovely introduction and hi everyone I’m happy to be talking today about</p>
<p>Bayesian fiying mapping methods and this isn’t going to be a comprehensive review I’m going to try to give an overview to</p>
<p>some of the main ideas in the field but as Sarah said I’m very happy to take questions as I go and answer I’ll be</p>
<p>moderating those questions so let me start by talking about the context for</p>
<p>affine mapping so in a genome-wide Association study we see often these</p>
<p>days many genome-wide associated regions so here’s an example of a Manhattan plot from the 2014 schizophrenia to us where</p>
<p>every green diamond is now Janome its locus that’s past genome-wide significance and that naturally invites</p>
<p>the question was actually going in the locust and there’s a lot of</p>
<p>questions that that we can ask about a particular locus that can mean a lot of things and what I’m gonna focus on now</p>
<p>is what are the actual variants that are driving the Association at the locus and</p>
<p>so typically when we zoom in on a locus we might see something like this so here</p>
<p>we’ve got your moment coordinates on the x-axis and then level of significance on the y-axis and this is an example from</p>
<p>Highland Kwan’s IBD analysis and what we imagine is going on is that there’s</p>
<p>actually a simple underlying causal structure or maybe there’s only two causal variants in the locus and it’s</p>
<p>only because of patterns of LD and then the noise due to finite sample size that we see all of these many variants coming</p>
<p>up as associated in this in this way and so the goal of statistical affine</p>
<p>mapping is to take the Jewess data that shows this complex Association at the</p>
<p>locus and to try to you know detangle it and figure out what’s the actual simple</p>
<p>story that’s underlying it what are the causal variants that are underlying this association and so why might we want to</p>
<p>do something like this well one reason is if we’re interested in genes if we</p>
<p>can identify the causal variants and these variants sometimes implicate genes for example the variants may be coding</p>
<p>variants that directly implicate a gene or they may be regulatory variants that</p>
<p>that we can then tie to a gene and so so</p>
<p>so if I’m mapping can often help us with this goal of finding causal genes and another reason might be even once we’ve</p>
<p>got the name of the gene we want the variant to gene mechanism and that for example might enable us to do an</p>
<p>experiment that more realistically recapitulates the disease relevant</p>
<p>biology then knocking out the gene altogether and then there’s a another</p>
<p>set of reasons having to do with a genetic architecture and so for example by looking at many fine mapping results</p>
<p>across many low sigh or by building models that are based on online mapping models you might be able to do enrichment analyses which</p>
<p>types of variants tend to be associated or causal for disease moving from</p>
<p>association to find mapping can also enable cross population and cross trait comparisons and has the potential to be</p>
<p>particularly useful in prediction and so there’s a lot of a lot of things that</p>
<p>we’re trying to do that become easier once we have some model that lets us get</p>
<p>not just Association but rather to make some inference about causal structure</p>
<p>and so today I’m gonna focus mostly on</p>
<p>different aspects of statistical methods for fine map and this is the outline I’ll start by talking about posterior</p>
<p>inclusion probabilities incredible sets and then I’ll go through a few different methods points and then I’ll close with a some thoughts on evaluate and find</p>
<p>mapping methods and so and I’ll pause after each section here and so maybe</p>
<p>I’ll just start by pausing after that brief introduction if there are any questions so far</p>
<p>great so then let me continue with PII</p>
<p>keys incredible sets what what are these kind of basic concepts so our goal in</p>
<p>fine mapping is to recover the causal variants but of course we can’t always with precise accuracy and perfect</p>
<p>competence recover exactly what the fine mapping with it with the causal variants are and so what does the output of</p>
<p>affine mapping algorithm typically look like well there’s two aspects that I’ll focus on here we’ll take each variant in</p>
<p>the locus and then we can plot it now with the y axis being the posterior inclusion probability so each variant</p>
<p>gets a P IP and then we can also identify sense of variance called credible set so here one credible set is</p>
<p>red and one credible set is blue so what are P IPS and what are credible sets the</p>
<p>posterior inclusion probability for a variant is the posterior probability that the variant is causal and this</p>
<p>courses according to the model so once you’ve bought into all of the</p>
<p>assumptions of your model then the p IP reflects the causality there the causal probably the probability that the</p>
<p>variant is causal and so a p IP of one would be the most confident you can</p>
<p>possibly get and then as the gets lower that means you’re less and less you think it’s less and less likely that</p>
<p>this is actually a causal variance driving the signal and this has a couple of different names posterior inclusion</p>
<p>probability is the most standard one that i’ve seen but some people call this posterior probability of causality or</p>
<p>you may see other acronyms in the literature and then a credible set</p>
<p>typically we talk about 95% credible sets is a set of variants that contains</p>
<p>a causal variant with at least 95 percent probability and so and this has</p>
<p>also been defined in some alternative ways and in some places in the literature but this is now to my</p>
<p>understanding the most standard use and so if we go back and look at this</p>
<p>particular locus you can see that the blue credible set is a set of variants that contains exactly one variant and</p>
<p>that variant has a very high p IP and so that means that there’s one signal</p>
<p>that’s been really resolved very well so the blue credible set says i think that one of the causal variants is here and</p>
<p>i’m pretty confident about it and then there’s a red credible set and so that means there’s a second causal variant i</p>
<p>think it’s one of these five red variants i’m not quite sure which of the five and my posterior inclusion</p>
<p>probability is going to quantify exactly what do i think is the probability that</p>
<p>each one of these variants is is the causal variant for this second signal</p>
<p>and so you can think of each credible set as corresponding to one putative causal variant and it’s reflecting the</p>
<p>uncertainty around which variant is that actual putative causal variant so so</p>
<p>typically when we think about fine mapping methods what we’re interested in is getting a p IP per variant and then a</p>
<p>credible perd you know variant in the locus and then a credible set each one of which</p>
<p>flex one causal variant and the uncertainty around where that causal variant might be so let me again ask if</p>
<p>there are questions so far on P ip’s and credible sets</p>
<p>okay so then with that I’ll dig into some of how do we actually try to compute these P IPs and credible sets</p>
<p>and I’ll start with the case of single causal variant fine mapping so so you</p>
<p>can imagine you’ve done a gos you’ve got a particular locus you’re interested in you’ve got the data on the locus and</p>
<p>I’ll discuss later on whether by that I mean summary statistics and LD or genotypes and phenotypes and now what</p>
<p>you’d like to get are some p IP s and some credible sets and you have a choice</p>
<p>now which is are you going to figure there’s probably only one causal variant in the locus or there may be multiple</p>
<p>causal variants in the locus and the there’s increasingly good evidence in</p>
<p>the field that many loci Harbor multiple causal variants and so that’s going to be an important point but single causal</p>
<p>variant fine mapping is very robust and</p>
<p>and statistically straightforward and it’s also a building block for a couple of the different multiple causal variant</p>
<p>message so first I’m going to talk about single causal variant find mapping so here we have our locus we’d like to know</p>
<p>is what’s the p IP for each variant and then there’s only going to be up one</p>
<p>credible set here because we’re assuming one causal variant and so which variants</p>
<p>should we put into our credible set and the p IP now these p IPS will sum to one</p>
<p>we’re saying there’s actually one causal variant we just don’t know which one it is and so now I’m gonna talk in a little</p>
<p>bit of technical detail for a few slides on how we actually go about doing this</p>
<p>so what is the p IP at snip j let’s</p>
<p>start by computing the p IP it’s NF j and we can write this as the probability under our models it sniffing j is causal</p>
<p>given the data that we have and we’re being bayesian and so let’s say that we</p>
<p>have a flat prior on which variant is causal and so then Bayes rule allows us to say</p>
<p>to rewrite this probability as the probability of the data given J is causal divided by the sum over all</p>
<p>variants in the locus of this probability of the data given with the variant is causal and this is a pretty</p>
<p>straightforward application of Bayes rule and then a trick comes in saying that well in order to make the</p>
<p>computation easier let’s just divide everything into both the numerator and the denominator by this null probability</p>
<p>the likelihood of the data under a null model in which none of the variants is causal and now we can call this new</p>
<p>quantity that we’ve got a Bayes factor so the Bayes factor is the likelihood of</p>
<p>the data given the variant K is causal divided by this null probability and</p>
<p>this just allows us to rewrite our p IP is the base factor person FJ divided by the sum over all variants of the Bayes</p>
<p>factors and the reason that this is a nice thing is because this Bayes factor</p>
<p>turns out to be pretty simple to compute and so Tamala at all showed that the</p>
<p>Bayes factor you don’t actually need to model all of the data at the locus to compute the Bayes factor for a single</p>
<p>variant you only care about what the genotypes are at that particular variant and then Wakefield and others showed</p>
<p>that this base factor can in fact be computed or approximated depending on the model that you’re fitting from</p>
<p>summary statistics and so it can computing this Bayes factor you can just</p>
<p>go one variant at a time and compute a pretty straightforward transformation of</p>
<p>what the of the summary statistics that you’ve seen so in particular this</p>
<p>doesn’t depend on LD at all and is a linear time computation so this is how</p>
<p>for simple causal variant fine mapping you might compute P IPs and so how about</p>
<p>credible sets well let’s first remember how we defined a credible set s is a set</p>
<p>of variants that we’ll call a 95% credible set if the probability that it</p>
<p>harbours the causal variant because we’re in a single causal variant land is at least 95 percent so we now have a</p>
<p>probability for each one of our very that it’s the causal variant and we want to know which causal variant should be</p>
<p>put together so that we are covering at least 95% of the probability space and</p>
<p>because we only are assuming the single causal variant assumption the probability that the causal variance in</p>
<p>s is just the sum of the p IPS of the variance in s and so to construct the</p>
<p>smallest 95% incredible set we can just add the variant that has the highest P</p>
<p>IP and then add the variant that has the second-highest VIP and just keep on going until our p IP son to 95 to 95%</p>
<p>and typically I shouldn’t I should know there’s a lot of different ways to construct credible sets you could always</p>
<p>just throw all of the variants in and that’ll some to more than 95 percent and so usually the goal is to construct the</p>
<p>smallest possible credible set because what you’d like is to have as much</p>
<p>resolution as possible and to be able to say we really narrowed down our signal</p>
<p>to as few as possible variance then the question yes asking what values are part</p>
<p>of the flat prior and what assumptions are made in order to calculate that flat prior absolutely absolutely so so when I</p>
<p>say flat prior yeah your I should have clarified this better what I mean is a flat prior over which variant is causal</p>
<p>which is also something that I’ll come back to so the flat priors here is saying a priori before I seen the G</p>
<p>Wasps data in my locus at all I’m gonna say that every bearing is equally likely to be causal there’s another prior that</p>
<p>has to be defined that has to do with what’s the effect size of each variant in the locus and there you do have to</p>
<p>specify it and that there’s different ways that different folks do that and it</p>
<p>turns out that that might actually be pretty important but for the sake of time I’m leaving that out of this</p>
<p>particular presentation and so here in order for what I said on this slide to hold all what you need is for the prior</p>
<p>on which variant is causal to be uniform across the different variants does that</p>
<p>answer the question yeah there is a follow-up one whether a</p>
<p>single causal variant is a prior that there is only one or no causal variant</p>
<p>or a constraint in this case it’s a constraint so in this case when I say</p>
<p>single causal variant fine mapping what I mean is the model that you write down says there is exactly one variant and</p>
<p>it’s gonna be one of these so under the prior you know if you have M variants your probability is 1 over m that your</p>
<p>first variant is causal and it’s 1 over m that your second variant is causal and that sums to 1 across the whole locus</p>
<p>when in in subsequent work that I’ll talk about in the next section we put</p>
<p>priors on the number of causal variants and those my top waiter down weight you</p>
<p>know well--there’s tend to up wait sparse sparse solutions like single causal variant solutions but in this</p>
<p>case there’s been hard constraint there is only one causal variant at the locus</p>
<p>and does LD structure affects the p IP there’s a lot of questions coming into</p>
<p>bed great no so that’s kind of the magical thing about single causal variant fine mapping</p>
<p>so this was first shown in 2012 and the smaller a tall paper but for one single</p>
<p>causal variant there’s a couple different ways to see it and if I had a white board then I would show some of</p>
<p>them but the fact that these Bayes factors that you can actually compute</p>
<p>the probability of all of the data given that a snip is causal divided by the probability of the data under the null</p>
<p>model that that no longer depends on all of the other variants in the locus you</p>
<p>can see this for example if you’re looking at like a linear model a</p>
<p>spanning of the standard model for quantitative traits them usually write down you can actually write down the normal likelihoods and watch the you</p>
<p>know watch things cancel and then a bunch of stuff disappears and you wind up with something pretty simple but there’s also probabilistic arguments in</p>
<p>both mama at all and wing at all that show that whether you’re conditioning on X or consider X to be part of your data</p>
<p>I it actually again you get this this</p>
<p>cancelling and so it doesn’t your Bayes factors don’t depend on any</p>
<p>variant except the variant that you’re computing the Bayes factor for and I think that’s part of why people like</p>
<p>single causal variant fine mapping so much is that means there’s no way to miss specify your LD it’s it’s super</p>
<p>simple and straightforward I think a related question just to finish up is</p>
<p>just whether there are any other methods that then prefer proximity so whether if you have a you know a clustering of</p>
<p>variants instead of a single variant i’ma that adjacency is considered in any alternative models interesting so the</p>
<p>question there is now you’re modeling multiple causal variants and you want to put a prior that your causal variants</p>
<p>are likely to be close together but you don’t want to up wait or down with any particular variant is that right well so</p>
<p>that was my interpretation of the question but I’ll read the I’ll read the question which was does your candidate set select our selection require that</p>
<p>variants are adjacent or is there a method that prefers proximity so this is about credible sets now so with credible</p>
<p>sets it doesn’t there’s nothing explicit about adjacency I think that typically</p>
<p>if you have a single causal variant then the variants that have the highest P IPS</p>
<p>are going to tend to be an LD with each other and so typically credible sets tend to consist of variants that are and</p>
<p>at least a medium amount of LD with each other and it can this is even used as a diagnostic and susi method if you’re</p>
<p>credible set contains a bunch of variants that are in very loose LD with each other then there’s a sense in which</p>
<p>things didn’t work and you should become suspicious so I would say that if the</p>
<p>model is well specified then you might expect a credible set to consist of variants and I’ll deal with each other but there’s nothing explicit here that</p>
<p>enforces that thank you so much so to recap how might</p>
<p>you do the single causal variant fine mapping well first you can take your summary statistics and compute a</p>
<p>proximate bayes factors or base vectors transform these into P IPs and then compute credible sets from your p IPS</p>
<p>one nice thing about single causal variant side mapping is it also allows us to build some intuition about some</p>
<p>basic concepts and fine mappings so one thing that we might be very interested</p>
<p>in is what factors affect our ability to find math effectively so we’re happy if</p>
<p>we get a few variants with high P IP and other the other variants are with low p IP and that means we’ve really been able</p>
<p>to you know zoom in on the on the causal variance another way to think about so</p>
<p>so I’m using power in quotes because it’s a very frequent test idea but intuitively we’re trying to say with</p>
<p>what confidence have we been able to identify these causal variance and you can imagine that if there’s a lot of LD</p>
<p>in your locus then it’s gonna be harder to identify the causal variant if you</p>
<p>know in the extreme if you have two variants in perfect LD then it doesn’t matter what your sample size is or what</p>
<p>your algorithm is you’re never going to be able to tease apart which of those variants is causal without bringing in</p>
<p>some extra information and then the less LD there is and the locus the easier it becomes to kind of tease apart that</p>
<p>which variant is causal in which variant which variants are non causal and then similarly as with to a sample size and</p>
<p>effect size are both both very important for being able to confidently zoom in on a small number of most likely causal</p>
<p>variants and so in this work by shaded</p>
<p>all the authors wrote down kind of a</p>
<p>approximate expected p IP at a causal snip under a simplified model and so</p>
<p>here’s an example you can imagine you have a locus with ten snips all snips</p>
<p>have equal LD they’re correlated to each other at level R there’s a single causal</p>
<p>simple that explains 1% of the variance in your phenotype and so now the authors</p>
<p>wrote down an analytic expression for roughly under this scenario what would you expect the P IP of the causal</p>
<p>variant to be and and they created this figure so here high values are good that</p>
<p>means we’d when we were able to narrow in with a lot of confidence on the causal variant and you can see that on</p>
<p>the x-axis as the amount of LD among variants in the locus changes you’re</p>
<p>less and less confident that the causal variant is actually causal and then the colored lines show how as you increase</p>
<p>your sample size you’re more and more confident and so being able to get this</p>
<p>you know kind of quantitative sense of what’s the trade-off between LD and</p>
<p>sample size as you’re trying to zoom in on particular causal variants can be a</p>
<p>useful way to build an intuition and one comment I want to make here is that when</p>
<p>we think about cross population by mapping one reason that it’s that it can</p>
<p>be particularly effective to combine information across multiple populations</p>
<p>and fine mapping is because it changes the LD structure so the relevant LD is</p>
<p>related to the average LD between the two populations and so even if you’re</p>
<p>not so if you compare let’s say the same sample size but you can choose to have</p>
<p>it either all in one population or all in another population re or</p>
<p>half-and-half two populations then because there are differences in LD structure among the two populations</p>
<p>combining across populations can help you move to the left in this plot which</p>
<p>is as you can see a good way to also move up which means you’re more</p>
<p>confident in the causal variant so that’s an overview of single causal</p>
<p>variant fine mapping and so now I’ll give kind of a high-level introduction</p>
<p>to a multiple causal variant evasion fine mapping and maybe I’ll pause one more time for questions we had some in</p>
<p>the middle but not just because I’m at the outline slide again are there other questions</p>
<p>great so we we know that there’s often</p>
<p>not just a single causal variant in a locus and so that’s usually not an assumption that we’d like to hard-code</p>
<p>and especially as our sample sizes increase that this becomes more and more relevant and is reflected more and more</p>
<p>clearly in the G loss data that we see so now if we think about multiple causal variant fine mapping there’s two main</p>
<p>approaches and the first one is to say okay there’s multiple causal variants let’s split our locus up in some way and</p>
<p>then apply single causal variant by mapping because that’s a really robust tool that we can use well so then how</p>
<p>does this typically work what does it mean to split the locus up there’s a lot</p>
<p>of different ways to do this one standard way is conditional analysis and so here’s a figure describing</p>
<p>conditional analysis let’s say that this is your locus in the top left here and in conditional analysis you take the top</p>
<p>signal and then you include the genotypes at that variant as a covariant</p>
<p>in your Association and if that variant is in high LD with a causal variant and</p>
<p>there’s only one causal variant then that variant explains the that variant explains all of the other associations</p>
<p>in the locus and so by conditioning on that variant you get this you know you</p>
<p>kill all the signal and you get this modal pattern here so if there’s a single causal variant and if the top variant is in high LD with that causal</p>
<p>variant then conditioning on the top variant will kill all of your signal on the other hand if you’ve got two causal</p>
<p>variants then conditioning on the top variant is unlikely to kill all of your signal and in particular if that top</p>
<p>variant is in high LD with a causal variant then after you’ve conditioned on it then there’s a sense in which you’ve</p>
<p>you know accounted for the effect of that causal variant and now you’ve got a locus that’s got one fewer causal</p>
<p>variant than before and so you can iterate this and then get these a set of</p>
<p>index snips and so conditional analysis is one</p>
<p>commonly used way to break complex locusts into multiple signals and then</p>
<p>to you know one way you might then use simple causal variant fine mapping would be to find map each each of these</p>
<p>signals conditioning on the other so once you’ve got all of your index variants that you got by a conditional</p>
<p>analysis and maybe you’ll include all but one as covariance and apply single causal variant fine mapping and then</p>
<p>repeat that excluding each signal one at a time so that’s a commonly used type of</p>
<p>approach conditional analysis and it has some limitations one limitation is that</p>
<p>you might why there’s no there’s no guarantee that your top variant is in</p>
<p>high LD with a causal variant so here’s an example from the susi paper where</p>
<p>they did a simulation where snips 1 and snip 2 are the causal snips but because</p>
<p>the yellow snip tags both of the two red snips it comes out as most associated</p>
<p>even though it’s not in particularly high LD with either one of these causal snips and so this would be a case where</p>
<p>if you did conditional analysis you start by conditioning on the yellow snip but that wouldn’t properly kill either</p>
<p>of your signals because this idea that your top variant is an high LD with a</p>
<p>causal variant if is violated in this particular case and so conditional</p>
<p>analysis is you know one one approach but examples like this motivate instead</p>
<p>writing down a Bayesian model to jointly model the effects of multiple variants</p>
<p>at the same time and so that’s what I’m calling you know approach number two how</p>
<p>might we jointly model multiple causal variants in one Bayesian model for the</p>
<p>locus the way there are two questions about that that last approach yes oh not</p>
<p>three uh-huh what do you mean by top variance is that defined by the G wife’s score yes yes</p>
<p>sorry by marginal significance and then when you iterate for variants conditionally there’s an assumption that</p>
<p>it’s not done manually what’s the process like and sorting out hits so</p>
<p>there’s a software to do this and it’s pretty automatic right at each case at</p>
<p>each step you want to take the so okay so I guess typically you you have to</p>
<p>kind of manual parts you have to decide when you’re gonna stop and that’s often done by setting a threshold of</p>
<p>significance at what point are you going to say you killed all of the signals and so you know you take the most</p>
<p>significant variant you include it as a covariant if any variant passes whatever</p>
<p>your predetermined level of residual significance is then you’ll do that again you’ll take the most significant</p>
<p>variant condition on it and then and then iterate and then you consider yourself done when no variant passes</p>
<p>your predetermined level of significance set answer the question I think so great</p>
<p>thank you great so then I’ll move on to how we</p>
<p>might jointly model multiple causal variants so here let’s start by analogy</p>
<p>to single causal variant fine mapping but here instead of one variant we’re</p>
<p>gonna look at sets of variants so let’s let SJ be a set of variants and we want</p>
<p>to know what’s the probability that this set of variants is causal given the data and we can again apply Bayes rule and</p>
<p>and then start to try to compute some likelihoods but we get stuck very quickly and the reason is before we were</p>
<p>only summing over variance in in the locus and so we could say like what is</p>
<p>the space of all things that could possibly happen well variant one could be caused variant two could be causal variant three could be caused when</p>
<p>there’s only number of variants possible choices but now what’s the space of all things that could possibly happen</p>
<p>well variant one could be causal or variant 1 and 2 could be causal or variance one 3 and 10 could be causal</p>
<p>and so now if you want to just naively apply Bayes rule you’re summing over all</p>
<p>double configurations of causal variants and that’s large but you know to to the</p>
<p>size of the locus and so that’s for a typical locus way too many terms to be</p>
<p>tractable and so there are a number of different methods to do joint modeling</p>
<p>of multiple causal variants and each one of them approaches this challenge differently so caviar which to my</p>
<p>knowledge was I think the first work to write down this model in this way limits</p>
<p>the maximum number of causal variants and is typically applied to a smaller loose I and and once you limit the</p>
<p>maximum number of causal variants then that limits the you know the total number of configurations as well in a</p>
<p>pretty you know direct way and then there are methods such as fine map and</p>
<p>Apogee that sum over what their algorithm thinks is the most likely</p>
<p>configurations and then more recently the susi method takes a different</p>
<p>approach based on variational inference for those of you can know what that is it’s analogous to iterative conditional</p>
<p>analysis where instead of just doing conditional analysis once through the locusts they then go back and redo the</p>
<p>conditional analysis multiple times until convergence and this has some nice</p>
<p>theoretical properties as well and so this isn’t you know a comprehensive overview of multiple causal variant fine</p>
<p>mapping but just to give a sense that when you want to do joint modeling of multiple causal variants there’s kind of</p>
<p>a fundamental challenge to the first way we would think of to do it and then there’s been a series of really nice</p>
<p>work making that more and more efficient in these different and in other works so</p>
<p>I’m not going to go into the details of exactly how these different methods work</p>
<p>so that’s something that I find very interesting and instead I’m gonna touch on two other methods topics and one of</p>
<p>them is we informed by mapping so let me pause again for questions before I move on to functionally informed by mapping there</p>
<p>is one question do you need to take into account effect size when you when you do this either assume effect size of each</p>
<p>causal variance in the same or weight causal variance by effect sense yeah that’s um a really subtle point that the</p>
<p>different methods deal with differently so you have to put a prior on effect size as the usual</p>
<p>way to do it and then integrate out the prior and so and then the question is well how do you figure out what the</p>
<p>prior should be and some methods do this</p>
<p>by having the prior be you know a mixture of normals or learning the prior</p>
<p>from the data in some cases it’s shared across all variants in some cases it’s different for the different variance and</p>
<p>so that’s an important point that different methods deal with differently</p>
<p>you</p>
<p>so let me sorry is there another question I might be looking at the wrong</p>
<p>place just popped up um mention that there’s evidence that there are multiple causal variants for Jia slow side you’re</p>
<p>curious he um and just curious as to which studies have confirmed that yeah</p>
<p>there’s a couple of different ways to see that I guess I mean one way to see</p>
<p>that is if you look at the applications of multiple causal variant methods that</p>
<p>then give you a posterior on how many variants there are then that posterior</p>
<p>is often concentrated away from one another way to see that is doing conditional analysis if there’s a single</p>
<p>causal variant then conditional analysis should kill your signal pretty well and it very often doesn’t another is</p>
<p>depending on how you define your locus sometimes you can just look at the you know the locus zoom plot and it’s pretty</p>
<p>clear that there’s more than one signal for example if you’ve got a variance</p>
<p>with a high marginal effect that are in low LD with your top variant that’s not really consistent with more than one</p>
<p>variant at the locus there’s been some</p>
<p>work from on actually estimating amounts</p>
<p>of allelic heterogeneity from far farhad and others reskin where they try to you</p>
<p>know model this specifically but i’d say that there’s just for the fact that it</p>
<p>often happens that there are multiple causal variants um that seems to be something when you can see in a lot of</p>
<p>different ways and then the question for how often and how many causal variants i think is a much the subtler and more</p>
<p>difficult thing to get at thank you</p>
<p>when we’re just popped up yes oh so</p>
<p>caviar Susie and Daphne each you’ve different models is there a way to judge a priori which method best suits our</p>
<p>users data so that’s something that I’ll get into towards the end evaluating fine</p>
<p>mapping methods and I in my opinion one</p>
<p>of the things that this field really needs more of is benchmarking in in realistic settings and so I’ll talk a</p>
<p>little bit about about that at the end but you can also base it a bit on</p>
<p>intuition based on just the assumptions that the methods make</p>
<p>but I but I think actually rather than go into that I think that empirical like more empirical evaluation is really</p>
<p>needed a common thing is also to apply more than one method and then when they agree to have more confidence so that’s</p>
<p>something that art has done where we apply both sine map and Susie and then</p>
<p>one way of evaluating the methods is to look at functional enrichments of the variants that get prioritized by these</p>
<p>two different methods and if you look at the enrichment when they agree versus the enrichment when they disagree and</p>
<p>you go with either method then you can see much stronger functional enrichment at the low site where the two methods</p>
<p>agreed and when they disagree but in our hands at least they mostly agree which</p>
<p>is I think Cosford thank you okay so I</p>
<p>got a question earlier about flat priors and and what I was saying was the</p>
<p>methods that I’ve described so far assume that before you look at the G Weiss data in the locus you think every</p>
<p>variant is equally likely to be causal but intuitively of course that’s not the case if you look you haven’t looked at</p>
<p>your gos data yet you just know which variants are in the locus but some of them are coding and some of them are</p>
<p>non-coding then a coding variant is is more likely to drive disease than a</p>
<p>non-coding variant and because we’re doing Bayesian analysis here that can be</p>
<p>incorporated into a prior so a functionally informed prior is one where</p>
<p>you take into account the functional annotations that are variant to up weight and down weight certain variants</p>
<p>according to which ones are more or less likely to be causal a priori and then</p>
<p>the question is how do you set that prior do you have to just kind of trust</p>
<p>your own intuition that I don’t know enhancer variants are five times more likely than then you know they’re not</p>
<p>coding variants to be causal and one way to get around this question is to learn</p>
<p>the prior from the data so there are so a lot of the methods that I described so far if you want to just say what the</p>
<p>prior that can actually be done pretty simply and what makes this difficult is learning from the data by looking across</p>
<p>many low sigh what prior it would make sense to set and so now what you’d like</p>
<p>to do is say ok I’ve got several different low say I’m gonna find max I’m simultaneously but I want to learn by</p>
<p>looking at these low sigh are they consistent with like what how much enrichment are they consistent with and</p>
<p>so different methods again have have done this in different ways FQs is a</p>
<p>functionally informed single causal variant find mapping method and then painter allows for a functionally</p>
<p>informed fine mapping at multiple causal variants and then caviar BF allows for</p>
<p>many annotations in a multiple causal variant framework and most recently poly fun leverages polygenic enrichment in a</p>
<p>by leveraging stratified LD score regression and so to give um just a</p>
<p>example of how this works sometimes I’ve pulled a pig or a figure from the puffin paper and so here if you first focus</p>
<p>only on the squares then you can see that so the squares reflect here the P</p>
<p>IPS that are not functionally informed and if you look only at the squares then</p>
<p>what you can see is the none of the P IPS are bigger than 0.4 and this are s 2</p>
<p>8 8 3 2 6 the Red Square gets a p IP that’s you know somewhere below point 4</p>
<p>but that particular variant turns out to be mountain synonymous and so the</p>
<p>functionally informed fine mapping results which are displayed in circles here up wait that in the prior and so</p>
<p>then if you look at the posterior inclusion probability or the posterior causal probability here then you can see</p>
<p>that incorporating this functional information has bumped up that nonsynonymous variant to a posterior</p>
<p>probability closer to one which might map our match our intuition better from</p>
<p>the combination of the data together with our understanding that this is an onsen</p>
<p>variant so this is this is you know an example of the kinds of ways that</p>
<p>functional information can be incorporated into fine mapping and this has pretty clear advantages for example</p>
<p>you know if your prior reflects true biology then you’ll get a more accurate</p>
<p>posterior and one disadvantage would be</p>
<p>if you want to use functional information downstream to for example evaluate your fine mapping method or if</p>
<p>you sometimes it can be useful to say my fine mapping results don’t actually have</p>
<p>what I haven’t incorporated the functional information yet and so then I can do for example enrichment analyses</p>
<p>but I think that especially as these methods become more efficient and robust</p>
<p>as they have recently then this is going to be an important direction as well a</p>
<p>lot of very useful type of information to be incorporating into fine mapping so</p>
<p>there any questions on functionally informed fine mapping you</p>
<p>I’m great so then um sorry was that sure</p>
<p>it was just a question about variants that might be in trans and how that complicates this analysis yeah for sure</p>
<p>for sure so in order to do functionally informed find mapping you need a set of</p>
<p>annotations so when when you say so so</p>
<p>what you’re taking advantage of is you know how to characterize variants if you don’t know how to characterize the</p>
<p>variants then you can’t take advantage of that anymore so typically you first start by writing down a set of</p>
<p>functional annotations here are my coding variants here are my promoter variants and one thing that’s different among the different methods is how many</p>
<p>of those can write down but if something is regulatory and trans in a way that hasn’t been well characterized or that</p>
<p>you can’t work into your model then yeah then that’s not something that you can take advantage of with these types of</p>
<p>methods and how specific is polyphen to a particular cell type disease or</p>
<p>phenotype and can that be customized so actually Omer feel this question but but</p>
<p>in general if you think about functionally informed find mapping it again depends on which annotations get</p>
<p>used and so if you only incorporate annotations from a certain cell types</p>
<p>and it’ll be cell type specific my understanding is the default for poly fun is not cell type specific and that</p>
<p>it uses annotations that don’t correspond to a particular phenotype which makes it pretty widely applicable</p>
<p>to polygenic phenotypes where you can only pick enrichment estimates I don’t</p>
<p>know if I’ll merge on the call but if he is then he shouldn’t feel free to chime in and then does do those annotations</p>
<p>and include features like promoters and enhancers yeah yeah coding is just one</p>
<p>example but there’s depending on which method you’re looking at typically a</p>
<p>large number of annotations that can be incorporated and then this is testing</p>
<p>the limits of my zoom abilities but Lela would like has a hand up</p>
<p>I will thank you so much great all right</p>
<p>so then maybe I’ll say a few words about summary statistics so many of the</p>
<p>methods that I’ve described I haven’t been differentiating so far but many of them rather than requiring your full</p>
<p>genotype matrix and phenotype vector can actually be run given only your LD matrix and summary statistics and this</p>
<p>is convenient because depending on what your sample size is and how you’re</p>
<p>defining your lo site the LD matrix can be a bit bit smaller but it’s particularly convenient if you can</p>
<p>estimate patterns of LD from a reference panel and so I’ll get into that in the</p>
<p>next slide but let me first point out that this isn’t actually a coincidence if we call our genotype matrix X in our</p>
<p>phenotype vector Y rld matrix is then up to normalization proportional to X transpose X and our summary statistics</p>
<p>allow us to recover X transpose Y X transpose X and X transpose Y are actually sufficient for me in the linear</p>
<p>model that most of these methods are based on and so what that means is that X transpose X and X transpose Y</p>
<p>statistically have the all the information about being that you would want to get from x and y and so the fact</p>
<p>that there continues to be summary statistics based methods is based on</p>
<p>this very nice fact as long as we’re starting from this y equals x people see model then it’s gonna be possible to do</p>
<p>it from summary statistics although here the only guarantee is if you have the actual x transpose x from your entire</p>
<p>genotype matrix so this is full in sample exact LD and of course it doesn’t</p>
<p>apply to you know logistic regression there are things like that and so so</p>
<p>when do you actually need so the statistical guarantees come from in sample LD and when is it okay to use a</p>
<p>subset of your samples or LD that you’ve estimated from a different population and so</p>
<p>Benner it all have written about this particular question and this is their</p>
<p>schematic of what is the question that we’re asking here so starting from the right you can do fine mapping from</p>
<p>summary statistics and LD information if your LD information comes from your G wass data traits and genotypes then</p>
<p>that’s optimal and then the question is if you have a reference panel then can it work to compute LD from the reference</p>
<p>panel instead and their conclusion is that it depends on the size of the</p>
<p>reference panel and the size of your gos and so as your gos gets bigger you have</p>
<p>to have a bigger and bigger reference panel and of course the population has to match as well and so for uh I think</p>
<p>what they say is for a Jewess of over 10,000 variants of 10,000 individuals you need a reference panel of at least</p>
<p>1,000 individuals or something like that and then I think this question of the population must match as well to my</p>
<p>understanding I haven’t seen much work exploring exactly how well do you have to have chosen a perfectly random subset</p>
<p>of the individuals you did your gos in or is it okay to get the right continent or is it something in between there and</p>
<p>and I think that the fact that you know a small perfectly matched subset doesn’t</p>
<p>suffice means that as your gos gets bigger and bigger you have to really be getting the LD very close to to perfect</p>
<p>and so I think that continuing to explore exactly in what situations</p>
<p>reference panel LD is okay and gives accurate answers is something that it</p>
<p>would be helpful to still have more work to understand that set of kind of</p>
<p>constraints because then you know know if it did work that would be very good</p>
<p>so that’s some summary statistics versus</p>
<p>full data and now move on to with my last small number of minutes oops to evaluating find method methods</p>
<p>and it looks like I don’t actually have time to talk about evaluating fine mapping methods so maybe I’ll actually</p>
<p>conclude there and just say the high level of evaluating fine mapping methods</p>
<p>is that it’s important to to try to</p>
<p>break them in all of the ways that we think they’re broken I’ll show you just this one slide by mapping methods tend</p>
<p>to assume that all the causal variants in the locus are modeled there’s no imputation noise you have exactly</p>
<p>between one and five or one and ten causal variants and that your phenotype</p>
<p>is normally distributed and conditional and your genotype you know things like that and then typically when fine</p>
<p>mapping methods are evaluated all of these assumptions are satisfied in the evaluation and so one thing that my</p>
<p>group has been working on that we think is very important is trying to find other ways to evaluate fine mapping</p>
<p>methods both in simulations that might break some of these assumptions and also</p>
<p>buy real data analyses that can give us insight into what’s working and what’s</p>
<p>not so with that I will conclude because</p>
<p>we’re out of time if there’s any final questions maybe I could take one first was that omer wrote and didn’t</p>
<p>completely agree with you that pali thein can be customized but isn’t by default and then I’ll just take one</p>
<p>question I think this is an interesting one I’ve been actually wondering is summary statistics preserve privacy but</p>
<p>is there a way to publish the true underlying LD matrices or approximations</p>
<p>there AB it will also preserve adequate participant privacy I think that’s a</p>
<p>super interesting thing to look into and I don’t know the answer to that I I’m</p>
<p>pretty sure that you can release approximate LD while preserving privacy because approximate LD should be the</p>
<p>same in different samples from the same population but I’m not sure whether you</p>
<p>can whether or not it’s possible to publish you know infinite precision exact LD while preserving privacy that’s</p>
<p>not something I’ve worked on myself and I don’t know of any work on that in particular if someone</p>
<p>else on the call does they should chime in good this was a wonderful session thank you so much Hillary this was our</p>
<p>most interactive timer yes clearly a topic of great interest very well presented but thank you all and we’ll</p>
<p>see you in just a few minutes for the mpg session</p>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>